{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # This will be helpful when visualizing retriever outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "import os\n",
    "import yake\n",
    "\"\"\"\n",
    "def load_pdfs_from_folder(folder_path):\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith(\".pdf\")]\n",
    "    documents = []\n",
    "    for pdf_file in tqdm(pdf_files):\n",
    "        loader = PyMuPDFLoader(REMOVED_SECRET(folder_path, pdf_file))\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\"\"\"\n",
    "def load_pdfs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    This function loads PDFs from a chosen folder - or a 'local database'. \n",
    "    For each file detected, it checks if the file is empty. \n",
    "    The file is then loaded into PyMuPDF. \n",
    "    The document is added to a list called 'documents'. \n",
    "    And then at the end, that list is returned. \n",
    "\n",
    "    I am planning to add functionality (perhaps another function) that will store keywords from each PDF.\n",
    "    \"\"\"\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith(\".pdf\")]\n",
    "    documents = []\n",
    "    for pdf_file in tqdm(pdf_files):\n",
    "        pdf_path = REMOVED_SECRET(folder_path, pdf_file)\n",
    "        try:\n",
    "            #Check if the file is empty before loading\n",
    "            if REMOVED_SECRET(pdf_path) == 0:\n",
    "                print(f\"Skipping empty file: {pdf_file}\")\n",
    "                continue  #Move on to the next file\n",
    "\n",
    "            loader = PyMuPDFLoader(pdf_path)\n",
    "            documents.extend(loader.load())\n",
    "        except Exception as e:  #Catch potential errors during loading\n",
    "            print(f\"Error loading file {pdf_file}: {e}\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "9f8e80459b47455bae55e4d7dee9480c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf_folder_path = \"local_database\"\n",
    "pdf_data = load_pdfs_from_folder(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "66a7510c129e40a0a4abca6e41cfc4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from REMOVED_SECRET import Document as LangchainDocument\n",
    "\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc.page_content, metadata={\"source\": doc.metadata[\"source\"]}) for doc in tqdm(pdf_data)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor = yake.KeywordExtractor()\n",
    "keywords = {}\n",
    "\n",
    "\n",
    "def get_keywords_from_file(documents):\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "97462edbb7124139910b32a867159ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "521bb847eda149d9ad29c9a4ee476740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keyword entries: [('local_REMOVED_SECRETde20231-133446952049283794.pdf', ['Birmingham City University', 'Birmingham City', 'City University', 'Lumivero', 'Birmingham', 'University', 'Assassin Creed', 'City', 'August', 'Candy Crush Saga']), ('local_database/How-it-Works-booklet.pdf', ['Logo', 'Parliament']), ('local_database/c4611_sample_explain.pdf', ['PDF Bookmark Sample', 'Bookmark Sample Page', 'PDF Bookmark', 'Sample Page', 'Bookmark Sample', 'Place', 'Output Designer', 'PDF', 'Page', 'Bookmark'])]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import yake  # Keyword extractor\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from REMOVED_SECRET import Document as LangchainDocument\n",
    "import os\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "\n",
    "def load_pdfs_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Loads PDFs from a folder, skipping empty files.\n",
    "    Adds keyword extraction to each document.\n",
    "    \"\"\"\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith(\".pdf\")]\n",
    "    documents = []\n",
    "    keyword_dict = {}  # Dictionary to store keywords by document ID\n",
    "\n",
    "    for pdf_file in tqdm(pdf_files):\n",
    "        pdf_path = REMOVED_SECRET(folder_path, pdf_file)\n",
    "        try:\n",
    "            if REMOVED_SECRET(pdf_path) == 0:\n",
    "                print(f\"Skipping empty file: {pdf_file}\")\n",
    "                continue\n",
    "\n",
    "            loader = PyMuPDFLoader(pdf_path)\n",
    "            loaded_docs = loader.load()\n",
    "\n",
    "            for doc in loaded_docs:  # Extract keywords for each loaded page\n",
    "                # Keyword extraction (you can adjust parameters)\n",
    "                kw_extractor = yake.KeywordExtractor(lan=\"en\", n=3, dedupLim=0.9, top=10)\n",
    "                keywords = kw_extractor.extract_keywords(doc.page_content)\n",
    "                keywords = [kw[0] for kw in keywords]  # Get just the keyword strings\n",
    "\n",
    "                # Create LangchainDocument with keywords added\n",
    "                langchain_doc = LangchainDocument(\n",
    "                    page_content=doc.page_content, \n",
    "                    metadata={\"source\": doc.metadata[\"source\"], \"keywords\": keywords}\n",
    "                )\n",
    "                documents.append(langchain_doc)\n",
    "\n",
    "                # Add to keyword dictionary\n",
    "                doc_id = langchain_doc.metadata[\"source\"]  # Unique ID (likely the file path)\n",
    "                keyword_dict[doc_id] = keywords \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {pdf_file}: {e}\")\n",
    "\n",
    "    return documents, keyword_dict\n",
    "\n",
    "\n",
    "# Load PDFs and get keywords\n",
    "pdf_folder_path = \"local_database\"\n",
    "pdf_data, keyword_dict = load_pdfs_from_folder(pdf_folder_path)\n",
    "\n",
    "# Your existing LangchainDocument creation, now with keywords\n",
    "RAW_KNOWLEDGE_BASE = [doc for doc in tqdm(pdf_data)] \n",
    "\n",
    "print(\"Sample keyword entries:\", list(keyword_dict.items())[:3])  # See some results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "REMOVED_SECRET"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

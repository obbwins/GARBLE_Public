{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "a3d7bd27ccce4b4186e4440a3a3c170f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `REMOVED_SECRET.GradScaler(args...)` is deprecated. Please use `REMOVED_SECRET('cuda', args...)` instead.\n",
      "  self.scaler = REMOVED_SECRET.GradScaler()\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:03<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question:\\n\\nwho owns st andrews golf course in scotland\\n\\nAnswer:\\n\\n<P> The Old Course at St Andrews is considered the oldest golf course in the world , a public\\n\\ncourse over common land in St Andrews , Fife , Scotland . It is held in trust by The St Andrews\\n\\nLinks Trust under an act of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have playing privileges on\\n\\nthe course , along with the general public . </P>\\n\\nContext:\\n\\nOld Course at St Andrews - wikipedia Old Course at St Andrews Jump to :\\n\\nnavigation , search Old Course R&A Clubhouse and 18th green in 2004 Club\\n\\ninformation\\n\\nCoordinates\\n\\n56 ° 20\\n\\n35 ''\\n\\nN 2 ° 48\\n\\n11 ''\\n\\n56.343 °\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Coordinates : 56 ° 20 35 '' N 2 ° 48 11 ''\\n\\nW\\n\\n56.343\\n\\n°\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Location St Andrews ,\\n\\nW\\n\\n/\\n\\nW\\n\\n/\\n\\nW\\n\\nScotland Established 1552 Type Public Owned by Fife Council\\n\\nOperated by St Andrews Links Trust Total holes 18 Tournaments hosted\\n\\nThe Open Championship , Alfred Dunhill Links Championship Website Old\\n\\nCourse Par 72 Length 7,305 yards ( 6,680 m ) Course record\\n\\n61 ; Ross Fisher ( 2017 ) St Andrews Location in Scotland St Andrews\\n\\nLocation in Fife , Scotland The Old Course at St Andrews is considered the\\n\\noldest golf course in the world , a public course over common land in St Andrews\\n\\n, Fife , Scotland . It is held in trust by The St Andrews Links Trust under an\\n\\nact of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have\\n\\nplaying privileges on the course , along with the general public . Contents\\n\\n( hide ) 1 History 1.1 Governance 1.2 Influence on modern golf 1.3 Old\\n\\nCourse and Bobby Jones 2 Features 3 The Open Championship 4 Scorecard\\n\\n5 Women 's British Open 6 Senior Open Championship 7 See also 8 References\\n\\n9 External links History ( edit ) The Old Course at St Andrews is\\n\\nconsidered by many to be the `` home of golf '' because the sport was first\\n\\nplayed on the Links at St Andrews in the early 15th century . Golf was becoming\\n\\nincreasingly popular in Scotland until in 1457 , when James II of Scotland\\n\\nbanned golf because he felt that young men were playing too much golf instead of\\n\\npractising their archery . The ban was upheld by the following kings of Scotland\\n\\nuntil 1502 , when King James IV became a\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question:\\n\\nequation for the velocity of an object in motion at constant acceleration\\n\\nAnswer:\\n\\nContext:\\n\\nEquations of motion - wikipedia Equations of motion Jump to : navigation ,\\n\\nsearch Classical mechanics F = m a ( \\\\ displaystyle ( \\\\ vec ( F ) ) =\\n\\nm ( \\\\ vec ( a ) ) ) Second law of motion History Timeline Branches\\n\\n( show ) Applied Celestial Continuum Dynamics Kinematics Kinetics\\n\\nStatics Statistical Fundamentals ( show ) Acceleration Angular\\n\\nmomentum Couple D'Alembert's principle Energy kinetic potential\\n\\nForce Frame of reference Impulse Inertia / Moment of inertia Mass\\n\\nMechanical power Mechanical work Moment Momentum Space Speed Time\\n\\nTorque Velocity Virtual work Formulations ( show ) Newton 's laws of\\n\\nmotion Analytical mechanics Lagrangian mechanics Hamiltonian mechanics\\n\\nRouthian mechanics Hamilton -- Jacobi equation Appell 's equation of motion\\n\\nUdwadia -- Kalaba equation Koopman -- von Neumann mechanics Core\\n\\ntopics ( show ) Damping ( ratio ) Displacement Equations of motion Euler\\n\\n's laws of motion Fictitious force Friction Harmonic oscillator\\n\\nInertial / Non-inertial reference frame Mechanics of planar particle motion\\n\\nMotion ( linear ) Newton 's law of universal gravitation Newton 's laws of\\n\\nmotion Relative velocity Rigid body dynamics Euler 's equations\\n\\nSimple harmonic motion Vibration Rotation ( show ) Circular motion\\n\\nRotating reference frame Centripetal force Centrifugal force reactive\\n\\nCoriolis force Pendulum Tangential speed Rotational speed Angular\\n\\nacceleration / displacement / frequency / velocity Scientists ( show )\\n\\nGalileo Newton Kepler Horrocks Halley Euler d'Alembert Clairaut\\n\\nLagrange Laplace Hamilton Poisson Daniel Bernoulli Johann Bernoulli\\n\\nCauchy In mathematical physics , equations of motion are\\n\\nequations that describe the behaviour of a physical system in terms of its\\n\\nmotion as a function of time . More specifically , the equations of motion\\n\\nde\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question:\\n\\nwho sang take that look off your face\\n\\nAnswer:\\n\\n<P> `` Take That Look Off Your Face '' is the title of a hit song by musical theatre composer\\n\\nAndrew Lloyd Webber . Collaborating with lyricist Don Black , it was written for the song cycle\\n\\nshow Tell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 , and\\n\\nbecame a No. 3 hit in the UK charts . The song was also popular in Ireland , and spent six weeks\\n\\nat number one . Later , Tell Me on a Sunday was combined with another Lloyd Webber work ,\\n\\nVariations , to form an entire new show , Song and Dance . </P>\\n\\nContext:\\n\\nTake that Look Off Your Face - Wikipedia Take that Look Off Your Face Jump to\\n\\n: navigation , search `` Take That Look Off Your Face '' Single by\\n\\nMarti Webb from the album Tell Me on a Sunday B - side `` Sheldon\\n\\nBloom '' Released January 1980 Format 7 '' single Recorded\\n\\n1979 Genre Pop , MOR , Theatrical Length 3 : 27 Label Polydor\\n\\nSongwriter ( s ) Andrew Lloyd Webber , Don Black Producer ( s ) Andrew\\n\\nLloyd Webber Marti Webb singles chronology `` D - Darling '' ( 1973 )\\n\\n`` Take That Look Off Your Face '' ( 1980 ) `` Tell Me on a Sunday '' ( 1980 )\\n\\n`` D - Darling '' ( 1973 ) `` Take That Look Off Your Face '' ( 1980 ) ``\\n\\nTell Me on a Sunday '' ( 1980 ) `` Take That Look Off Your Face '' is the\\n\\ntitle of a hit song by musical theatre composer Andrew Lloyd Webber .\\n\\nCollaborating with lyricist Don Black , it was written for the song cycle show\\n\\nTell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 ,\\n\\nand became a No. 3 hit in the UK charts . The song was also popular in Ireland ,\\n\\nand spent six weeks at number one . Later , Tell Me on a Sunday was combined\\n\\nwith another Lloyd Webber work , Variations , to form an entire new show , Song\\n\\nand Dance . The song is about a woman being told of her boyfriend 's\\n\\ninfidelity . The woman denies this initially , before rebuking her newsbearer (\\n\\na girlfriend ) with the revelation that she `` knew before '' and had done for\\n\\nsome time . She also spends much of the song criticising her friend for rushing\\n\\nto break the `` bad news '' to her . Despite having been written during the\\n\\ncreative process for Tell Me on a Sunday , the song was n't recorded during the\\n\\nalbum 's principal sessions . Black reminded Lloyd Webber that they had missed a\\n\\ntrack , then entitled `` You Must Be Mistaken '' . John Mole , the bass guitar\\n\\nplayer , improvised a part reminiscent of the arrangement style of Phil Spector\\n\\n, inspiring the rest of the orchestra\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content='Question:\\n\\nwho was gails most recent husband in coronation street\\n\\nAnswer:\\n\\nContext:\\n\\nGail McIntyre - wikipedia Gail McIntyre Gail McIntyre Coronation\\n\\nStreet character Portrayed by Helen Worth Duration 1974 -- First\\n\\nappearance Episode 1412 29 July 1974 Introduced by H.V. Kershaw Book\\n\\nappearances Coronation Street : The Complete Saga Norman Bates with a\\n\\nBriefcase : The story of Richard Hillman Spin - off appearances East\\n\\nStreet ( 2010 ) Classification Present ; regular Profile Other\\n\\nnames Gail Potter Gail Tilsley Gail Platt Gail McIntyre Gail Hillman\\n\\nGail Rodwell Occupation Receptionist Cleaner Waitress Factory\\n\\nWorker Newsagent Home 8 Coronation Street ( 1991 - 33 Hammond Road\\n\\n( 1985 - 1991 ) 5 Buxton Close ( 1980 - 1983 ) 5 Coronation Street ( 1979 -\\n\\n1980 , 1983 - 1985 ) 11 Coronation Street ( 1976 - 1979 ) 15a Coronation\\n\\nStreet ( 1975 - 1976 ) show Family Father Ted Page Mother\\n\\nAudrey Roberts Stepfather Alf Roberts Half - brothers Stephen Reid\\n\\nHusband Brian Tilsley ( 1979 -- 1987 , 1988 -- 1989 ) Martin Platt ( 1991\\n\\n-- 2001 ) Richard Hillman ( 2002 -- 2003 ) Joe McIntyre ( 2010 ) Michael\\n\\nRodwell ( 2015 -- 2016 ) Sons Nick Tilsley David Platt Daughters\\n\\nSarah Platt Stepdaughters Tina McIntyre Grandsons Billy Platt\\n\\nHarry Platt Max Turner ( step ) Granddaughters Bethany Platt Lily\\n\\nPlatt Grandfathers Robert Potter Grandmothers Nancy Potter\\n\\nGail Rodwell ( also Potter , Tilsley , Platt , Hillman and McIntyre ) is a\\n\\nfictional character from the British ITV soap opera , Coronation Street .\\n\\nPortrayed by Helen Worth , the character first appeared on - screen on 29 July\\n\\n1974 . As of 2018 , Gail has been on the show for 44 years , which currently\\n\\nmakes her the third longest - running character on the show after Ken Barlow and\\n\\nRita Tanner . Gail is the daughter of Audrey Roberts ( Sue Nicholls ) and Ted\\n\\nPage ( Michael Byrne ) and is the mother of Nick Tilsley (', metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content=\"Question:\\n\\nwhen did they figure out that yeast made bread rise\\n\\nAnswer:\\n\\n<P> The most common source of leavening in antiquity was to retain a piece of dough ( with\\n\\nsugar and water in ) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to produce `` a\\n\\nlighter kind of bread than other peoples . '' Parts of the ancient world that drank wine instead of\\n\\nbeer used a paste composed of grape must and flour that was allowed to begin fermenting , or\\n\\nwheat bran steeped in wine , as a source for yeast . </P>\\n\\nContext:\\n\\nHistory of bread - wikipedia History of bread Jump to : navigation , search\\n\\nSlab stele from mastaba tomb of Itjer at Giza . 4th Dynasty , 2543 - 2435 BC .\\n\\nItjer is seated at a table with slices of bread , shown vertical by convention .\\n\\nEgyptian Museum , Turin Bread was central to the formation of early human\\n\\nsocieties . From the western half of Asia , where wheat was domesticated ,\\n\\ncultivation spread north and west , to Europe and North Africa . This in turn\\n\\nled to the formation of towns , as opposed to the nomadic lifestyle , and gave\\n\\nrise to more and more sophisticated forms of societal organization . Similar\\n\\ndevelopments occurred in eastern Asia , centered on rice , and in the Americas\\n\\nwith maize . Contents ( hide ) 1 Antiquity 2 Middle Ages 3 To the\\n\\n19th century 4 Industrialization 5 See also 6 Notes Antiquity ( edit\\n\\n) Conical loaves of bread as grave goods exactly as laid out in the Great Tomb\\n\\n, North Necropolis , Gebelein , 5th Dynasty ( Old Kingdom ) , 2435 - 2305 BC .\\n\\nExcavations by Ernesto Schiaparelli , 1911 . Egyptian Museum , Turin , S. 14051\\n\\n14055 There is extensive evidence of breadmaking in Ancient Egypt in the form\\n\\nof artistic depictions , remains of structures and items used in bread making ,\\n\\nand remains of the dough and bread itself . The most common source of\\n\\nleavening in antiquity was to retain a piece of dough ( with sugar and water in\\n\\n) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to\\n\\nproduce `` a lighter kind of bread than other peoples . '' Parts of the ancient\\n\\nworld that drank wine instead of beer used a paste composed of grape must and\\n\\nflour that was allowed to begin fermenting , or wheat bran steeped in wine , as\\n\\na source for yeast . The idea of a free - standing oven that could be pre-\\n\\nheated , with a door for access , appears to have been Greek . Even in\\n\\nantiquity there were a wide variety of breads\", metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question:\\n\\nwho led the various reform movements of the 19th century\\n\\nAnswer:\\n\\nContext:\\n\\nConservation movement - wikipedia Conservation movement Jump to : navigation ,\\n\\nsearch For specific types of conservation , see Conservation ( disambiguation )\\n\\n. `` Conservationism '' redirects here . It is not to be confused with\\n\\nConservatism . Much attention has been given to preserving the natural\\n\\ncharacteristics of Hopetoun Falls , Australia , while allowing ample access for\\n\\nvisitors . Part of the Politics series Party politics Political\\n\\nspectrum Left - wing Far - left Hard - Left Extreme left\\n\\nCentre Centre - left Radical center Centre - right , Third Position\\n\\nRight - wing Far - right Hard right New right Alt - right Alt -\\n\\nlite Party platform Extremist Radical Moderate\\n\\nReformist Syncretic Third Position Conservative Fundamentalist\\n\\nReactionary Party system Non-partisan One - party\\n\\nDominant - party Two - party Multi-party Coalition Hung\\n\\nparliament Confidence and supply Minority government Rainbow coalition\\n\\nGrand coalition Full coalition National unity government Majority\\n\\ngovernment Lists Ruling parties by country Political parties by UN\\n\\ngeoscheme Political ideologies Politics portal The\\n\\nconservation movement , also known as nature conservation , is a political ,\\n\\nenvironmental and a social movement that seeks to protect natural resources\\n\\nincluding animal and plant species as well as their habitat for the future .\\n\\nThe early conservation movement included fisheries and wildlife management ,\\n\\nwater , soil conservation and sustainable forestry . The contemporary\\n\\nconservation movement has broadened from the early movement 's emphasis on use\\n\\nof sustainable yield of natural resources and preservation of wilderness areas\\n\\nto include preservation of biodiversity . Some say the conservation movement is\\n\\npart of the broader and more far - reaching environmental movement , while\\n\\nothers arg\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content=\"Question:\\n\\nwho has climbed the great wall of china\\n\\nAnswer:\\n\\nContext:\\n\\nGreat Wall of China - wikipedia Great Wall of China Jump to : navigation ,\\n\\nsearch `` Great Wall '' redirects here . For other uses , see Great Wall (\\n\\ndisambiguation ) . Great Wall of China The Great Wall of China\\n\\nat Jinshanling Map of all the wall constructions General information\\n\\nType Fortification Country China Coordinates 40 ° 41 N 117 ° 14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Coordinates : 40 ° 41 N 117\\n\\n°\\n\\n14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Technical details\\n\\nSize 21,196 km ( 13,171 mi ) UNESCO World Heritage Site Criteria\\n\\nCultural : ( i ) , ( ii ) , ( iii ) , ( iv ) , ( vi ) Reference 438\\n\\n°\\n\\n°\\n\\nE\\n\\n/\\n\\nE\\n\\nE\\n\\n/\\n\\nE\\n\\nInscription 1987 ( 11th Session ) ( edit on Wikidata ) Great\\n\\nWall of China Simplified Chinese Traditional Chinese\\n\\nLiteral meaning `` The Long Wall '' ( show ) Transcriptions\\n\\nStandard Mandarin Hanyu Pinyin Chángchéng Wade -- Giles Ch'ang -\\n\\nch'eng\\n\\nIPA\\n\\nh\\n\\n) Wu Romanization Saon sen Yue :\\n\\nCantonese\\n\\nYale Romanization\\n\\nCheung sing\\n\\ntsh\\n\\n. s )\\n\\nJyutping\\n\\nCoeng sing\\n\\nSouthern Min\\n\\nTn\\n\\ng - siân Tâi -\\n\\nlô\\n\\nTn\\n\\ng - siânn Alternative Chinese name Simplified Chinese\\n\\nTraditional Chinese Literal meaning `` The 10,000 - Mile Long Wall\\n\\n'' ( show ) Transcriptions Wu Romanization Vae - li saon - sen\\n\\nYue : Cantonese Yale Romanization Maan lei Cheung sing IPA ( màn.\\n\\nle\\n\\ni\\n\\n(\\n\\nIPA\\n\\nHokkien POJ\\n\\nh.\\n\\n(\\n\\ntsh\\n\\n. s ) Jyutping Maan - lei coeng - sing Southern Min\\n\\nTâi\\n\\n\\n\\nlô\\n\\nBn\\n\\ntn\\n\\ng - siânn The Great Wall of China is a series\\n\\nof fortifications made of stone , brick , tamped earth , wood , and other\\n\\nmaterials , generally built along an east - to - west line across the historical\\n\\nnorthern borders of China to protect the Chinese states and empires against the\\n\\nraids and invasions of the various nomadic groups of the Eu\\n\\n\\n\\nlí\", metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content='Question:\\n\\nwhen did star trek the next generation first air\\n\\nAnswer:\\n\\n<Table> <Tr> <Th colspan=\"2\"> Season </Th> <Th colspan=\"2\"> Episodes </Th> <Th\\n\\ncolspan=\"2\"> Originally aired </Th> </Tr> <Tr> <Th> First aired </Th> <Th> Last aired </Th>\\n\\n</Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 28 , 1987 ( 1987 - 09 - 28 ) </Td> <Td> May 16 , 1988 ( 1988 - 05 - 16\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 22 </Td> <Td\\n\\ncolspan=\"1\"> November 21 , 1988 ( 1988 - 11 - 21 ) </Td> <Td> July 17 , 1989 ( 1989 - 07 - 17 )\\n\\n</Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 25 , 1989 ( 1989 - 09 - 25 ) </Td> <Td> June 18 , 1990 ( 1990 - 06 - 18\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 24 , 1990 ( 1990 - 09 - 24 ) </Td> <Td> June 17 , 1991 ( 1991 - 06 - 17\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 5 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 23 , 1991 ( 1991 - 09 - 23 ) </Td> <Td> June 15 , 1992 ( 1992 - 06 - 15\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 6 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 21 , 1992 ( 1992 - 09 - 21 ) </Td> <Td> June 21 , 1993 ( 1993 - 06 - 21\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 7 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 20 , 1993 ( 1993 - 09 - 20 ) </Td> <Td> May 23 , 1994 ( 1994 - 05 - 23\\n\\n) </Td> </Tr> </Table>\\n\\nContext:\\n\\nStar Trek : the Next Generation - wikipedia Star Trek : the Next Generation\\n\\nJump to : navigation , search This article is about the television series . For\\n\\nthe games , see Star Trek : The Next Generation ( 1994 video game ) and Star\\n\\nTrek : The Next Generation : A World For All Seasons . Star Trek : The Next\\n\\nGeneration Genre Science fiction Drama Mystery Action\\n\\nadventure Created by Gene Roddenberry Based on Star Trek by Gene\\n\\nRoddenberry Starring Patrick Stewart Jonathan Frakes Brent Spiner\\n\\nLeVar Burton Denise Crosby Michael Dorn Gates McFadden Marina Sirtis\\n\\nWil Wheaton Theme music composer Alexander Courage Jerry Goldsmith\\n\\nComposer ( s ) Dennis McCarthy Jay Chattaway Ron Jones Country of origin\\n\\nUnited States Original language ( s ) English No. of seasons 7\\n\\nNo. of episodes 178 ( list of episodes ) Production Executive producer\\n\\n( s ) Gene Roddenberry ( 1987 -- 91 ) Rick Berman ( 1989 -- 94 )\\n\\nShowrunners Maurice Hurley ( 1988 -- 89 ) Michael Piller ( 1989 -- 94 )\\n\\nJeri Taylor ( 1993 -- 94 ) Cinematography Edward R. Brown ( 1987 -- 89\\n\\n) Marvin V. Rush ( 1989 -- 92 ) Jonathan West ( 1992 -- 94 ) Running\\n\\ntime 44 minutes Production company ( s ) Paramount Domestic Television\\n\\nDistributor CBS Television Distribution Budget $1.3 million per episode\\n\\nRelease Original network First - run syndication Picture format\\n\\nNTSC 480i 4 : 3 1080p 4 : 3 ( Blu - ray ) Audio format Dolby SR\\n\\nDolby Digital 5.1 ( DVD ) DTS - HD Master Audio 7.1 Blu - ray Original\\n\\nrelease September 28 , 1987 ( 1987 - 09 - 28 ) -- May 23 , 1994 ( 1994 - 05 -\\n\\n23 ) Chronology Preceded by Star Trek : The Animated Series\\n\\nFollowed by Star Trek : Deep Space Nine Related shows Star Trek TV\\n\\nseries External links Star Trek : The Next Generation at StarTrek.com\\n\\nStar Trek : The Next Generation ( abbreviated as TNG and ST : TNG ) i', metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content=\"Question:\\n\\nwhere were deep-sea hydrothermal vents first discovered 25 years ago\\n\\nAnswer:\\n\\nContext:\\n\\nHydrothermal vent - wikipedia Hydrothermal vent Jump to : navigation , search\\n\\nMarine habitats White smokers emitting liquid rich in barium , calcium ,\\n\\nsilicon and carbon dioxide at the Champagne vent , Northwest Eifuku volcano ,\\n\\nMarianas Trench Marine National Monument Littoral zone Intertidal zone\\n\\nEstuaries Kelp forests Coral reefs Ocean banks Continental shelf\\n\\nNeritic zone Straits Pelagic zone Oceanic zone Seamounts Hydrothermal\\n\\nvents Cold seeps Demersal zone Benthic zone A\\n\\nhydrothermal vent is a fissure in a planet 's surface from which geothermally\\n\\nheated water issues . Hydrothermal vents were discovered years ago in 1977 .\\n\\nHydrothermal vents are commonly found near volcanically active places , areas\\n\\nwhere tectonic plates are moving apart at spreading centers , ocean basins , and\\n\\nhotspots . Hydrothermal vents exist because the earth is both geologically\\n\\nactive and has large amounts of water on its surface and within its crust .\\n\\nCommon land types include hot springs , fumaroles and geysers . Under the sea ,\\n\\nhydrothermal vents may form features called black smokers . Relative to the\\n\\nmajority of the deep sea , the areas around submarine hydrothermal vents are\\n\\nbiologically more productive , often hosting complex communities fueled by the\\n\\nchemicals dissolved in the vent fluids . Chemosynthetic bacteria and archaea\\n\\nform the base of the food chain , supporting diverse organisms , including giant\\n\\ntube worms , clams , limpets and shrimp . Active hydrothermal vents are believed\\n\\nto exist on Jupiter 's moon Europa , and Saturn 's moon Enceladus , and it is\\n\\nspeculated that ancient hydrothermal vents once existed on Mars . Contents\\n\\n( hide ) 1 Physical properties 2 Black smokers and white smokers 3\\n\\nBiological communities 4 Biological theories 4.1 The Deep Hot Biosphere\\n\\n4.2 Hydrothermal origin of life 5 Discovery and exploration 6 Distribution\\n\\n7 Exploitation 8 Conservation 9 See also 10 References\", metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question:\\n\\nthe period of european history between ancient and modern eras\\n\\nAnswer:\\n\\nContext:\\n\\nHistory of Europe - wikipedia History of Europe Jump to : navigation , search\\n\\nThe history of Europe covers the peoples inhabiting Europe from prehistory to\\n\\nthe present . The period known as classical antiquity began with the emergence\\n\\nof the city - states of ancient Greece . Later , the Roman Empire came to\\n\\ndominate the entire Mediterranean basin . The fall of the Roman Empire in AD 476\\n\\ntraditionally marks the start of the Middle Ages . Beginning in the 14th century\\n\\na Renaissance of knowledge challenged traditional doctrines in science and\\n\\ntheology . Simultaneously , the Protestant Reformation set up Protestant\\n\\nchurches primarily in Germany , Scandinavia and England . After 1800 , the\\n\\nIndustrial Revolution brought prosperity to Britain and Western Europe . The\\n\\nmain powers set up colonies in most of the Americas and Africa , and parts of\\n\\nAsia . In the 20th century , World War I , and World War II resulted in massive\\n\\nnumbers of deaths . The Cold War dominated European geo - politics from 1947 to\\n\\n1989 . Unification into a European Union moved forward after 1950 , with some\\n\\nsetbacks . Today , most countries west of Russia belong to the NATO military\\n\\nalliance , along with the United States and Canada . Europe depicted by Antwerp\\n\\ncartographer Abraham Ortelius in 1595 Contents ( hide ) 1 Overview 2\\n\\nPrehistory 3 Minoans and Mycenae 2700 -- 1100 BC 4 Classical antiquity 4.1\\n\\nAncient Greece 4.2 The rise of Rome 4.3 Decline of the Roman Empire 4.4\\n\\nLate Antiquity and Migration Period 5 Middle Ages 5.1 Byzantium 5.2\\n\\nEarly Middle Ages 5.2. 1 Feudal Christendom 5.3 High Middle Ages 5.3. 1\\n\\nA divided church 5.3. 2 Holy wars 5.4 Late Middle Ages 6 Early modern\\n\\nEurope 6.1 Renaissance 6.2 Exploration and trade 6.3 Reformation 6.4\\n\\nMercantilism and colonial expansion 6.5 Crisis of the 17th century 6.6 Age\\n\\nof Absolutism 6.6. 1 Thirty Years ' War 1618 -- 1648 6.6. 2 War of the\\n\\nSpanish Succession 6.6. 3 Prussia 6.6. 4 Rus\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question:\\n\\nwho sang the most wonderful summer of my life\\n\\nAnswer:\\n\\n<P> Jackie Ward ( born Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an\\n\\nAmerican singer , regarded as a `` one - hit wonder '' of 1963 million - selling song `` Wonderful\\n\\nSummer '' . However , using her real name she was highly accomplished and successful singing in\\n\\ngroups . Ward 's voice is heard in U.S. television series , motion pictures , advertisements , and\\n\\npop records . She is one of the real singers of the hits attributed to The Partridge Family . </P>\\n\\nContext:\\n\\nRobin Ward ( singer ) - wikipedia Robin Ward ( singer ) This article may\\n\\nneed to be rewritten entirely to comply with Wikipedia 's quality standards .\\n\\nYou can help . The discussion page may contain suggestions . ( January 2018 )\\n\\nRobin Ward Birth name Jacqueline McDonnell Also known as Jackie Ward\\n\\n1941 ( age 76 -- 77 ) Hawaii , USA Genres Pop , TV theme songs , Movie\\n\\nsongs , Advertising Occupation ( s ) Singer Instruments Voice\\n\\nYears active 1954 -- 1979 Labels Dot Records Associated acts\\n\\nPartridge Family , Ray Conniff Singers , Ron Hicklin Singers Jackie Ward (\\n\\nborn Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an American\\n\\nsinger , regarded as a `` one - hit wonder '' of 1963 million - selling song ``\\n\\nWonderful Summer '' . However , using her real name she was highly accomplished\\n\\nand successful singing in groups . Ward 's voice is heard in U.S. television\\n\\nseries , motion pictures , advertisements , and pop records . She is one of the\\n\\nreal singers of the hits attributed to The Partridge Family . Contents 1\\n\\nBiography 1.1 Early years 1.2 `` Wonderful Summer '' 1.3 Post `` Robin\\n\\nWard '' TV , movies , and records singing 1.4 The Partridge Family 2\\n\\nReferences 3 External links Biography ( edit ) Early years ( edit )\\n\\nWard was born Jacqueline McDonnell in 1941 to a military family in Hawaii ( her\\n\\nfather served in the US Navy ) and raised in Nebraska . Her first public singing\\n\\nperformances were with her two sisters in a Nebraska church when she was eight\\n\\nyears old . After the trio won a national talent search run by Horace Heidt ,\\n\\nthey moved to Los Angeles to seek work in the music industry . At the age of\\n\\n13 , Ward was hired by Los Angeles television station KTLA to sing on a Your Hit\\n\\nParade - like program , Bandstand Revue ; Ward performed popular hits for four\\n\\nyears . Then she started a career of singing on demo and released recordings .\\n\\nOne 1962 session was singing the `` la la\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question:\\n\\nhow many beverly hills cops movies are there\\n\\nAnswer:\\n\\n<P> Beverly Hills Cop is a series of American action comedy films and an unaired television pilot\\n\\nbased on characters created by Daniel Petrie , Jr. and Danilo Bach . The films star Eddie Murphy\\n\\nas Axel Foley , a street - smart Detroit cop who travels to Beverly Hills , California to investigate\\n\\ncrimes , even though it is out of his jurisdiction . There , he meets Detective Billy Rosewood (\\n\\nJudge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and Lieutenant Andrew Bogomil ( Ronny\\n\\nCox ) . Ashton and Cox do not appear in Beverly Hills Cop III . Murphy , Reinhold , and Gil Hill ,\\n\\nwho plays Axel 's boss , Inspector Todd , are the only actors who appear in all three films . Harold\\n\\nFaltermeyer produced the now famous `` Axel F '' theme song heard throughout the series . The\\n\\nseries as a whole have been distributed by Paramount Pictures . The films have made a total of $\\n\\n735,534,503 at the worldwide box office . </P>\\n\\nContext:\\n\\nBeverly Hills Cop ( film series ) - wikipedia Beverly Hills Cop ( film series )\\n\\nJump to : navigation , search Beverly Hills Cop Directed by\\n\\nMartin Brest ( I ) Tony Scott ( II ) John Landis ( III ) Adil El Arbi ( IV\\n\\n) Bilall Fallah ( IV ) Produced by Jerry Bruckheimer ( I - II , IV )\\n\\nDon Simpson ( I - II ) Mace Neufeld ( III ) Robert Rehme ( III ) Eddie\\n\\nMurphy ( IV ) Screenplay by Daniel Petrie , Jr . ( I ) Larry\\n\\nFerguson ( II ) Warren Skaaren ( II ) Steven E. de Souza ( III ) Josh\\n\\nAppelbaum ( IV ) André Nemec ( IV ) Story by Danilo Bach ( I )\\n\\nDaniel Petrie , Jr . ( I ) Eddie Murphy ( II ) Robert D. Wachs ( II )\\n\\nSteven E. de Souza ( III ) Josh Appelbaum ( IV ) André Nemec ( IV )\\n\\nStarring Eddie Murphy Judge Reinhold John Ashton ( l - ll , lV ) Gil\\n\\nHill ( l - lll ) Ronny Cox ( I - II ) Brandon T. Jackson ( Unaired pilot )\\n\\nMusic by Harold Faltermeyer ( I - II ) Nile Rodgers ( III )\\n\\nCinematography Bruce Surtees ( I ) Jeffrey L. Kimball ( II ) Mac Ahlberg\\n\\n( III ) Dante Spinotti ( IV ) Edited by Billy Weber ( I - II )\\n\\nArthur Coburn ( I ) Chris Lebenzon ( II ) Michael Tronick ( II ) Dale\\n\\nBeldin ( III ) Production company Simpson / Bruckheimer ( I - II )\\n\\nEddie Murphy Productions ( I - III ) Distributed by Paramount Pictures\\n\\nRelease date 1984 - 1994 Running time 312 minutes Country United\\n\\nStates Language English Budget $85 million Box office $735.5\\n\\nmillion Beverly Hills Cop is a series of American action comedy films and an\\n\\nunaired television pilot based on characters created by Daniel Petrie , Jr. and\\n\\nDanilo Bach . The films star Eddie Murphy as Axel Foley , a street - smart\\n\\nDetroit cop who travels to Beverly Hills , California to investigate crimes ,\\n\\neven though it is out of his jurisdiction . There , he meets Detective Billy\\n\\nRosewood ( Judge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and\\n\\nLieu\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question:\\n\\ndale carnegie how to win and influence friends pdf\\n\\nAnswer:\\n\\nContext:\\n\\nHow to Win Friends and Influence people - wikipedia How to Win Friends and\\n\\nInfluence people Jump to : navigation , search For the Terrorvision album , see\\n\\nHow to Make Friends and Influence People . How to Win Friends and Influence\\n\\nPeople First edition , 11th printing ( February 1937 ) Author Dale\\n\\nCarnegie Country United States Language English Subject Self -\\n\\nhelp Genre Non-fiction Publisher Simon and Schuster ( 1936 )\\n\\nPublication date October 1936 Media type Print ( hardcover / paperback )\\n\\nPages 291 pp ISBN 1 - 4391 - 6734 - 6 OCLC 40137494 How to Win\\n\\nFriends and Influence People is a self - help book written by Dale Carnegie ,\\n\\npublished in 1936 . Over 30 million copies have been sold world - wide , making\\n\\nit one of the best - selling books of all time . In 2011 , it was number 19 on\\n\\nTime Magazine 's list of the 100 most influential books . In 1934 , Leon\\n\\nShimkin of the publishing firm Simon & Schuster took one of Carnegie 's 14 -\\n\\nweek courses ; afterward , Shimkin persuaded Carnegie to let a stenographer take\\n\\nnotes from the course to be revised for publication . The original book\\n\\ncontained colorful anecdotes and insightful wisdom , and gave instruction in\\n\\nhandling people , `` winning '' friends , bringing people to your way of\\n\\nthinking , being a great leader , and successfully navigating home life .\\n\\nCarnegie combined age - old truisms with the emerging field of psychology to\\n\\npresent a handbook in human relations which was interesting and accessible .\\n\\nEmphasizing using others ' egotistical tendencies to one 's advantage , Carnegie\\n\\nmaintained that success could be found by charm , appreciation , and personality\\n\\n. The book sold exceptionally well from the start , going through 17 editions in\\n\\nits first year alone . In 1981 , a revised edition containing updated language\\n\\nand anecdotes was released . The revised edition reduced the number of sections\\n\\nfrom six to four , eliminating sections on effectiv\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question:\\n\\nthe human tendency to mimic other peoples behavior is an example of\\n\\nAnswer:\\n\\n<P> Mirroring is the behaviour in which one person subconsciously imitates the gesture , speech\\n\\npattern , or attitude of another . Mirroring often occurs in social situations , particularly in the\\n\\ncompany of close friends or family . The concept often affects other individuals ' notions about\\n\\nthe individual that is exhibiting mirroring behaviors , which can lead to the individual building\\n\\nrapport with others . </P>\\n\\nContext:\\n\\nMirroring ( psychology ) - wikipedia Mirroring ( psychology ) This\\n\\narticle needs additional citations for verification . Please help improve this\\n\\narticle by adding citations to reliable sources . Unsourced material may be\\n\\nchallenged and removed . ( August 2015 ) ( Learn how and when to remove this\\n\\ntemplate message ) Mirroring in an argument . Mirroring is the behaviour in\\n\\nwhich one person subconsciously imitates the gesture , speech pattern , or\\n\\nattitude of another . Mirroring often occurs in social situations , particularly\\n\\nin the company of close friends or family . The concept often affects other\\n\\nindividuals ' notions about the individual that is exhibiting mirroring\\n\\nbehaviors , which can lead to the individual building rapport with others .\\n\\nMirroring is the subconscious replication of another person 's nonverbal signals\\n\\n. This concept takes place in everyday interactions , and often goes unnoticed\\n\\nby both the person enacting the mirroring behaviors as well as the individual\\n\\nwho is being mirrored . The activation of mirror neurons takes place within the\\n\\nindividual who begins to mirror another 's movements , and allows them a greater\\n\\nconnection and understanding with the individual who they are mirroring , as\\n\\nwell as allowing the individual who is being mirrored to feel a stronger\\n\\nconnection with the other individual . Mirroring is distinct from conscious\\n\\nimitation under the premise that while the latter is a conscious , typically\\n\\novert effort to copy another person , mirroring is subconsciously done during\\n\\nthe act and often goes unnoticed . The display of mirroring often begins as\\n\\nearly as infancy , as babies begin to mimic individuals around them and\\n\\nestablish connections with particular body movements . The ability to mimic\\n\\nanother person 's actions allows the infant to establish a sense of empathy and\\n\\nthus begin to understand another person 's emotions . The infant continues to\\n\\nestablish connections with other individual 's emotions and subsequent\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question:\\n\\nwho invented the use of electricity during the industrial revolution\\n\\nAnswer:\\n\\nContext:\\n\\nIndustrial Revolution - wikipedia Industrial Revolution Jump to : navigation ,\\n\\nsearch A Roberts loom in a weaving shed in 1835 . Textiles were the leading\\n\\nindustry of the Industrial Revolution and mechanized factories , powered by a\\n\\ncentral water wheel or steam engine , were the new workplace . The Industrial\\n\\nRevolution was the transition to new manufacturing processes in the period from\\n\\nabout 1760 to sometime between 1820 and 1840 . This transition included going\\n\\nfrom hand production methods to machines , new chemical manufacturing and iron\\n\\nproduction processes , the increasing use of steam power , the development of\\n\\nmachine tools and the rise of the factory system . Textiles were the dominant\\n\\nindustry of the Industrial Revolution in terms of employment , value of output\\n\\nand capital invested . The textile industry was also the first to use modern\\n\\nproduction methods . The Industrial Revolution began in Great Britain , and\\n\\nmany of the technological innovations were of British origin . By the mid-18th\\n\\ncentury Britain was the world 's leading commercial nation , controlling a\\n\\nglobal trading empire with colonies in North America and Africa , and with some\\n\\npolitical influence on the Indian subcontinent , through the activities of the\\n\\nEast India Company . The development of trade and the rise of business were\\n\\nmajor causes of the Industrial Revolution . The Industrial Revolution marks a\\n\\nmajor turning point in history ; almost every aspect of daily life was\\n\\ninfluenced in some way . In particular , average income and population began to\\n\\nexhibit unprecedented sustained growth . Some economists say that the major\\n\\nimpact of the Industrial Revolution was that the standard of living for the\\n\\ngeneral population began to increase consistently for the first time in history\\n\\n, although others have said that it did not begin to meaningfully improve until\\n\\nthe late 19th and 20th centuries . GDP per capita was broadly stable before\\n\\nthe Industrial Revolution and the emergence of\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question:\\n\\nhow is the head of the church of england\\n\\nAnswer:\\n\\n<P> The Church of England ( C of E ) is the Established Church of England . The Archbishop of\\n\\nCanterbury is the most senior cleric , although the monarch is the supreme governor . The Church\\n\\nof England is also the mother church of the international Anglican Communion . It traces its\\n\\nhistory to the Christian church recorded as existing in the Roman province of Britain by the third\\n\\ncentury , and to the 6th - century Gregorian mission to Kent led by Augustine of Canterbury .\\n\\n</P>\\n\\nContext:\\n\\nChurch of England - wikipedia Church of England `` C of E '' redirects here .\\n\\nFor other uses , see Council of Europe . Anglican state church of England\\n\\nChurch of England Abbreviation C of E Orientation Anglican\\n\\nPolity Episcopal Supreme Governor Queen Elizabeth II Primate\\n\\nArchbishop Justin Welby Associations Anglican Communion Porvoo Communion\\n\\nRegion England , Wales ( cross-border parishes ) Isle of Man Channel Islands\\n\\nContinental Europe Headquarters Church House , Westminster , England ,\\n\\nUnited Kingdom Separated from Roman Catholic Church ( 1534 )\\n\\nSeparations English Dissenters ( 1534 onwards ) Methodists ( 18th century )\\n\\nPlymouth Brethren ( 1820s ) Free Church of England ( 1844 ) Members 25\\n\\nmillion Official website churchofengland.org Part of a series on\\n\\nAnglicanism Theology ( show ) Christian theology Anglican doctrine\\n\\nThirty - nine Articles Books of Homilies Caroline Divines Lambeth Quadrilateral\\n\\nEpiscopal polity Sacraments Mary Ministry and worship ( show ) Ministry\\n\\nMusic Eucharist King James Version ( Book of Common Prayer ) Liturgical year\\n\\nChurchmanship ( High , Low , Central , Broad ) Monasticism Saints\\n\\nChristianity ( show ) Jesus Christ Paul Christian Church First seven Ecumenical\\n\\nCouncils Background and history ( show ) Celtic Christianity Augustine of\\n\\nCanterbury Bede Medieval cathedral architecture Henry VIII English Reformation\\n\\nThomas Cranmer Dissolution of Monasteries Church of England Edward VI Elizabeth\\n\\nI Parker Hooker James I Charles I Laud Nonjuring schism Anglo - Catholicism\\n\\nOxford Movement Anglican Communion ( show ) Anglican Communion history\\n\\nArchbishop of Canterbury Anglican Communion Primates ' Meetings Lambeth\\n\\nConference Bishops Anglican Consultative Council Ecumenism Ordination of women\\n\\nWindsor Report Continuing Anglicanism ( show ) Anglican realignment\\n\\nBartonville Agreement Congress of St. Louis North American Anglican Conference\\n\\nAnglicanism portal\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content='Question:\\n\\nwho holds the most women\\'s wimbledon titles\\n\\nAnswer:\\n\\n<Table> Wimbledon Ladies \\' Singles Champions <Tr> <Th> Location </Th> <Td> London\\n\\nUnited Kingdom </Td> </Tr> <Tr> <Th> Venue </Th> <Td> AELTC </Td> </Tr> <Tr> <Th>\\n\\nGoverning body </Th> <Td> AELTC / LTA </Td> </Tr> <Tr> <Th> Created </Th> <Td> 1884 (\\n\\nestablished ) Open Era : 1968 ( 51 editions ) </Td> </Tr> <Tr> <Th> Surface </Th> <Td>\\n\\nGrass ( 1884 -- Present ) </Td> </Tr> <Tr> <Th> Prize money </Th> <Td> £ 2,000,000 ( 2016\\n\\n) </Td> </Tr> <Tr> <Th> Trophy </Th> <Td> Venus Rosewater Dish </Td> </Tr> <Tr> <Th>\\n\\nWebsite </Th> <Td> REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html </Td>\\n\\n</Tr> <Tr> <Th colspan=\"2\"> Most titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 7\\n\\n: Dorothea Lambert Chambers ( challenge round ) 8 : Helen Wills Moody ( regular ) </Td> </Tr>\\n\\n<Tr> <Th> Open era </Th> <Td> 9 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\">\\n\\nMost consecutive titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 3 : Lottie Dod\\n\\nSuzanne Lenglen ( challenge round ) 4 : Helen Wills Moody ( regular ) </Td> </Tr> <Tr> <Th>\\n\\nOpen era </Th> <Td> 6 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\"> Current\\n\\nchampion </Th> </Tr> <Tr> <Td colspan=\"2\"> Angelique Kerber ( 1st singles title ) </Td>\\n\\n</Tr> </Table>\\n\\nContext:\\n\\nList of Wimbledon Ladies \\' Singles champions - wikipedia List of Wimbledon\\n\\nLadies \\' Singles champions Wimbledon Ladies \\' Singles Champions Location\\n\\nLondon United Kingdom Venue AELTC Governing body AELTC / LTA\\n\\nCreated 1884 ( established ) Open Era : 1968 ( 51 editions ) Surface\\n\\nGrass ( 1884 -- Present ) Prize money £ 2,000,000 ( 2016 ) Trophy\\n\\nVenus Rosewater Dish Website\\n\\REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html Most\\n\\ntitles Amateur era 7 : Dorothea Lambert Chambers ( challenge round ) 8 :\\n\\nHelen Wills Moody ( regular ) Open era 9 : Martina Navratilova Most\\n\\nconsecutive titles Amateur era 3 : Lottie Dod Suzanne Lenglen ( challenge\\n\\nround ) 4 : Helen Wills Moody ( regular ) Open era 6 : Martina Navratilova\\n\\nCurrent champion Angelique Kerber ( 1st singles title ) The\\n\\nChampionships , Wimbledon is an annual tennis tournament first contested in 1877\\n\\nand played on outdoor grass courts at the All England Lawn Tennis and Croquet\\n\\nClub ( AELTC ) in the Wimbledon suburb of London , United Kingdom . The Ladies \\'\\n\\nSingles was started in 1884 . Contents 1 History 2 Champions 2.1\\n\\nAmateur Era 2.2 Open Era 3 Statistics 3.1 Multiple champions 3.2\\n\\nChampionships by country 4 See also 5 Notes 6 References 7 External\\n\\nlinks History ( edit ) Wimbledon has historically been played in the last\\n\\nweek of June and the first week of July ( though changed to the first two weeks\\n\\nof July in 2017 ) , and has been chronologically the third of the four Grand\\n\\nSlam tournaments of the tennis season since 1987 . The event was not held from\\n\\n1915 to 1918 because of World War I and again from 1940 to 1945 because of World\\n\\nWar II . The Ladies \\' Singles \\' rules have undergone several changes since the\\n\\nfirst edition . From 1886 until 1921 , the event started with a knockout phase ,\\n\\nthe All Comers \\' Singles , whose winner then faced the defending champion in a\\n\\nchallenge round . The All', metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content=\"Question:\\n\\nhow many goals scored ronaldo in his career\\n\\nAnswer:\\n\\n<P> Cristiano Ronaldo dos Santos Aveiro GOIH ComM ( European Portuguese : ( kitjnu\\n\\nonadu ) ; born 5 February 1985 ) is a Portuguese professional footballer who plays as a forward\\n\\nfor Italian club Juventus and the Portugal national team . Often considered the best player in the\\n\\nworld and regarded by many as one of the greatest players of all time , Ronaldo has a record -\\n\\ntying five Ballon d'Or awards , the most for a European player , and is the first player to win four\\n\\nEuropean Golden Shoes . He has won 26 trophies in his career , including five league titles , five\\n\\nUEFA Champions League titles and one UEFA European Championship . A prolific goalscorer ,\\n\\nRonaldo holds the records for most official goals scored in Europe 's top - five leagues ( 395 ) , the\\n\\nUEFA Champions League ( 120 ) , the UEFA European Championship ( 9 ) , as well as those for\\n\\nmost assists in the UEFA Champions League ( 34 ) and the UEFA European Championship ( 6 ) .\\n\\nHe has scored over 670 senior career goals for club and country . </P>\\n\\nContext:\\n\\nCristiano Ronaldo - wikipedia Cristiano Ronaldo Portuguese footballer For\\n\\nthe Brazilian footballer , see Ronaldo ( Brazilian footballer ) . This name uses\\n\\nPortuguese naming customs . The first or maternal family name is Santos and the\\n\\nsecond or paternal family name is Aveiro . Cristiano Ronaldo Cristiano\\n\\nRonaldo with Portugal at the 2018 FIFA World Cup Full name Cristiano\\n\\nRonaldo dos Santos Aveiro Date of birth ( 1985 - 02 - 05 ) 5 February 1985\\n\\n( age 33 ) Place of birth Funchal , Madeira , Portugal Height 1.85 m\\n\\n( 6 ft 1 in ) Playing position Forward Club information Current\\n\\nteam Juventus Number 7 Youth career 1992 -- 1995 Andorinha\\n\\n1995 -- 1997 Nacional 1997 -- 2002 Sporting CP Senior career *\\n\\nYears Team Apps ( Gls ) 2002 -- 2003 Sporting CP B ( 0 )\\n\\n2002 -- 2003 Sporting CP 25 ( 3 ) 2003 -- 2009 Manchester United\\n\\n196 ( 84 ) 2009 -- 2018 Real Madrid 292 ( 311 ) 2018 --\\n\\nJuventus ( 0 ) National team Portugal U15 9 ( 7 ) 2001 --\\n\\n2002 Portugal U17 7 ( 5 ) 2003 Portugal U20 5 ( 1 ) 2002 --\\n\\n2003 Portugal U21 10 ( 3 ) Portugal U23 ( 2 ) 2003 --\\n\\nPortugal 154 ( 85 ) Honours ( show ) Men 's football\\n\\nRepresenting Portugal UEFA European Championship 2004 Portugal\\n\\n2012 Poland & Ukraine 2016 France FIFA Confederations Cup\\n\\n2017 Russia * Senior club appearances and goals counted for the\\n\\ndomestic league only and correct as of 25 August 2018 National team caps and\\n\\ngoals correct as of 30 June 2018 This article is part of a series\\n\\nabout Cristiano Ronaldo Portuguese professional footballer\\n\\nInternational goals Career achievements Comparisons to Lionel Messi\\n\\nNamesakes Cristiano Ronaldo Campus Futebol Cristiano Ronaldo International\\n\\nAirport Galaxy CR7 Museu CR7 Films Cristiano Ronaldo : The World at\\n\\nHis Feet Ronaldo\", metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the orange stuff on my sushi\\n\\nAnswer:\\n\\n<P> The eggs are small , ranging from 0.5 to 0.8 mm . For comparison , tobiko is larger than\\n\\nmasago ( capelin roe ) , but smaller than ikura ( salmon roe ) . Natural tobiko has a red - orange\\n\\ncolor , a mild smoky or salty taste , and a crunchy texture . </P>\\n\\nContext:\\n\\nTobiko - wikipedia Tobiko Jump to : navigation , search This article\\n\\nneeds additional citations for verification . Please help improve this article\\n\\nby adding citations to reliable sources . Unsourced material may be challenged\\n\\nand removed . ( February 2013 ) ( Learn how and when to remove this template\\n\\nmessage ) Tobiko in varying colors , served as sushi Tobiko ( ) is the\\n\\nJapanese word for flying fish roe . It is most widely known for its use in\\n\\ncreating certain types of sushi . The eggs are small , ranging from 0.5 to 0.8\\n\\nmm . For comparison , tobiko is larger than masago ( capelin roe ) , but smaller\\n\\nthan ikura ( salmon roe ) . Natural tobiko has a red - orange color , a mild\\n\\nsmoky or salty taste , and a crunchy texture . Tobiko , shown in its natural\\n\\ncolor , topping grilled Albacore tuna Sometimes tobiko is colored to change its\\n\\nappearance , other natural ingredients are used to accomplish the change , such\\n\\nas squid ink to make it black , yuzu to make it pale orange ( almost yellow ) ,\\n\\nor even wasabi to make it green and spicy . Sometimes a serving of tobiko\\n\\ncontains several pieces , each having a different color . When prepared as\\n\\nsashimi , it may be presented on avocado halves or wedges . Tobiko is used in\\n\\nthe creation of many other Japanese dishes . Often , tobiko is used as an\\n\\ningredient in California rolls . Frequently , masago ( capelin or smelt roe )\\n\\nis substituted for tobiko , due to its similar appearance and flavor . The\\n\\nsmaller size of the individual eggs is apparent to the experienced diner ,\\n\\nhowever . References ( edit ) Wikimedia Commons has media related to\\n\\nTobiko . Jump up ^ `` Tobiko vs Masago Difference '' . Expert answer\\n\\nQuestion. 2016 - 11 - 16 . Retrieved 2016 - 11 - 16 . Jump up ^ Food Republic\\n\\nhttp://REMOVED_SECRET/2013/04/19/what-tobiko-and-whats-different-colors .\\n\\nRetrieved 18 October 2014 . Missing or empty title = ( help ) Sushi\\n\\nHistory of sushi List of sushi and sashimi ingr\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question:\\n\\nwho was the first president to get his picture taken\\n\\nAnswer:\\n\\nContext:\\n\\nList of United States Presidential Firsts - wikipedia List of United States\\n\\nPresidential Firsts Jump to : navigation , search This article needs\\n\\nadditional citations for verification . Please help improve this article by\\n\\nadding citations to reliable sources . Unsourced material may be challenged and\\n\\nremoved . ( January 2017 ) ( Learn how and when to remove this template message\\n\\n) This list lists achievements and distinctions of various Presidents of the\\n\\nUnited States . It includes distinctions achieved in their earlier life and\\n\\npost-presidencies . Due to some confusion surrounding sovereignty of nations\\n\\nduring presidential visits , only nations that were independent , sovereign , or\\n\\nrecognized by the United States during the presidency are listed here as a\\n\\nprecedent . Contents ( hide ) 1 George Washington ( 1789 - 1797 ) 2 John\\n\\nAdams ( 1797 - 1801 ) 3 Thomas Jefferson ( 1801 - 1809 ) 4 James Madison (\\n\\n1809 - 1817 ) 5 James Monroe ( 1817 - 1825 ) 6 John Quincy Adams ( 1825 -\\n\\n1829 ) 7 Andrew Jackson ( 1829 - 1837 ) 8 Martin Van Buren ( 1837 - 1841 )\\n\\n9 William Henry Harrison ( 1841 ) 10 John Tyler ( 1841 - 1845 ) 11 James K.\\n\\nPolk ( 1845 - 1849 ) 12 Zachary Taylor ( 1849 - 1850 ) 13 Millard Fillmore (\\n\\n1850 - 1853 ) 14 Franklin Pierce ( 1853 - 1857 ) 15 James Buchanan ( 1857 -\\n\\n1861 ) 16 Abraham Lincoln ( 1861 - 1865 ) 17 Andrew Johnson ( 1865 - 1869 )\\n\\n18 Ulysses S. Grant ( 1869 - 1877 ) 19 Rutherford B. Hayes ( 1877 - 1881 )\\n\\n20 James A. Garfield ( 1881 ) 21 Chester A. Arthur ( 1881 - 1885 ) 22 Grover\\n\\nCleveland ( 1885 - 1889 ; 1893 - 1897 ) 23 Benjamin Harrison ( 1889 - 1893 )\\n\\n24 William McKinley ( 1897 - 1901 ) 25 Theodore Roosevelt ( 1901 - 1909 ) 26\\n\\nWilliam Howard Taft ( 1909 - 1913 ) 27 Woodrow Wilson ( 1913 - 1921 ) 28\\n\\nWarren G. Harding ( 1921 - 1923 ) 29 Calvin Coolidge ( 1923 - 1929 ) 30\\n\\nHerbert Hoover ( 1929 - 1933 ) 31 Franklin D. Roosevelt ( 1933 - 1945 ) 32\\n\\nHarry S. Truman ( 1945 - 1953 ) 3', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the moral of the ant and the grasshopper\\n\\nAnswer:\\n\\n<P> The story has been used to teach the virtues of hard work and the perils of improvidence .\\n\\nSome versions state a moral at the end along the lines of `` Idleness brings want '' , `` To work\\n\\ntoday is to eat tomorrow '' , `` Beware of winter before it comes '' . In La Fontaine 's Fables no\\n\\nfinal judgment is made , although it has been argued that the author is there making sly fun of\\n\\nhis own notoriously improvident ways . But the point of view in most retellings of the fable is\\n\\nsupportive of the ant . It is also influenced by the commendation in the biblical Book of Proverbs ,\\n\\nwhich mentions the ant twice . The first proverb admonishes , `` Go to the ant , you sluggard !\\n\\nConsider her ways and be wise , which having no captain , overseer or ruler , provides her\\n\\nsupplies in the summer , and gathers her food in the harvest '' ( 6.6 - 9 ) . Later , in a parallel\\n\\nsaying of Agur , the insects figure among the ' four things that are little upon the earth but they\\n\\nare exceeding wise . The ants are a people not strong , yet they provide their food in the summer\\n\\n. ' ( 30.24 - 5 ) </P>\\n\\nContext:\\n\\nThe ant and the grasshopper - wikipedia The ant and the grasshopper Jump to :\\n\\nnavigation , search Coloured print of La Fontaine 's fable by Jean - Baptiste\\n\\nOudry The Ant and the Grasshopper , alternatively titled The Grasshopper and\\n\\nthe Ant ( or Ants ) , is one of Aesop 's Fables , numbered 373 in the Perry\\n\\nIndex . The fable describes how a hungry grasshopper begs for food from an ant\\n\\nwhen winter comes and is refused . The situation sums up moral lessons about the\\n\\nvirtues of hard work and planning for the future . Even in Classical times ,\\n\\nhowever , the advice was mistrusted and an alternative story represented the ant\\n\\n's industry as mean and self - serving . Jean de la Fontaine 's delicately\\n\\nironical retelling in French later widened the debate to cover the themes of\\n\\ncompassion and charity . Since the 18th century the grasshopper has been seen as\\n\\nthe type of the artist and the question of the place of culture in society has\\n\\nalso been included . Argument over the fable 's ambivalent meaning has generally\\n\\nbeen conducted through adaptation or reinterpretation of the fable in literature\\n\\n, arts and music . Contents ( hide ) 1 Fable and counter-fable 2 In art\\n\\n3 Later adaptations 4 Musical settings 5 Film and television treatments 6\\n\\nMoral and artistic debate 7 See also 8 References 9 External links\\n\\nFable and counter-fable ( edit ) The fable concerns a grasshopper ( in the\\n\\noriginal , a cicada ) that has spent the summer singing while the ant ( or ants\\n\\nin some versions ) worked to store up food for winter . When that season arrives\\n\\n, the grasshopper finds itself dying of hunger and begs the ant for food .\\n\\nHowever , the ant rebukes its idleness and tells it to dance the winter away now\\n\\n. Versions of the fable are found in the verse collections of Babrius ( 140 )\\n\\nand Avianus ( 34 ) , and in several prose collections including those attributed\\n\\nto Syntipas and Aphthonius of Antioch . The fable 's Greek original cicada is\\n\\nkept in the Latin and Romance\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content=\"Question:\\n\\nwhich city has the highest hiv rate in south africa\\n\\nAnswer:\\n\\nContext:\\n\\nHIV / AIDS in South Africa - Wikipedia HIV / AIDS in South Africa This\\n\\narticle needs to be updated . Please update this article to reflect recent\\n\\nevents or newly available information . ( July 2018 ) Estimated HIV\\n\\nprevalence among adults aged 15 - 49 by country in 2007 HIV / AIDS is the most\\n\\nserious health concern in South Africa . The country has the fourth - highest\\n\\nadult HIV prevalence rate in the world , according to the 2016 United Nations\\n\\nstatistics . According to a UNAids dataset sourced from the World Bank , in\\n\\n2016 the HIV prevalence rate for adults aged 15 to 49 was 27 % in Swaziland , 25\\n\\n% in Lesotho , 25 % in Botswana and 19 % in South Africa . Contents 1\\n\\nUnderstanding HIV prevalence 2 Latest data on HIV prevalence in South Africa\\n\\n3 Other statistics 3.1 By race 3.2 By gender 3.3 By pregnant women 3.4\\n\\nBy age 3.5 By province 4 Awareness campaigns 5 Co-infection with\\n\\ntuberculosis 6 History 6.1 1990 6.2 1993 6.3 1995 6.4 1996 6.5 1997\\n\\n6.6 1999 6.7 2000 6.8 2001 6.9 2002 7 Demographics 8 Aids denialism\\n\\nunder Thabo Mbeki 8.1 2000 8.2 2001 8.3 2003 8.4 2006 8.5 2007 9\\n\\nRole of the media in South Africa 's epidemic 10 See also 11 References 12\\n\\nFurther reading 13 External links Understanding HIV prevalence ( edit )\\n\\nHIV prevalence does not indicate that a country has an AIDS crisis , as HIV and\\n\\nAIDS are separate conditions . HIV prevalence , instead , indicates that people\\n\\nremain alive , despite the infection . South Africa has the largest HIV\\n\\ntreatment programme in the world . With the correct medication , HIV is a\\n\\nmanageable chronic condition , like diabetes or hypertension . A population with\\n\\na larger proportion of diabetics , means more people are receiving treatment for\\n\\nthe condition . Hence , a population with a larger proportion of HIV - positive\\n\\npeople , means more people are receiving anti-retroviral treatment . World\\n\\nBank Open Data explains the data it publishes on HI\", metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question:\\n\\nnow that's what i call music 17 songs\\n\\nAnswer:\\n\\nContext:\\n\\nNow That 's What I Call Music 17 ( UK series ) - wikipedia Now That 's What I\\n\\nCall Music 17 ( UK series ) Jump to : navigation , search This article\\n\\ndoes not cite any sources . Please help improve this article by adding citations\\n\\nto reliable sources . Unsourced material may be challenged and removed . (\\n\\nDecember 2009 ) ( Learn how and when to remove this template message ) This\\n\\narticle describes the 17th album in the UK Now ! series . It should not be\\n\\nconfused with identically - numbered albums from other Now ! series . For more\\n\\ninformation , see Now That 's What I Call Music ! 17 and Now That 's What I Call\\n\\nMusic ! discography . Now That 's What I Call Music 17 Compilation\\n\\nalbum by various artists Released 23 April 1990 Genre Pop Length\\n\\n2 : 05 : 00 Label Virgin / EMI / Polygram Series chronology Now\\n\\nThat 's What I Call Music 16 ( 1989 ) Now That 's What I Call Music 17 ( 1990\\n\\n) Now ! That 's What I Call Music 18 ( 1990 ) Now That 's What I Call\\n\\nMusic 17 or Now 17 is the 17th edition of the Now ! series in the United Kingdom\\n\\nand was released in April 1990 on vinyl , audio cassette , compact disc and VHS\\n\\n. Track listing ( edit ) CD / record / tape 1 No . Title Artist (\\n\\ns ) Length 1 . `` Blue Savannah '' Erasure 2 . `` Better World\\n\\n'' Rebel MC 3 . `` Opposites Attract '' Paula Abdul 4 . ``\\n\\nDub Be Good to Me '' Beats International 5 . `` Kingston Town ''\\n\\nUB40 6 . `` Strawberry Fields Forever '' Candy Flip 7 . `` I\\n\\nDo n't Wanna Lose You '' Tina Turner 8 . `` I Wish It Would Rain Down\\n\\n'' Phil Collins 9 . `` Step On '' Happy Mondays 10 . ``\\n\\nLoaded '' Primal Scream 11 . `` Enjoy the Silence '' Depeche Mode\\n\\n12 . `` Real Real Real '' Jesus Jones 13 . `` This Is How It Feels\\n\\n'' Inspiral Carpets 14 . `` Shine On '' The House of Love 15 .\\n\\n`` From Out of Nowhere ''\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question:\\n\\nwhen does model code of conduct come into force\\n\\nAnswer:\\n\\n<P> Election Commission of India 's Model Code of Conduct is a set of guidelines issued by the\\n\\nElection Commission of India for conduct of political parties and candidates during elections\\n\\nmainly with respect to speeches , polling day , polling booths , election manifestos , processions\\n\\nand general conduct . These set of norms has been evolved with the consensus of political parties\\n\\nwho have consented to abide by the principles embodied in the said code in its letter and spirit.\\n\\nThe Model Code of Conduct comes into force immediately on announcement of the election\\n\\nschedule by the commission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example , politicians should not\\n\\nmake hate speeches , putting one community against another or make promises about new\\n\\nprojects that may sway a voter . </P>\\n\\nContext:\\n\\nElection Commission of India 's Model code of Conduct - wikipedia Election\\n\\nCommission of India 's Model code of Conduct Jump to : navigation , search\\n\\nThis article needs more links to other articles to help integrate it into the\\n\\nencyclopedia . Please help improve this article by adding links that are\\n\\nrelevant to the context within the existing text . ( April 2014 ) ( Learn how\\n\\nand when to remove this template message ) Election Commission of India 's\\n\\nModel Code of Conduct is a set of guidelines issued by the Election Commission\\n\\nof India for conduct of political parties and candidates during elections mainly\\n\\nwith respect to speeches , polling day , polling booths , election manifestos ,\\n\\nprocessions and general conduct . These set of norms has been evolved with the\\n\\nconsensus of political parties who have consented to abide by the principles\\n\\nembodied in the said code in its letter and spirit. The Model Code of Conduct\\n\\ncomes into force immediately on announcement of the election schedule by the\\n\\ncommission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example ,\\n\\npoliticians should not make hate speeches , putting one community against\\n\\nanother or make promises about new projects that may sway a voter . For the\\n\\n2014 general election the code came into force on 5 March 2014 when the\\n\\nCommission announced the dates and remains in force till the end of the\\n\\nelectoral process . `` The Model Code of Conduct is crucial to make sure a\\n\\nlevel playing field among various contenders in the poll fray , '' said the\\n\\nChief Election Commissioner V.S. Sampath at the press conference . Main points\\n\\n( edit ) The main points of the code are : Government bodies are not to\\n\\nparticipate in any new recruitment process during the electoral process . The\\n\\ncontesting candidates and the campaigners must respect the home life of their\\n\\nrivals and should not disturb them by holding road shows or demonstrations\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content=\"Question:\\n\\nwhere is the greatest royal rumble taking place\\n\\nAnswer:\\n\\n<P> Greatest Royal Rumble was a professional wrestling pay - per - view event and WWE\\n\\nNetwork event promoted by WWE for their Raw and SmackDown brands . The event was held on\\n\\nApril 27 , 2018 at the King Abdullah Sports City 's King Abdullah International Stadium in Jeddah ,\\n\\nSaudi Arabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in the United\\n\\nStates at noon EDT , with a pre-show starting at 11 a.m. EDT . At the event , all men 's main\\n\\nroster championships were defended , in addition to a 50 - man Royal Rumble match . </P>\\n\\nContext:\\n\\nWWE Greatest Royal Rumble - Wikipedia WWE Greatest Royal Rumble Jump to :\\n\\nnavigation , search Greatest Royal Rumble Promotional poster featuring\\n\\nvarious WWE wrestlers Theme song ( s ) `` When Legends Rise '' by Godsmack\\n\\nInformation Promotion WWE Brand ( s ) Raw SmackDown Sponsor ( s\\n\\n) Saudi General Sports Authority Date April 27 , 2018 Attendance\\n\\n60,000 Venue King Abdullah International Stadium City Jeddah , Saudi\\n\\nArabia WWE Network event chronology WrestleMania 34 Greatest Royal\\n\\nRumble Backlash ( 2018 ) Greatest Royal Rumble was a professional\\n\\nwrestling pay - per - view event and WWE Network event promoted by WWE for their\\n\\nRaw and SmackDown brands . The event was held on April 27 , 2018 at the King\\n\\nAbdullah Sports City 's King Abdullah International Stadium in Jeddah , Saudi\\n\\nArabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in\\n\\nthe United States at noon EDT , with a pre-show starting at 11 a.m. EDT . At the\\n\\nevent , all men 's main roster championships were defended , in addition to a 50\\n\\nman Royal Rumble match . The card featured ten matches . In the main event ,\\n\\nBraun Strowman won the titular Greatest Royal Rumble match to become the\\n\\ninaugural Greatest Royal Rumble Champion . In the penultimate match , Brock\\n\\nLesnar retained the Universal Championship in a steel cage match against Roman\\n\\nReigns . On the undercard , the WWE Championship match between AJ Styles and\\n\\nShinsuke Nakamura resulted in a double countout , The Undertaker defeated Rusev\\n\\nin a casket match , and John Cena defeated Triple H in the opening match .\\n\\nContents ( hide ) 1 Production 1.1 Background 1.2 Storylines 2 Event\\n\\n2.1 Preliminary matches 2.2 Main event 3 Controversy 4 Results 4.1 Tag\\n\\nTeam Eliminator bracket 4.2 Greatest Royal Rumble match entrances and\\n\\neliminations 5 WWE Greatest Royal Rumble Championship 5.1 History 5.2\\n\\nChampionship belt design 5.3 Reigns 6\", metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question:\\n\\nwho died from the band faith no more\\n\\nAnswer:\\n\\n<P> Former Faith No More singer Chuck Mosley died on November 9 , 2017 , due to `` the\\n\\ndisease of addiction . '' He was 57 years old . </P>\\n\\nContext:\\n\\nFaith No More - Wikipedia Faith No More Jump to : navigation , search Faith\\n\\nNo More Faith No More performing in Portugal in 2009 Background\\n\\ninformation Also known as Faith No Man Sharp Young Men Origin\\n\\nSan Francisco , California , United States Genres Alternative metal\\n\\nfunk metal experimental rock Years active 1979 -- 1998 2009 --\\n\\npresent Labels Slash London Mordam Reclamation ! Ipecac\\n\\nAssociated acts Mr. Bungle Pop - O - Pies Website fnm.com\\n\\nMembers Mike Bordin Roddy Bottum Billy Gould Mike Patton Jon Hudson\\n\\nPast members List of Faith No More band members Faith No More ( sometimes\\n\\nabbreviated as FNM ) is an American rock band from San Francisco , California ,\\n\\nformed in 1979 . Before settling on their current name in 1982 , the band\\n\\nperformed under the names Sharp Young Men and later Faith No Man . Bassist Billy\\n\\nGould and drummer Mike Bordin are the longest remaining members of the band ,\\n\\nhaving been involved with Faith No More since its inception . The band underwent\\n\\nseveral lineup changes early in their career , along with some major changes\\n\\nlater on . The current lineup of Faith No More consists of Gould , Bordin ,\\n\\nkeyboardist / rhythm guitarist Roddy Bottum , lead guitarist Jon Hudson and\\n\\nvocalist / lyricist Mike Patton . After releasing six studio albums ,\\n\\nincluding their best - selling records The Real Thing ( 1989 ) and Angel Dust (\\n\\n1992 ) , Faith No More officially announced their breakup on April 20 , 1998 .\\n\\nThey have since reunited , embarked on The Second Coming Tour from 2009 to 2012\\n\\n, and released their seventh studio album , Sol Invictus , in May 2015 .\\n\\nContents ( hide ) 1 History 1.1 Early days ( 1979 -- 1984 ) 1.2 We Care a\\n\\nLot and Introduce Yourself ( 1985 -- 1988 ) 1.3 Mike Patton joins and The Real\\n\\nThing ( 1989 -- 1991 ) 1.4 Angel Dust ( 1992 -- 1994 ) 1.5 King for a Day\\n\\n... , Album of the Year and break - up ( 1995 -- 1998 ) 1.6 R\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content=\"Question:\\n\\nwhat is sauce for the goose is sauce for the gander examples\\n\\nAnswer:\\n\\nContext:\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander - Wikipedia\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander This page\\n\\nis an essay . It contains the advice or opinions of one or more Wikipedia\\n\\ncontributors . This page is not one of Wikipedia 's policies or guidelines , as\\n\\nit has not been thoroughly vetted by the community . Some essays represent\\n\\nwidespread norms ; others only represent minority viewpoints . Shortcuts WP\\n\\n: SAUCE WP : GOOSE WP : GANDER This page in a nutshell : This phrase\\n\\nis employed to expose holding forth a `` double standard . '' If some kind of\\n\\nbehavior is wrong , it 's probably wrong for both sides , not just one . Do n't\\n\\ndo it yourself either . There 's an old saying , `` What is sauce for the\\n\\ngoose is sauce for the gander . '' This meshes well with the Golden Rule , or\\n\\nethic of reciprocity , which is a key moral principle in many religions and\\n\\nphilosophies , and is often stated as `` Do unto others as you wish to be done\\n\\nfor you '' , or conversely , `` Do n't do unto others what you would not wish to\\n\\nbe done to you . '' Tasty sauces to enjoy on your stir - fried wikipedia . But\\n\\nare they reliable sauces ? Look up sauce for the goose in Wiktionary , the\\n\\nfree dictionary . Unfortunately , when the infighting here in Wikipedia gets\\n\\nheated , participants often forget this principle and do unto their opponents\\n\\nthings that would not be fair to be done unto them , and sometimes add insult to\\n\\ninjury by crying `` fowl '' if their opponents do in fact raise similar\\n\\nobjections to their own actions ( and those of their friends ) to the ones they\\n\\nraised against the opponents in the first place . These `` wars '' can easily\\n\\nturn both parties into hypocrites . Some of the sorts of things that violate\\n\\nthis principle include : Trying to squelch or discredit an opposing viewpoint\\n\\nby associating it with a banned editor who espoused something similar , when in\\n\\nfact some of your own viewpoints a\", metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content=\"Question:\\n\\nwho was the gospel of john written to\\n\\nAnswer:\\n\\nContext:\\n\\nGospel of John - wikipedia Gospel of John Books of the New Testament\\n\\nGospels Matthew Mark Luke John Acts Acts of the Apostles\\n\\nEpistles Romans 1 Corinthians 2 Corinthians Galatians Ephesians Philippians\\n\\nColossians 1 Thessalonians 2 Thessalonians 1 Timothy 2 Timothy Titus Philemon\\n\\nHebrews James 1 Peter 2 Peter 1 John 2 John 3 John Jude Apocalypse\\n\\nRevelation New Testament manuscripts This article is about\\n\\nthe book in the New Testament . For the film , see The Gospel of John ( film ) .\\n\\nNot to be confused with First Epistle of John . Part of a series of articles\\n\\non John in the Bible Johannine literature Gospel Epistles\\n\\nFirst Second Third Revelation Events Authorship Apostle\\n\\nBeloved disciple Evangelist Patmos Presbyter Related literature\\n\\nApocryphon Acts Signs Gospel See also Johannine Christianity\\n\\nLogos Holy Spirit in Johannine literature John 's vision of the Son of Man\\n\\nNew Testament people named John The Gospel According to John\\n\\nis the fourth of the canonical gospels . The work is anonymous , although it\\n\\nidentifies an unnamed `` disciple whom Jesus loved '' as the source of its\\n\\ntraditions . It is closely related in style and content to the three Johannine\\n\\nepistles , and most scholars treat the four books , along with the Book of\\n\\nRevelation , as a single corpus of Johannine literature , albeit not from the\\n\\nsame author . C.K. Barrett , and later Raymond E. Brown , suggested that a\\n\\ntradition developed around the `` Johannine Community '' , and that this\\n\\ntradition gave rise to the gospel . The discovery of a large number of papyrus\\n\\nfragments of manuscripts with Johannine themes has led more scholars to\\n\\nrecognize that the texts were among the most influential in the early Church .\\n\\nThe discourses contained in this gospel seem to be concerned with issues of the\\n\\nchurch -- synagogue debate at the time of composition . It is no\", metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content='Question:\\n\\nfor an asset to be considered money it must be\\n\\nAnswer:\\n\\nContext:\\n\\nAsset - wikipedia Asset This article is about the finance definition . For\\n\\nother uses , see Asset ( disambiguation ) . Part of a series on\\n\\nAccounting Historical cost Constant purchasing power Management\\n\\nTax Major types ( show ) Audit Budget Cost Forensic Financial\\n\\nFund Governmental Management Social Tax Key concepts ( show )\\n\\nAccounting period Accrual Constant purchasing power Economic entity Fair\\n\\nvalue Going concern Historical cost Matching principle Materiality\\n\\nRevenue recognition Unit of account Selected accounts ( show ) Assets\\n\\nCash Cost of goods sold Depreciation / Amortization Equity Expenses\\n\\nGoodwill Liabilities Profit Revenue Accounting standards ( show )\\n\\nGenerally - accepted principles Generally - accepted auditing standards\\n\\nConvergence International Financial Reporting Standards International\\n\\nStandards on Auditing Management Accounting Principles Financial\\n\\nstatements ( show ) Annual report Balance sheet Cash - flow Equity\\n\\nIncome Management discussion Notes to the financial statements\\n\\nBookkeeping ( show ) Bank reconciliation Debits and credits Double - entry\\n\\nsystem FIFO and LIFO Journal Ledger / General ledger T accounts Trial\\n\\nbalance Auditing ( show ) Financial Internal Firms Report\\n\\nPeople and organizations ( show ) Accountants Accounting organizations\\n\\nLuca Pacioli Development ( show ) History Research Positive\\n\\naccounting Sarbanes -- Oxley Act Business portal In\\n\\nfinancial accounting , an asset is an economic resource . Anything tangible or\\n\\nintangible that can be owned or controlled to produce value and that is held by\\n\\na company to produce positive economic value is an asset . Simply stated ,\\n\\nassets represent value of ownership that can be converted into cash ( although\\n\\ncash itself is also considered an asset ) . The balance sheet of a firm\\n\\nrecords the monetary value o', metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content='Question:\\n\\nhow many district in punjab and also write its name\\n\\nAnswer:\\n\\nContext:\\n\\nPunjab , India - Wikipedia Punjab , India This article is about a state of\\n\\nIndia . For a geographical region , see Punjab . For other uses of the name ,\\n\\nsee Punjab ( disambiguation ) . State in India Punjab State The\\n\\nonly state in India with a majority Sikh population , Punjab contains the Golden\\n\\nTemple , amongst the most important sites in Sikhism Seal Location\\n\\nof Punjab in India Coordinates ( Chandigarh ) : 30 ° 47 N 75 ° 50 E\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/\\n\\n30.79\\n\\n;\\n\\n75.84\\n\\nCoordinates\\n\\n:\\n\\n30\\n\\n°\\n\\n47\\n\\nN 75\\n\\n°\\n\\n50\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/ 30.79 ; 75.84 Country India Capital\\n\\nChandigarh Largest city Ludhiana Districts 22 Government\\n\\nGovernor VP Singh Badnore Chief Minister Captain Amarinder Singh ( INC )\\n\\nE\\n\\nE\\n\\nE\\n\\nLegislature Unicameral ( 117 seats ) Parliamentary constituency 13\\n\\nHigh Court Punjab and Haryana High Court Area Total 50,362 km (\\n\\n19,445 sq mi ) Area rank 20th Highest elevation 551 m ( 1,808 ft )\\n\\nLowest elevation 150 m ( 490 ft ) Population ( 2011 ) Total\\n\\n27,704,236 Rank 16th Density 550 / km ( 1,400 / sq mi ) Demonym\\n\\n( s ) Punjabi GDP ( 2017 -- 18 ) Total 4.65 lakh crore ( US $69\\n\\nbillion ) Per capita 142,958 ( US $2,100 ) Time zone IST ( UTC +\\n\\n05 : 30 ) ISO 3166 code IN - PB HDI 0.6614 ( medium ) HDI rank\\n\\n5th ( 2015 ) Official language Punjabi Website REMOVED_SECRET ^\\n\\nJoint Capital with Haryana . Common for Punjab , Haryana and Chandigarh .\\n\\nSymbols of Punjab Emblem Lion Capital of Ashoka with Wheat stem ( above )\\n\\nand Crossed Swords ( below ) Language Punjabi Dance Bhangra , Giddha\\n\\nAnimal Blackbuck Bird Baaz ( Accipiter gentilis ) Punjab ( /\\n\\npndb / ( listen ) ) is a state in northern India . Forming part of the\\n\\nlarger Punjab region , the state is bordered by the Indian states of Jammu and\\n\\nKashmir to the north , Himachal Pradesh to the east', metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 259.48it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_evaluation_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Load your evaluation dataset\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# You should replace this with your actual evaluation dataset\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m eval_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_evaluation_dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m questions \u001b[38;5;241m=\u001b[39m eval_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     54\u001b[0m reference_answers \u001b[38;5;241m=\u001b[39m eval_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/codes/langers/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codes/langers/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/codes/langers/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codes/langers/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/codes/langers/.venv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_evaluation_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# RAG System Evaluation Notebook\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score as bert_score\n",
    "import matplotlib.pyplot as plt\n",
    "from RAG_UTILS import RAGSystem, DocumentProcessor  # Import your existing RAG system\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "MODEL_ID = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
    "RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n",
    "PDF_FOLDER_PATH = \"local_database\"  # Update this to your local database path\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = RAGSystem(\n",
    "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_id=MODEL_ID,\n",
    "    reranker_model=RERANKER_MODEL,\n",
    ")\n",
    "\n",
    "# Load and process documents\n",
    "doc_processor = DocumentProcessor(EMBEDDING_MODEL_NAME)\n",
    "raw_documents = doc_processor.load_pdfs_from_folder(PDF_FOLDER_PATH)\n",
    "processed_documents = doc_processor.split_documents(raw_documents)\n",
    "\n",
    "# Build vector database\n",
    "knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_rag(questions: List[str], reference_answers: List[str]) -> dict:\n",
    "    results = []\n",
    "    for question, reference in tqdm(zip(questions, reference_answers), total=len(questions)):\n",
    "        answer, relevant_docs, _ = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"reference_answer\": reference,\n",
    "            \"generated_answer\": answer,\n",
    "            \"relevant_docs\": relevant_docs\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Load your evaluation dataset\n",
    "# You should replace this with your actual evaluation dataset\n",
    "eval_data = pd.read_csv(\"your_evaluation_dataset.csv\")\n",
    "questions = eval_data[\"question\"].tolist()\n",
    "reference_answers = eval_data[\"reference_answer\"].tolist()\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_rag(questions, reference_answers)\n",
    "\n",
    "# Helper functions for different metrics\n",
    "\n",
    "def calculate_retrieval_metrics(results: List[dict]) -> dict:\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for result in results:\n",
    "        relevant_docs = set(result[\"relevant_docs\"])\n",
    "        retrieved_docs = set(result[\"generated_answer\"].split())  # Simplification, adjust as needed\n",
    "        precision = len(relevant_docs.intersection(retrieved_docs)) / len(retrieved_docs) if retrieved_docs else 0\n",
    "        recall = len(relevant_docs.intersection(retrieved_docs)) / len(relevant_docs) if relevant_docs else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return {\n",
    "        \"avg_precision\": np.mean(precisions),\n",
    "        \"avg_recall\": np.mean(recalls),\n",
    "        \"avg_f1\": np.mean(f1s)\n",
    "    }\n",
    "\n",
    "def calculate_bertscore(results: List[dict]) -> float:\n",
    "    references = [r[\"reference_answer\"] for r in results]\n",
    "    candidates = [r[\"generated_answer\"] for r in results]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def calculate_semantic_similarity(results: List[dict]) -> float:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        ref_embedding = model.encode(result[\"reference_answer\"])\n",
    "        gen_embedding = model.encode(result[\"generated_answer\"])\n",
    "        similarity = np.dot(ref_embedding, gen_embedding) / (REMOVED_SECRET(ref_embedding) * REMOVED_SECRET(gen_embedding))\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# Calculate metrics\n",
    "retrieval_metrics = calculate_retrieval_metrics(evaluation_results)\n",
    "bertscore = calculate_bertscore(evaluation_results)\n",
    "semantic_similarity = calculate_semantic_similarity(evaluation_results)\n",
    "\n",
    "# Print results\n",
    "print(\"Retrieval Metrics:\")\n",
    "print(f\"Average Precision: {retrieval_metrics['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {retrieval_metrics['avg_recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {retrieval_metrics['avg_f1']:.4f}\")\n",
    "print(f\"BERTScore: {bertscore:.4f}\")\n",
    "print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'BERTScore', 'Semantic Similarity']\n",
    "values = [retrieval_metrics['avg_precision'], retrieval_metrics['avg_recall'], \n",
    "          retrieval_metrics['avg_f1'], bertscore, semantic_similarity]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, values)\n",
    "plt.title('RAG System Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation complete. Results saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "c1e9513dd95342b8878a65332d6dabc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `REMOVED_SECRET.GradScaler(args...)` is deprecated. Please use `REMOVED_SECRET('cuda', args...)` instead.\n",
      "  self.scaler = REMOVED_SECRET.GradScaler()\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:03<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question:\\n\\nwho owns st andrews golf course in scotland\\n\\nAnswer:\\n\\n<P> The Old Course at St Andrews is considered the oldest golf course in the world , a public\\n\\ncourse over common land in St Andrews , Fife , Scotland . It is held in trust by The St Andrews\\n\\nLinks Trust under an act of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have playing privileges on\\n\\nthe course , along with the general public . </P>\\n\\nContext:\\n\\nOld Course at St Andrews - wikipedia Old Course at St Andrews Jump to :\\n\\nnavigation , search Old Course R&A Clubhouse and 18th green in 2004 Club\\n\\ninformation\\n\\nCoordinates\\n\\n56 ° 20\\n\\n35 ''\\n\\nN 2 ° 48\\n\\n11 ''\\n\\n56.343 °\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Coordinates : 56 ° 20 35 '' N 2 ° 48 11 ''\\n\\nW\\n\\n56.343\\n\\n°\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Location St Andrews ,\\n\\nW\\n\\n/\\n\\nW\\n\\n/\\n\\nW\\n\\nScotland Established 1552 Type Public Owned by Fife Council\\n\\nOperated by St Andrews Links Trust Total holes 18 Tournaments hosted\\n\\nThe Open Championship , Alfred Dunhill Links Championship Website Old\\n\\nCourse Par 72 Length 7,305 yards ( 6,680 m ) Course record\\n\\n61 ; Ross Fisher ( 2017 ) St Andrews Location in Scotland St Andrews\\n\\nLocation in Fife , Scotland The Old Course at St Andrews is considered the\\n\\noldest golf course in the world , a public course over common land in St Andrews\\n\\n, Fife , Scotland . It is held in trust by The St Andrews Links Trust under an\\n\\nact of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have\\n\\nplaying privileges on the course , along with the general public . Contents\\n\\n( hide ) 1 History 1.1 Governance 1.2 Influence on modern golf 1.3 Old\\n\\nCourse and Bobby Jones 2 Features 3 The Open Championship 4 Scorecard\\n\\n5 Women 's British Open 6 Senior Open Championship 7 See also 8 References\\n\\n9 External links History ( edit ) The Old Course at St Andrews is\\n\\nconsidered by many to be the `` home of golf '' because the sport was first\\n\\nplayed on the Links at St Andrews in the early 15th century . Golf was becoming\\n\\nincreasingly popular in Scotland until in 1457 , when James II of Scotland\\n\\nbanned golf because he felt that young men were playing too much golf instead of\\n\\npractising their archery . The ban was upheld by the following kings of Scotland\\n\\nuntil 1502 , when King James IV became a\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question:\\n\\nequation for the velocity of an object in motion at constant acceleration\\n\\nAnswer:\\n\\nContext:\\n\\nEquations of motion - wikipedia Equations of motion Jump to : navigation ,\\n\\nsearch Classical mechanics F = m a ( \\\\ displaystyle ( \\\\ vec ( F ) ) =\\n\\nm ( \\\\ vec ( a ) ) ) Second law of motion History Timeline Branches\\n\\n( show ) Applied Celestial Continuum Dynamics Kinematics Kinetics\\n\\nStatics Statistical Fundamentals ( show ) Acceleration Angular\\n\\nmomentum Couple D'Alembert's principle Energy kinetic potential\\n\\nForce Frame of reference Impulse Inertia / Moment of inertia Mass\\n\\nMechanical power Mechanical work Moment Momentum Space Speed Time\\n\\nTorque Velocity Virtual work Formulations ( show ) Newton 's laws of\\n\\nmotion Analytical mechanics Lagrangian mechanics Hamiltonian mechanics\\n\\nRouthian mechanics Hamilton -- Jacobi equation Appell 's equation of motion\\n\\nUdwadia -- Kalaba equation Koopman -- von Neumann mechanics Core\\n\\ntopics ( show ) Damping ( ratio ) Displacement Equations of motion Euler\\n\\n's laws of motion Fictitious force Friction Harmonic oscillator\\n\\nInertial / Non-inertial reference frame Mechanics of planar particle motion\\n\\nMotion ( linear ) Newton 's law of universal gravitation Newton 's laws of\\n\\nmotion Relative velocity Rigid body dynamics Euler 's equations\\n\\nSimple harmonic motion Vibration Rotation ( show ) Circular motion\\n\\nRotating reference frame Centripetal force Centrifugal force reactive\\n\\nCoriolis force Pendulum Tangential speed Rotational speed Angular\\n\\nacceleration / displacement / frequency / velocity Scientists ( show )\\n\\nGalileo Newton Kepler Horrocks Halley Euler d'Alembert Clairaut\\n\\nLagrange Laplace Hamilton Poisson Daniel Bernoulli Johann Bernoulli\\n\\nCauchy In mathematical physics , equations of motion are\\n\\nequations that describe the behaviour of a physical system in terms of its\\n\\nmotion as a function of time . More specifically , the equations of motion\\n\\nde\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question:\\n\\nwho sang take that look off your face\\n\\nAnswer:\\n\\n<P> `` Take That Look Off Your Face '' is the title of a hit song by musical theatre composer\\n\\nAndrew Lloyd Webber . Collaborating with lyricist Don Black , it was written for the song cycle\\n\\nshow Tell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 , and\\n\\nbecame a No. 3 hit in the UK charts . The song was also popular in Ireland , and spent six weeks\\n\\nat number one . Later , Tell Me on a Sunday was combined with another Lloyd Webber work ,\\n\\nVariations , to form an entire new show , Song and Dance . </P>\\n\\nContext:\\n\\nTake that Look Off Your Face - Wikipedia Take that Look Off Your Face Jump to\\n\\n: navigation , search `` Take That Look Off Your Face '' Single by\\n\\nMarti Webb from the album Tell Me on a Sunday B - side `` Sheldon\\n\\nBloom '' Released January 1980 Format 7 '' single Recorded\\n\\n1979 Genre Pop , MOR , Theatrical Length 3 : 27 Label Polydor\\n\\nSongwriter ( s ) Andrew Lloyd Webber , Don Black Producer ( s ) Andrew\\n\\nLloyd Webber Marti Webb singles chronology `` D - Darling '' ( 1973 )\\n\\n`` Take That Look Off Your Face '' ( 1980 ) `` Tell Me on a Sunday '' ( 1980 )\\n\\n`` D - Darling '' ( 1973 ) `` Take That Look Off Your Face '' ( 1980 ) ``\\n\\nTell Me on a Sunday '' ( 1980 ) `` Take That Look Off Your Face '' is the\\n\\ntitle of a hit song by musical theatre composer Andrew Lloyd Webber .\\n\\nCollaborating with lyricist Don Black , it was written for the song cycle show\\n\\nTell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 ,\\n\\nand became a No. 3 hit in the UK charts . The song was also popular in Ireland ,\\n\\nand spent six weeks at number one . Later , Tell Me on a Sunday was combined\\n\\nwith another Lloyd Webber work , Variations , to form an entire new show , Song\\n\\nand Dance . The song is about a woman being told of her boyfriend 's\\n\\ninfidelity . The woman denies this initially , before rebuking her newsbearer (\\n\\na girlfriend ) with the revelation that she `` knew before '' and had done for\\n\\nsome time . She also spends much of the song criticising her friend for rushing\\n\\nto break the `` bad news '' to her . Despite having been written during the\\n\\ncreative process for Tell Me on a Sunday , the song was n't recorded during the\\n\\nalbum 's principal sessions . Black reminded Lloyd Webber that they had missed a\\n\\ntrack , then entitled `` You Must Be Mistaken '' . John Mole , the bass guitar\\n\\nplayer , improvised a part reminiscent of the arrangement style of Phil Spector\\n\\n, inspiring the rest of the orchestra\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content='Question:\\n\\nwho was gails most recent husband in coronation street\\n\\nAnswer:\\n\\nContext:\\n\\nGail McIntyre - wikipedia Gail McIntyre Gail McIntyre Coronation\\n\\nStreet character Portrayed by Helen Worth Duration 1974 -- First\\n\\nappearance Episode 1412 29 July 1974 Introduced by H.V. Kershaw Book\\n\\nappearances Coronation Street : The Complete Saga Norman Bates with a\\n\\nBriefcase : The story of Richard Hillman Spin - off appearances East\\n\\nStreet ( 2010 ) Classification Present ; regular Profile Other\\n\\nnames Gail Potter Gail Tilsley Gail Platt Gail McIntyre Gail Hillman\\n\\nGail Rodwell Occupation Receptionist Cleaner Waitress Factory\\n\\nWorker Newsagent Home 8 Coronation Street ( 1991 - 33 Hammond Road\\n\\n( 1985 - 1991 ) 5 Buxton Close ( 1980 - 1983 ) 5 Coronation Street ( 1979 -\\n\\n1980 , 1983 - 1985 ) 11 Coronation Street ( 1976 - 1979 ) 15a Coronation\\n\\nStreet ( 1975 - 1976 ) show Family Father Ted Page Mother\\n\\nAudrey Roberts Stepfather Alf Roberts Half - brothers Stephen Reid\\n\\nHusband Brian Tilsley ( 1979 -- 1987 , 1988 -- 1989 ) Martin Platt ( 1991\\n\\n-- 2001 ) Richard Hillman ( 2002 -- 2003 ) Joe McIntyre ( 2010 ) Michael\\n\\nRodwell ( 2015 -- 2016 ) Sons Nick Tilsley David Platt Daughters\\n\\nSarah Platt Stepdaughters Tina McIntyre Grandsons Billy Platt\\n\\nHarry Platt Max Turner ( step ) Granddaughters Bethany Platt Lily\\n\\nPlatt Grandfathers Robert Potter Grandmothers Nancy Potter\\n\\nGail Rodwell ( also Potter , Tilsley , Platt , Hillman and McIntyre ) is a\\n\\nfictional character from the British ITV soap opera , Coronation Street .\\n\\nPortrayed by Helen Worth , the character first appeared on - screen on 29 July\\n\\n1974 . As of 2018 , Gail has been on the show for 44 years , which currently\\n\\nmakes her the third longest - running character on the show after Ken Barlow and\\n\\nRita Tanner . Gail is the daughter of Audrey Roberts ( Sue Nicholls ) and Ted\\n\\nPage ( Michael Byrne ) and is the mother of Nick Tilsley (', metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content=\"Question:\\n\\nwhen did they figure out that yeast made bread rise\\n\\nAnswer:\\n\\n<P> The most common source of leavening in antiquity was to retain a piece of dough ( with\\n\\nsugar and water in ) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to produce `` a\\n\\nlighter kind of bread than other peoples . '' Parts of the ancient world that drank wine instead of\\n\\nbeer used a paste composed of grape must and flour that was allowed to begin fermenting , or\\n\\nwheat bran steeped in wine , as a source for yeast . </P>\\n\\nContext:\\n\\nHistory of bread - wikipedia History of bread Jump to : navigation , search\\n\\nSlab stele from mastaba tomb of Itjer at Giza . 4th Dynasty , 2543 - 2435 BC .\\n\\nItjer is seated at a table with slices of bread , shown vertical by convention .\\n\\nEgyptian Museum , Turin Bread was central to the formation of early human\\n\\nsocieties . From the western half of Asia , where wheat was domesticated ,\\n\\ncultivation spread north and west , to Europe and North Africa . This in turn\\n\\nled to the formation of towns , as opposed to the nomadic lifestyle , and gave\\n\\nrise to more and more sophisticated forms of societal organization . Similar\\n\\ndevelopments occurred in eastern Asia , centered on rice , and in the Americas\\n\\nwith maize . Contents ( hide ) 1 Antiquity 2 Middle Ages 3 To the\\n\\n19th century 4 Industrialization 5 See also 6 Notes Antiquity ( edit\\n\\n) Conical loaves of bread as grave goods exactly as laid out in the Great Tomb\\n\\n, North Necropolis , Gebelein , 5th Dynasty ( Old Kingdom ) , 2435 - 2305 BC .\\n\\nExcavations by Ernesto Schiaparelli , 1911 . Egyptian Museum , Turin , S. 14051\\n\\n14055 There is extensive evidence of breadmaking in Ancient Egypt in the form\\n\\nof artistic depictions , remains of structures and items used in bread making ,\\n\\nand remains of the dough and bread itself . The most common source of\\n\\nleavening in antiquity was to retain a piece of dough ( with sugar and water in\\n\\n) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to\\n\\nproduce `` a lighter kind of bread than other peoples . '' Parts of the ancient\\n\\nworld that drank wine instead of beer used a paste composed of grape must and\\n\\nflour that was allowed to begin fermenting , or wheat bran steeped in wine , as\\n\\na source for yeast . The idea of a free - standing oven that could be pre-\\n\\nheated , with a door for access , appears to have been Greek . Even in\\n\\nantiquity there were a wide variety of breads\", metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question:\\n\\nwho led the various reform movements of the 19th century\\n\\nAnswer:\\n\\nContext:\\n\\nConservation movement - wikipedia Conservation movement Jump to : navigation ,\\n\\nsearch For specific types of conservation , see Conservation ( disambiguation )\\n\\n. `` Conservationism '' redirects here . It is not to be confused with\\n\\nConservatism . Much attention has been given to preserving the natural\\n\\ncharacteristics of Hopetoun Falls , Australia , while allowing ample access for\\n\\nvisitors . Part of the Politics series Party politics Political\\n\\nspectrum Left - wing Far - left Hard - Left Extreme left\\n\\nCentre Centre - left Radical center Centre - right , Third Position\\n\\nRight - wing Far - right Hard right New right Alt - right Alt -\\n\\nlite Party platform Extremist Radical Moderate\\n\\nReformist Syncretic Third Position Conservative Fundamentalist\\n\\nReactionary Party system Non-partisan One - party\\n\\nDominant - party Two - party Multi-party Coalition Hung\\n\\nparliament Confidence and supply Minority government Rainbow coalition\\n\\nGrand coalition Full coalition National unity government Majority\\n\\ngovernment Lists Ruling parties by country Political parties by UN\\n\\ngeoscheme Political ideologies Politics portal The\\n\\nconservation movement , also known as nature conservation , is a political ,\\n\\nenvironmental and a social movement that seeks to protect natural resources\\n\\nincluding animal and plant species as well as their habitat for the future .\\n\\nThe early conservation movement included fisheries and wildlife management ,\\n\\nwater , soil conservation and sustainable forestry . The contemporary\\n\\nconservation movement has broadened from the early movement 's emphasis on use\\n\\nof sustainable yield of natural resources and preservation of wilderness areas\\n\\nto include preservation of biodiversity . Some say the conservation movement is\\n\\npart of the broader and more far - reaching environmental movement , while\\n\\nothers arg\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content=\"Question:\\n\\nwho has climbed the great wall of china\\n\\nAnswer:\\n\\nContext:\\n\\nGreat Wall of China - wikipedia Great Wall of China Jump to : navigation ,\\n\\nsearch `` Great Wall '' redirects here . For other uses , see Great Wall (\\n\\ndisambiguation ) . Great Wall of China The Great Wall of China\\n\\nat Jinshanling Map of all the wall constructions General information\\n\\nType Fortification Country China Coordinates 40 ° 41 N 117 ° 14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Coordinates : 40 ° 41 N 117\\n\\n°\\n\\n14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Technical details\\n\\nSize 21,196 km ( 13,171 mi ) UNESCO World Heritage Site Criteria\\n\\nCultural : ( i ) , ( ii ) , ( iii ) , ( iv ) , ( vi ) Reference 438\\n\\n°\\n\\n°\\n\\nE\\n\\n/\\n\\nE\\n\\nE\\n\\n/\\n\\nE\\n\\nInscription 1987 ( 11th Session ) ( edit on Wikidata ) Great\\n\\nWall of China Simplified Chinese Traditional Chinese\\n\\nLiteral meaning `` The Long Wall '' ( show ) Transcriptions\\n\\nStandard Mandarin Hanyu Pinyin Chángchéng Wade -- Giles Ch'ang -\\n\\nch'eng\\n\\nIPA\\n\\nh\\n\\n) Wu Romanization Saon sen Yue :\\n\\nCantonese\\n\\nYale Romanization\\n\\nCheung sing\\n\\ntsh\\n\\n. s )\\n\\nJyutping\\n\\nCoeng sing\\n\\nSouthern Min\\n\\nTn\\n\\ng - siân Tâi -\\n\\nlô\\n\\nTn\\n\\ng - siânn Alternative Chinese name Simplified Chinese\\n\\nTraditional Chinese Literal meaning `` The 10,000 - Mile Long Wall\\n\\n'' ( show ) Transcriptions Wu Romanization Vae - li saon - sen\\n\\nYue : Cantonese Yale Romanization Maan lei Cheung sing IPA ( màn.\\n\\nle\\n\\ni\\n\\n(\\n\\nIPA\\n\\nHokkien POJ\\n\\nh.\\n\\n(\\n\\ntsh\\n\\n. s ) Jyutping Maan - lei coeng - sing Southern Min\\n\\nTâi\\n\\n\\n\\nlô\\n\\nBn\\n\\ntn\\n\\ng - siânn The Great Wall of China is a series\\n\\nof fortifications made of stone , brick , tamped earth , wood , and other\\n\\nmaterials , generally built along an east - to - west line across the historical\\n\\nnorthern borders of China to protect the Chinese states and empires against the\\n\\nraids and invasions of the various nomadic groups of the Eu\\n\\n\\n\\nlí\", metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content='Question:\\n\\nwhen did star trek the next generation first air\\n\\nAnswer:\\n\\n<Table> <Tr> <Th colspan=\"2\"> Season </Th> <Th colspan=\"2\"> Episodes </Th> <Th\\n\\ncolspan=\"2\"> Originally aired </Th> </Tr> <Tr> <Th> First aired </Th> <Th> Last aired </Th>\\n\\n</Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 28 , 1987 ( 1987 - 09 - 28 ) </Td> <Td> May 16 , 1988 ( 1988 - 05 - 16\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 22 </Td> <Td\\n\\ncolspan=\"1\"> November 21 , 1988 ( 1988 - 11 - 21 ) </Td> <Td> July 17 , 1989 ( 1989 - 07 - 17 )\\n\\n</Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 25 , 1989 ( 1989 - 09 - 25 ) </Td> <Td> June 18 , 1990 ( 1990 - 06 - 18\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 24 , 1990 ( 1990 - 09 - 24 ) </Td> <Td> June 17 , 1991 ( 1991 - 06 - 17\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 5 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 23 , 1991 ( 1991 - 09 - 23 ) </Td> <Td> June 15 , 1992 ( 1992 - 06 - 15\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 6 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 21 , 1992 ( 1992 - 09 - 21 ) </Td> <Td> June 21 , 1993 ( 1993 - 06 - 21\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 7 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 20 , 1993 ( 1993 - 09 - 20 ) </Td> <Td> May 23 , 1994 ( 1994 - 05 - 23\\n\\n) </Td> </Tr> </Table>\\n\\nContext:\\n\\nStar Trek : the Next Generation - wikipedia Star Trek : the Next Generation\\n\\nJump to : navigation , search This article is about the television series . For\\n\\nthe games , see Star Trek : The Next Generation ( 1994 video game ) and Star\\n\\nTrek : The Next Generation : A World For All Seasons . Star Trek : The Next\\n\\nGeneration Genre Science fiction Drama Mystery Action\\n\\nadventure Created by Gene Roddenberry Based on Star Trek by Gene\\n\\nRoddenberry Starring Patrick Stewart Jonathan Frakes Brent Spiner\\n\\nLeVar Burton Denise Crosby Michael Dorn Gates McFadden Marina Sirtis\\n\\nWil Wheaton Theme music composer Alexander Courage Jerry Goldsmith\\n\\nComposer ( s ) Dennis McCarthy Jay Chattaway Ron Jones Country of origin\\n\\nUnited States Original language ( s ) English No. of seasons 7\\n\\nNo. of episodes 178 ( list of episodes ) Production Executive producer\\n\\n( s ) Gene Roddenberry ( 1987 -- 91 ) Rick Berman ( 1989 -- 94 )\\n\\nShowrunners Maurice Hurley ( 1988 -- 89 ) Michael Piller ( 1989 -- 94 )\\n\\nJeri Taylor ( 1993 -- 94 ) Cinematography Edward R. Brown ( 1987 -- 89\\n\\n) Marvin V. Rush ( 1989 -- 92 ) Jonathan West ( 1992 -- 94 ) Running\\n\\ntime 44 minutes Production company ( s ) Paramount Domestic Television\\n\\nDistributor CBS Television Distribution Budget $1.3 million per episode\\n\\nRelease Original network First - run syndication Picture format\\n\\nNTSC 480i 4 : 3 1080p 4 : 3 ( Blu - ray ) Audio format Dolby SR\\n\\nDolby Digital 5.1 ( DVD ) DTS - HD Master Audio 7.1 Blu - ray Original\\n\\nrelease September 28 , 1987 ( 1987 - 09 - 28 ) -- May 23 , 1994 ( 1994 - 05 -\\n\\n23 ) Chronology Preceded by Star Trek : The Animated Series\\n\\nFollowed by Star Trek : Deep Space Nine Related shows Star Trek TV\\n\\nseries External links Star Trek : The Next Generation at StarTrek.com\\n\\nStar Trek : The Next Generation ( abbreviated as TNG and ST : TNG ) i', metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content=\"Question:\\n\\nwhere were deep-sea hydrothermal vents first discovered 25 years ago\\n\\nAnswer:\\n\\nContext:\\n\\nHydrothermal vent - wikipedia Hydrothermal vent Jump to : navigation , search\\n\\nMarine habitats White smokers emitting liquid rich in barium , calcium ,\\n\\nsilicon and carbon dioxide at the Champagne vent , Northwest Eifuku volcano ,\\n\\nMarianas Trench Marine National Monument Littoral zone Intertidal zone\\n\\nEstuaries Kelp forests Coral reefs Ocean banks Continental shelf\\n\\nNeritic zone Straits Pelagic zone Oceanic zone Seamounts Hydrothermal\\n\\nvents Cold seeps Demersal zone Benthic zone A\\n\\nhydrothermal vent is a fissure in a planet 's surface from which geothermally\\n\\nheated water issues . Hydrothermal vents were discovered years ago in 1977 .\\n\\nHydrothermal vents are commonly found near volcanically active places , areas\\n\\nwhere tectonic plates are moving apart at spreading centers , ocean basins , and\\n\\nhotspots . Hydrothermal vents exist because the earth is both geologically\\n\\nactive and has large amounts of water on its surface and within its crust .\\n\\nCommon land types include hot springs , fumaroles and geysers . Under the sea ,\\n\\nhydrothermal vents may form features called black smokers . Relative to the\\n\\nmajority of the deep sea , the areas around submarine hydrothermal vents are\\n\\nbiologically more productive , often hosting complex communities fueled by the\\n\\nchemicals dissolved in the vent fluids . Chemosynthetic bacteria and archaea\\n\\nform the base of the food chain , supporting diverse organisms , including giant\\n\\ntube worms , clams , limpets and shrimp . Active hydrothermal vents are believed\\n\\nto exist on Jupiter 's moon Europa , and Saturn 's moon Enceladus , and it is\\n\\nspeculated that ancient hydrothermal vents once existed on Mars . Contents\\n\\n( hide ) 1 Physical properties 2 Black smokers and white smokers 3\\n\\nBiological communities 4 Biological theories 4.1 The Deep Hot Biosphere\\n\\n4.2 Hydrothermal origin of life 5 Discovery and exploration 6 Distribution\\n\\n7 Exploitation 8 Conservation 9 See also 10 References\", metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question:\\n\\nthe period of european history between ancient and modern eras\\n\\nAnswer:\\n\\nContext:\\n\\nHistory of Europe - wikipedia History of Europe Jump to : navigation , search\\n\\nThe history of Europe covers the peoples inhabiting Europe from prehistory to\\n\\nthe present . The period known as classical antiquity began with the emergence\\n\\nof the city - states of ancient Greece . Later , the Roman Empire came to\\n\\ndominate the entire Mediterranean basin . The fall of the Roman Empire in AD 476\\n\\ntraditionally marks the start of the Middle Ages . Beginning in the 14th century\\n\\na Renaissance of knowledge challenged traditional doctrines in science and\\n\\ntheology . Simultaneously , the Protestant Reformation set up Protestant\\n\\nchurches primarily in Germany , Scandinavia and England . After 1800 , the\\n\\nIndustrial Revolution brought prosperity to Britain and Western Europe . The\\n\\nmain powers set up colonies in most of the Americas and Africa , and parts of\\n\\nAsia . In the 20th century , World War I , and World War II resulted in massive\\n\\nnumbers of deaths . The Cold War dominated European geo - politics from 1947 to\\n\\n1989 . Unification into a European Union moved forward after 1950 , with some\\n\\nsetbacks . Today , most countries west of Russia belong to the NATO military\\n\\nalliance , along with the United States and Canada . Europe depicted by Antwerp\\n\\ncartographer Abraham Ortelius in 1595 Contents ( hide ) 1 Overview 2\\n\\nPrehistory 3 Minoans and Mycenae 2700 -- 1100 BC 4 Classical antiquity 4.1\\n\\nAncient Greece 4.2 The rise of Rome 4.3 Decline of the Roman Empire 4.4\\n\\nLate Antiquity and Migration Period 5 Middle Ages 5.1 Byzantium 5.2\\n\\nEarly Middle Ages 5.2. 1 Feudal Christendom 5.3 High Middle Ages 5.3. 1\\n\\nA divided church 5.3. 2 Holy wars 5.4 Late Middle Ages 6 Early modern\\n\\nEurope 6.1 Renaissance 6.2 Exploration and trade 6.3 Reformation 6.4\\n\\nMercantilism and colonial expansion 6.5 Crisis of the 17th century 6.6 Age\\n\\nof Absolutism 6.6. 1 Thirty Years ' War 1618 -- 1648 6.6. 2 War of the\\n\\nSpanish Succession 6.6. 3 Prussia 6.6. 4 Rus\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question:\\n\\nwho sang the most wonderful summer of my life\\n\\nAnswer:\\n\\n<P> Jackie Ward ( born Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an\\n\\nAmerican singer , regarded as a `` one - hit wonder '' of 1963 million - selling song `` Wonderful\\n\\nSummer '' . However , using her real name she was highly accomplished and successful singing in\\n\\ngroups . Ward 's voice is heard in U.S. television series , motion pictures , advertisements , and\\n\\npop records . She is one of the real singers of the hits attributed to The Partridge Family . </P>\\n\\nContext:\\n\\nRobin Ward ( singer ) - wikipedia Robin Ward ( singer ) This article may\\n\\nneed to be rewritten entirely to comply with Wikipedia 's quality standards .\\n\\nYou can help . The discussion page may contain suggestions . ( January 2018 )\\n\\nRobin Ward Birth name Jacqueline McDonnell Also known as Jackie Ward\\n\\n1941 ( age 76 -- 77 ) Hawaii , USA Genres Pop , TV theme songs , Movie\\n\\nsongs , Advertising Occupation ( s ) Singer Instruments Voice\\n\\nYears active 1954 -- 1979 Labels Dot Records Associated acts\\n\\nPartridge Family , Ray Conniff Singers , Ron Hicklin Singers Jackie Ward (\\n\\nborn Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an American\\n\\nsinger , regarded as a `` one - hit wonder '' of 1963 million - selling song ``\\n\\nWonderful Summer '' . However , using her real name she was highly accomplished\\n\\nand successful singing in groups . Ward 's voice is heard in U.S. television\\n\\nseries , motion pictures , advertisements , and pop records . She is one of the\\n\\nreal singers of the hits attributed to The Partridge Family . Contents 1\\n\\nBiography 1.1 Early years 1.2 `` Wonderful Summer '' 1.3 Post `` Robin\\n\\nWard '' TV , movies , and records singing 1.4 The Partridge Family 2\\n\\nReferences 3 External links Biography ( edit ) Early years ( edit )\\n\\nWard was born Jacqueline McDonnell in 1941 to a military family in Hawaii ( her\\n\\nfather served in the US Navy ) and raised in Nebraska . Her first public singing\\n\\nperformances were with her two sisters in a Nebraska church when she was eight\\n\\nyears old . After the trio won a national talent search run by Horace Heidt ,\\n\\nthey moved to Los Angeles to seek work in the music industry . At the age of\\n\\n13 , Ward was hired by Los Angeles television station KTLA to sing on a Your Hit\\n\\nParade - like program , Bandstand Revue ; Ward performed popular hits for four\\n\\nyears . Then she started a career of singing on demo and released recordings .\\n\\nOne 1962 session was singing the `` la la\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question:\\n\\nhow many beverly hills cops movies are there\\n\\nAnswer:\\n\\n<P> Beverly Hills Cop is a series of American action comedy films and an unaired television pilot\\n\\nbased on characters created by Daniel Petrie , Jr. and Danilo Bach . The films star Eddie Murphy\\n\\nas Axel Foley , a street - smart Detroit cop who travels to Beverly Hills , California to investigate\\n\\ncrimes , even though it is out of his jurisdiction . There , he meets Detective Billy Rosewood (\\n\\nJudge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and Lieutenant Andrew Bogomil ( Ronny\\n\\nCox ) . Ashton and Cox do not appear in Beverly Hills Cop III . Murphy , Reinhold , and Gil Hill ,\\n\\nwho plays Axel 's boss , Inspector Todd , are the only actors who appear in all three films . Harold\\n\\nFaltermeyer produced the now famous `` Axel F '' theme song heard throughout the series . The\\n\\nseries as a whole have been distributed by Paramount Pictures . The films have made a total of $\\n\\n735,534,503 at the worldwide box office . </P>\\n\\nContext:\\n\\nBeverly Hills Cop ( film series ) - wikipedia Beverly Hills Cop ( film series )\\n\\nJump to : navigation , search Beverly Hills Cop Directed by\\n\\nMartin Brest ( I ) Tony Scott ( II ) John Landis ( III ) Adil El Arbi ( IV\\n\\n) Bilall Fallah ( IV ) Produced by Jerry Bruckheimer ( I - II , IV )\\n\\nDon Simpson ( I - II ) Mace Neufeld ( III ) Robert Rehme ( III ) Eddie\\n\\nMurphy ( IV ) Screenplay by Daniel Petrie , Jr . ( I ) Larry\\n\\nFerguson ( II ) Warren Skaaren ( II ) Steven E. de Souza ( III ) Josh\\n\\nAppelbaum ( IV ) André Nemec ( IV ) Story by Danilo Bach ( I )\\n\\nDaniel Petrie , Jr . ( I ) Eddie Murphy ( II ) Robert D. Wachs ( II )\\n\\nSteven E. de Souza ( III ) Josh Appelbaum ( IV ) André Nemec ( IV )\\n\\nStarring Eddie Murphy Judge Reinhold John Ashton ( l - ll , lV ) Gil\\n\\nHill ( l - lll ) Ronny Cox ( I - II ) Brandon T. Jackson ( Unaired pilot )\\n\\nMusic by Harold Faltermeyer ( I - II ) Nile Rodgers ( III )\\n\\nCinematography Bruce Surtees ( I ) Jeffrey L. Kimball ( II ) Mac Ahlberg\\n\\n( III ) Dante Spinotti ( IV ) Edited by Billy Weber ( I - II )\\n\\nArthur Coburn ( I ) Chris Lebenzon ( II ) Michael Tronick ( II ) Dale\\n\\nBeldin ( III ) Production company Simpson / Bruckheimer ( I - II )\\n\\nEddie Murphy Productions ( I - III ) Distributed by Paramount Pictures\\n\\nRelease date 1984 - 1994 Running time 312 minutes Country United\\n\\nStates Language English Budget $85 million Box office $735.5\\n\\nmillion Beverly Hills Cop is a series of American action comedy films and an\\n\\nunaired television pilot based on characters created by Daniel Petrie , Jr. and\\n\\nDanilo Bach . The films star Eddie Murphy as Axel Foley , a street - smart\\n\\nDetroit cop who travels to Beverly Hills , California to investigate crimes ,\\n\\neven though it is out of his jurisdiction . There , he meets Detective Billy\\n\\nRosewood ( Judge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and\\n\\nLieu\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question:\\n\\ndale carnegie how to win and influence friends pdf\\n\\nAnswer:\\n\\nContext:\\n\\nHow to Win Friends and Influence people - wikipedia How to Win Friends and\\n\\nInfluence people Jump to : navigation , search For the Terrorvision album , see\\n\\nHow to Make Friends and Influence People . How to Win Friends and Influence\\n\\nPeople First edition , 11th printing ( February 1937 ) Author Dale\\n\\nCarnegie Country United States Language English Subject Self -\\n\\nhelp Genre Non-fiction Publisher Simon and Schuster ( 1936 )\\n\\nPublication date October 1936 Media type Print ( hardcover / paperback )\\n\\nPages 291 pp ISBN 1 - 4391 - 6734 - 6 OCLC 40137494 How to Win\\n\\nFriends and Influence People is a self - help book written by Dale Carnegie ,\\n\\npublished in 1936 . Over 30 million copies have been sold world - wide , making\\n\\nit one of the best - selling books of all time . In 2011 , it was number 19 on\\n\\nTime Magazine 's list of the 100 most influential books . In 1934 , Leon\\n\\nShimkin of the publishing firm Simon & Schuster took one of Carnegie 's 14 -\\n\\nweek courses ; afterward , Shimkin persuaded Carnegie to let a stenographer take\\n\\nnotes from the course to be revised for publication . The original book\\n\\ncontained colorful anecdotes and insightful wisdom , and gave instruction in\\n\\nhandling people , `` winning '' friends , bringing people to your way of\\n\\nthinking , being a great leader , and successfully navigating home life .\\n\\nCarnegie combined age - old truisms with the emerging field of psychology to\\n\\npresent a handbook in human relations which was interesting and accessible .\\n\\nEmphasizing using others ' egotistical tendencies to one 's advantage , Carnegie\\n\\nmaintained that success could be found by charm , appreciation , and personality\\n\\n. The book sold exceptionally well from the start , going through 17 editions in\\n\\nits first year alone . In 1981 , a revised edition containing updated language\\n\\nand anecdotes was released . The revised edition reduced the number of sections\\n\\nfrom six to four , eliminating sections on effectiv\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question:\\n\\nthe human tendency to mimic other peoples behavior is an example of\\n\\nAnswer:\\n\\n<P> Mirroring is the behaviour in which one person subconsciously imitates the gesture , speech\\n\\npattern , or attitude of another . Mirroring often occurs in social situations , particularly in the\\n\\ncompany of close friends or family . The concept often affects other individuals ' notions about\\n\\nthe individual that is exhibiting mirroring behaviors , which can lead to the individual building\\n\\nrapport with others . </P>\\n\\nContext:\\n\\nMirroring ( psychology ) - wikipedia Mirroring ( psychology ) This\\n\\narticle needs additional citations for verification . Please help improve this\\n\\narticle by adding citations to reliable sources . Unsourced material may be\\n\\nchallenged and removed . ( August 2015 ) ( Learn how and when to remove this\\n\\ntemplate message ) Mirroring in an argument . Mirroring is the behaviour in\\n\\nwhich one person subconsciously imitates the gesture , speech pattern , or\\n\\nattitude of another . Mirroring often occurs in social situations , particularly\\n\\nin the company of close friends or family . The concept often affects other\\n\\nindividuals ' notions about the individual that is exhibiting mirroring\\n\\nbehaviors , which can lead to the individual building rapport with others .\\n\\nMirroring is the subconscious replication of another person 's nonverbal signals\\n\\n. This concept takes place in everyday interactions , and often goes unnoticed\\n\\nby both the person enacting the mirroring behaviors as well as the individual\\n\\nwho is being mirrored . The activation of mirror neurons takes place within the\\n\\nindividual who begins to mirror another 's movements , and allows them a greater\\n\\nconnection and understanding with the individual who they are mirroring , as\\n\\nwell as allowing the individual who is being mirrored to feel a stronger\\n\\nconnection with the other individual . Mirroring is distinct from conscious\\n\\nimitation under the premise that while the latter is a conscious , typically\\n\\novert effort to copy another person , mirroring is subconsciously done during\\n\\nthe act and often goes unnoticed . The display of mirroring often begins as\\n\\nearly as infancy , as babies begin to mimic individuals around them and\\n\\nestablish connections with particular body movements . The ability to mimic\\n\\nanother person 's actions allows the infant to establish a sense of empathy and\\n\\nthus begin to understand another person 's emotions . The infant continues to\\n\\nestablish connections with other individual 's emotions and subsequent\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question:\\n\\nwho invented the use of electricity during the industrial revolution\\n\\nAnswer:\\n\\nContext:\\n\\nIndustrial Revolution - wikipedia Industrial Revolution Jump to : navigation ,\\n\\nsearch A Roberts loom in a weaving shed in 1835 . Textiles were the leading\\n\\nindustry of the Industrial Revolution and mechanized factories , powered by a\\n\\ncentral water wheel or steam engine , were the new workplace . The Industrial\\n\\nRevolution was the transition to new manufacturing processes in the period from\\n\\nabout 1760 to sometime between 1820 and 1840 . This transition included going\\n\\nfrom hand production methods to machines , new chemical manufacturing and iron\\n\\nproduction processes , the increasing use of steam power , the development of\\n\\nmachine tools and the rise of the factory system . Textiles were the dominant\\n\\nindustry of the Industrial Revolution in terms of employment , value of output\\n\\nand capital invested . The textile industry was also the first to use modern\\n\\nproduction methods . The Industrial Revolution began in Great Britain , and\\n\\nmany of the technological innovations were of British origin . By the mid-18th\\n\\ncentury Britain was the world 's leading commercial nation , controlling a\\n\\nglobal trading empire with colonies in North America and Africa , and with some\\n\\npolitical influence on the Indian subcontinent , through the activities of the\\n\\nEast India Company . The development of trade and the rise of business were\\n\\nmajor causes of the Industrial Revolution . The Industrial Revolution marks a\\n\\nmajor turning point in history ; almost every aspect of daily life was\\n\\ninfluenced in some way . In particular , average income and population began to\\n\\nexhibit unprecedented sustained growth . Some economists say that the major\\n\\nimpact of the Industrial Revolution was that the standard of living for the\\n\\ngeneral population began to increase consistently for the first time in history\\n\\n, although others have said that it did not begin to meaningfully improve until\\n\\nthe late 19th and 20th centuries . GDP per capita was broadly stable before\\n\\nthe Industrial Revolution and the emergence of\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question:\\n\\nhow is the head of the church of england\\n\\nAnswer:\\n\\n<P> The Church of England ( C of E ) is the Established Church of England . The Archbishop of\\n\\nCanterbury is the most senior cleric , although the monarch is the supreme governor . The Church\\n\\nof England is also the mother church of the international Anglican Communion . It traces its\\n\\nhistory to the Christian church recorded as existing in the Roman province of Britain by the third\\n\\ncentury , and to the 6th - century Gregorian mission to Kent led by Augustine of Canterbury .\\n\\n</P>\\n\\nContext:\\n\\nChurch of England - wikipedia Church of England `` C of E '' redirects here .\\n\\nFor other uses , see Council of Europe . Anglican state church of England\\n\\nChurch of England Abbreviation C of E Orientation Anglican\\n\\nPolity Episcopal Supreme Governor Queen Elizabeth II Primate\\n\\nArchbishop Justin Welby Associations Anglican Communion Porvoo Communion\\n\\nRegion England , Wales ( cross-border parishes ) Isle of Man Channel Islands\\n\\nContinental Europe Headquarters Church House , Westminster , England ,\\n\\nUnited Kingdom Separated from Roman Catholic Church ( 1534 )\\n\\nSeparations English Dissenters ( 1534 onwards ) Methodists ( 18th century )\\n\\nPlymouth Brethren ( 1820s ) Free Church of England ( 1844 ) Members 25\\n\\nmillion Official website churchofengland.org Part of a series on\\n\\nAnglicanism Theology ( show ) Christian theology Anglican doctrine\\n\\nThirty - nine Articles Books of Homilies Caroline Divines Lambeth Quadrilateral\\n\\nEpiscopal polity Sacraments Mary Ministry and worship ( show ) Ministry\\n\\nMusic Eucharist King James Version ( Book of Common Prayer ) Liturgical year\\n\\nChurchmanship ( High , Low , Central , Broad ) Monasticism Saints\\n\\nChristianity ( show ) Jesus Christ Paul Christian Church First seven Ecumenical\\n\\nCouncils Background and history ( show ) Celtic Christianity Augustine of\\n\\nCanterbury Bede Medieval cathedral architecture Henry VIII English Reformation\\n\\nThomas Cranmer Dissolution of Monasteries Church of England Edward VI Elizabeth\\n\\nI Parker Hooker James I Charles I Laud Nonjuring schism Anglo - Catholicism\\n\\nOxford Movement Anglican Communion ( show ) Anglican Communion history\\n\\nArchbishop of Canterbury Anglican Communion Primates ' Meetings Lambeth\\n\\nConference Bishops Anglican Consultative Council Ecumenism Ordination of women\\n\\nWindsor Report Continuing Anglicanism ( show ) Anglican realignment\\n\\nBartonville Agreement Congress of St. Louis North American Anglican Conference\\n\\nAnglicanism portal\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content='Question:\\n\\nwho holds the most women\\'s wimbledon titles\\n\\nAnswer:\\n\\n<Table> Wimbledon Ladies \\' Singles Champions <Tr> <Th> Location </Th> <Td> London\\n\\nUnited Kingdom </Td> </Tr> <Tr> <Th> Venue </Th> <Td> AELTC </Td> </Tr> <Tr> <Th>\\n\\nGoverning body </Th> <Td> AELTC / LTA </Td> </Tr> <Tr> <Th> Created </Th> <Td> 1884 (\\n\\nestablished ) Open Era : 1968 ( 51 editions ) </Td> </Tr> <Tr> <Th> Surface </Th> <Td>\\n\\nGrass ( 1884 -- Present ) </Td> </Tr> <Tr> <Th> Prize money </Th> <Td> £ 2,000,000 ( 2016\\n\\n) </Td> </Tr> <Tr> <Th> Trophy </Th> <Td> Venus Rosewater Dish </Td> </Tr> <Tr> <Th>\\n\\nWebsite </Th> <Td> REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html </Td>\\n\\n</Tr> <Tr> <Th colspan=\"2\"> Most titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 7\\n\\n: Dorothea Lambert Chambers ( challenge round ) 8 : Helen Wills Moody ( regular ) </Td> </Tr>\\n\\n<Tr> <Th> Open era </Th> <Td> 9 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\">\\n\\nMost consecutive titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 3 : Lottie Dod\\n\\nSuzanne Lenglen ( challenge round ) 4 : Helen Wills Moody ( regular ) </Td> </Tr> <Tr> <Th>\\n\\nOpen era </Th> <Td> 6 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\"> Current\\n\\nchampion </Th> </Tr> <Tr> <Td colspan=\"2\"> Angelique Kerber ( 1st singles title ) </Td>\\n\\n</Tr> </Table>\\n\\nContext:\\n\\nList of Wimbledon Ladies \\' Singles champions - wikipedia List of Wimbledon\\n\\nLadies \\' Singles champions Wimbledon Ladies \\' Singles Champions Location\\n\\nLondon United Kingdom Venue AELTC Governing body AELTC / LTA\\n\\nCreated 1884 ( established ) Open Era : 1968 ( 51 editions ) Surface\\n\\nGrass ( 1884 -- Present ) Prize money £ 2,000,000 ( 2016 ) Trophy\\n\\nVenus Rosewater Dish Website\\n\\REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html Most\\n\\ntitles Amateur era 7 : Dorothea Lambert Chambers ( challenge round ) 8 :\\n\\nHelen Wills Moody ( regular ) Open era 9 : Martina Navratilova Most\\n\\nconsecutive titles Amateur era 3 : Lottie Dod Suzanne Lenglen ( challenge\\n\\nround ) 4 : Helen Wills Moody ( regular ) Open era 6 : Martina Navratilova\\n\\nCurrent champion Angelique Kerber ( 1st singles title ) The\\n\\nChampionships , Wimbledon is an annual tennis tournament first contested in 1877\\n\\nand played on outdoor grass courts at the All England Lawn Tennis and Croquet\\n\\nClub ( AELTC ) in the Wimbledon suburb of London , United Kingdom . The Ladies \\'\\n\\nSingles was started in 1884 . Contents 1 History 2 Champions 2.1\\n\\nAmateur Era 2.2 Open Era 3 Statistics 3.1 Multiple champions 3.2\\n\\nChampionships by country 4 See also 5 Notes 6 References 7 External\\n\\nlinks History ( edit ) Wimbledon has historically been played in the last\\n\\nweek of June and the first week of July ( though changed to the first two weeks\\n\\nof July in 2017 ) , and has been chronologically the third of the four Grand\\n\\nSlam tournaments of the tennis season since 1987 . The event was not held from\\n\\n1915 to 1918 because of World War I and again from 1940 to 1945 because of World\\n\\nWar II . The Ladies \\' Singles \\' rules have undergone several changes since the\\n\\nfirst edition . From 1886 until 1921 , the event started with a knockout phase ,\\n\\nthe All Comers \\' Singles , whose winner then faced the defending champion in a\\n\\nchallenge round . The All', metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content=\"Question:\\n\\nhow many goals scored ronaldo in his career\\n\\nAnswer:\\n\\n<P> Cristiano Ronaldo dos Santos Aveiro GOIH ComM ( European Portuguese : ( kitjnu\\n\\nonadu ) ; born 5 February 1985 ) is a Portuguese professional footballer who plays as a forward\\n\\nfor Italian club Juventus and the Portugal national team . Often considered the best player in the\\n\\nworld and regarded by many as one of the greatest players of all time , Ronaldo has a record -\\n\\ntying five Ballon d'Or awards , the most for a European player , and is the first player to win four\\n\\nEuropean Golden Shoes . He has won 26 trophies in his career , including five league titles , five\\n\\nUEFA Champions League titles and one UEFA European Championship . A prolific goalscorer ,\\n\\nRonaldo holds the records for most official goals scored in Europe 's top - five leagues ( 395 ) , the\\n\\nUEFA Champions League ( 120 ) , the UEFA European Championship ( 9 ) , as well as those for\\n\\nmost assists in the UEFA Champions League ( 34 ) and the UEFA European Championship ( 6 ) .\\n\\nHe has scored over 670 senior career goals for club and country . </P>\\n\\nContext:\\n\\nCristiano Ronaldo - wikipedia Cristiano Ronaldo Portuguese footballer For\\n\\nthe Brazilian footballer , see Ronaldo ( Brazilian footballer ) . This name uses\\n\\nPortuguese naming customs . The first or maternal family name is Santos and the\\n\\nsecond or paternal family name is Aveiro . Cristiano Ronaldo Cristiano\\n\\nRonaldo with Portugal at the 2018 FIFA World Cup Full name Cristiano\\n\\nRonaldo dos Santos Aveiro Date of birth ( 1985 - 02 - 05 ) 5 February 1985\\n\\n( age 33 ) Place of birth Funchal , Madeira , Portugal Height 1.85 m\\n\\n( 6 ft 1 in ) Playing position Forward Club information Current\\n\\nteam Juventus Number 7 Youth career 1992 -- 1995 Andorinha\\n\\n1995 -- 1997 Nacional 1997 -- 2002 Sporting CP Senior career *\\n\\nYears Team Apps ( Gls ) 2002 -- 2003 Sporting CP B ( 0 )\\n\\n2002 -- 2003 Sporting CP 25 ( 3 ) 2003 -- 2009 Manchester United\\n\\n196 ( 84 ) 2009 -- 2018 Real Madrid 292 ( 311 ) 2018 --\\n\\nJuventus ( 0 ) National team Portugal U15 9 ( 7 ) 2001 --\\n\\n2002 Portugal U17 7 ( 5 ) 2003 Portugal U20 5 ( 1 ) 2002 --\\n\\n2003 Portugal U21 10 ( 3 ) Portugal U23 ( 2 ) 2003 --\\n\\nPortugal 154 ( 85 ) Honours ( show ) Men 's football\\n\\nRepresenting Portugal UEFA European Championship 2004 Portugal\\n\\n2012 Poland & Ukraine 2016 France FIFA Confederations Cup\\n\\n2017 Russia * Senior club appearances and goals counted for the\\n\\ndomestic league only and correct as of 25 August 2018 National team caps and\\n\\ngoals correct as of 30 June 2018 This article is part of a series\\n\\nabout Cristiano Ronaldo Portuguese professional footballer\\n\\nInternational goals Career achievements Comparisons to Lionel Messi\\n\\nNamesakes Cristiano Ronaldo Campus Futebol Cristiano Ronaldo International\\n\\nAirport Galaxy CR7 Museu CR7 Films Cristiano Ronaldo : The World at\\n\\nHis Feet Ronaldo\", metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the orange stuff on my sushi\\n\\nAnswer:\\n\\n<P> The eggs are small , ranging from 0.5 to 0.8 mm . For comparison , tobiko is larger than\\n\\nmasago ( capelin roe ) , but smaller than ikura ( salmon roe ) . Natural tobiko has a red - orange\\n\\ncolor , a mild smoky or salty taste , and a crunchy texture . </P>\\n\\nContext:\\n\\nTobiko - wikipedia Tobiko Jump to : navigation , search This article\\n\\nneeds additional citations for verification . Please help improve this article\\n\\nby adding citations to reliable sources . Unsourced material may be challenged\\n\\nand removed . ( February 2013 ) ( Learn how and when to remove this template\\n\\nmessage ) Tobiko in varying colors , served as sushi Tobiko ( ) is the\\n\\nJapanese word for flying fish roe . It is most widely known for its use in\\n\\ncreating certain types of sushi . The eggs are small , ranging from 0.5 to 0.8\\n\\nmm . For comparison , tobiko is larger than masago ( capelin roe ) , but smaller\\n\\nthan ikura ( salmon roe ) . Natural tobiko has a red - orange color , a mild\\n\\nsmoky or salty taste , and a crunchy texture . Tobiko , shown in its natural\\n\\ncolor , topping grilled Albacore tuna Sometimes tobiko is colored to change its\\n\\nappearance , other natural ingredients are used to accomplish the change , such\\n\\nas squid ink to make it black , yuzu to make it pale orange ( almost yellow ) ,\\n\\nor even wasabi to make it green and spicy . Sometimes a serving of tobiko\\n\\ncontains several pieces , each having a different color . When prepared as\\n\\nsashimi , it may be presented on avocado halves or wedges . Tobiko is used in\\n\\nthe creation of many other Japanese dishes . Often , tobiko is used as an\\n\\ningredient in California rolls . Frequently , masago ( capelin or smelt roe )\\n\\nis substituted for tobiko , due to its similar appearance and flavor . The\\n\\nsmaller size of the individual eggs is apparent to the experienced diner ,\\n\\nhowever . References ( edit ) Wikimedia Commons has media related to\\n\\nTobiko . Jump up ^ `` Tobiko vs Masago Difference '' . Expert answer\\n\\nQuestion. 2016 - 11 - 16 . Retrieved 2016 - 11 - 16 . Jump up ^ Food Republic\\n\\nhttp://REMOVED_SECRET/2013/04/19/what-tobiko-and-whats-different-colors .\\n\\nRetrieved 18 October 2014 . Missing or empty title = ( help ) Sushi\\n\\nHistory of sushi List of sushi and sashimi ingr\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question:\\n\\nwho was the first president to get his picture taken\\n\\nAnswer:\\n\\nContext:\\n\\nList of United States Presidential Firsts - wikipedia List of United States\\n\\nPresidential Firsts Jump to : navigation , search This article needs\\n\\nadditional citations for verification . Please help improve this article by\\n\\nadding citations to reliable sources . Unsourced material may be challenged and\\n\\nremoved . ( January 2017 ) ( Learn how and when to remove this template message\\n\\n) This list lists achievements and distinctions of various Presidents of the\\n\\nUnited States . It includes distinctions achieved in their earlier life and\\n\\npost-presidencies . Due to some confusion surrounding sovereignty of nations\\n\\nduring presidential visits , only nations that were independent , sovereign , or\\n\\nrecognized by the United States during the presidency are listed here as a\\n\\nprecedent . Contents ( hide ) 1 George Washington ( 1789 - 1797 ) 2 John\\n\\nAdams ( 1797 - 1801 ) 3 Thomas Jefferson ( 1801 - 1809 ) 4 James Madison (\\n\\n1809 - 1817 ) 5 James Monroe ( 1817 - 1825 ) 6 John Quincy Adams ( 1825 -\\n\\n1829 ) 7 Andrew Jackson ( 1829 - 1837 ) 8 Martin Van Buren ( 1837 - 1841 )\\n\\n9 William Henry Harrison ( 1841 ) 10 John Tyler ( 1841 - 1845 ) 11 James K.\\n\\nPolk ( 1845 - 1849 ) 12 Zachary Taylor ( 1849 - 1850 ) 13 Millard Fillmore (\\n\\n1850 - 1853 ) 14 Franklin Pierce ( 1853 - 1857 ) 15 James Buchanan ( 1857 -\\n\\n1861 ) 16 Abraham Lincoln ( 1861 - 1865 ) 17 Andrew Johnson ( 1865 - 1869 )\\n\\n18 Ulysses S. Grant ( 1869 - 1877 ) 19 Rutherford B. Hayes ( 1877 - 1881 )\\n\\n20 James A. Garfield ( 1881 ) 21 Chester A. Arthur ( 1881 - 1885 ) 22 Grover\\n\\nCleveland ( 1885 - 1889 ; 1893 - 1897 ) 23 Benjamin Harrison ( 1889 - 1893 )\\n\\n24 William McKinley ( 1897 - 1901 ) 25 Theodore Roosevelt ( 1901 - 1909 ) 26\\n\\nWilliam Howard Taft ( 1909 - 1913 ) 27 Woodrow Wilson ( 1913 - 1921 ) 28\\n\\nWarren G. Harding ( 1921 - 1923 ) 29 Calvin Coolidge ( 1923 - 1929 ) 30\\n\\nHerbert Hoover ( 1929 - 1933 ) 31 Franklin D. Roosevelt ( 1933 - 1945 ) 32\\n\\nHarry S. Truman ( 1945 - 1953 ) 3', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the moral of the ant and the grasshopper\\n\\nAnswer:\\n\\n<P> The story has been used to teach the virtues of hard work and the perils of improvidence .\\n\\nSome versions state a moral at the end along the lines of `` Idleness brings want '' , `` To work\\n\\ntoday is to eat tomorrow '' , `` Beware of winter before it comes '' . In La Fontaine 's Fables no\\n\\nfinal judgment is made , although it has been argued that the author is there making sly fun of\\n\\nhis own notoriously improvident ways . But the point of view in most retellings of the fable is\\n\\nsupportive of the ant . It is also influenced by the commendation in the biblical Book of Proverbs ,\\n\\nwhich mentions the ant twice . The first proverb admonishes , `` Go to the ant , you sluggard !\\n\\nConsider her ways and be wise , which having no captain , overseer or ruler , provides her\\n\\nsupplies in the summer , and gathers her food in the harvest '' ( 6.6 - 9 ) . Later , in a parallel\\n\\nsaying of Agur , the insects figure among the ' four things that are little upon the earth but they\\n\\nare exceeding wise . The ants are a people not strong , yet they provide their food in the summer\\n\\n. ' ( 30.24 - 5 ) </P>\\n\\nContext:\\n\\nThe ant and the grasshopper - wikipedia The ant and the grasshopper Jump to :\\n\\nnavigation , search Coloured print of La Fontaine 's fable by Jean - Baptiste\\n\\nOudry The Ant and the Grasshopper , alternatively titled The Grasshopper and\\n\\nthe Ant ( or Ants ) , is one of Aesop 's Fables , numbered 373 in the Perry\\n\\nIndex . The fable describes how a hungry grasshopper begs for food from an ant\\n\\nwhen winter comes and is refused . The situation sums up moral lessons about the\\n\\nvirtues of hard work and planning for the future . Even in Classical times ,\\n\\nhowever , the advice was mistrusted and an alternative story represented the ant\\n\\n's industry as mean and self - serving . Jean de la Fontaine 's delicately\\n\\nironical retelling in French later widened the debate to cover the themes of\\n\\ncompassion and charity . Since the 18th century the grasshopper has been seen as\\n\\nthe type of the artist and the question of the place of culture in society has\\n\\nalso been included . Argument over the fable 's ambivalent meaning has generally\\n\\nbeen conducted through adaptation or reinterpretation of the fable in literature\\n\\n, arts and music . Contents ( hide ) 1 Fable and counter-fable 2 In art\\n\\n3 Later adaptations 4 Musical settings 5 Film and television treatments 6\\n\\nMoral and artistic debate 7 See also 8 References 9 External links\\n\\nFable and counter-fable ( edit ) The fable concerns a grasshopper ( in the\\n\\noriginal , a cicada ) that has spent the summer singing while the ant ( or ants\\n\\nin some versions ) worked to store up food for winter . When that season arrives\\n\\n, the grasshopper finds itself dying of hunger and begs the ant for food .\\n\\nHowever , the ant rebukes its idleness and tells it to dance the winter away now\\n\\n. Versions of the fable are found in the verse collections of Babrius ( 140 )\\n\\nand Avianus ( 34 ) , and in several prose collections including those attributed\\n\\nto Syntipas and Aphthonius of Antioch . The fable 's Greek original cicada is\\n\\nkept in the Latin and Romance\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content=\"Question:\\n\\nwhich city has the highest hiv rate in south africa\\n\\nAnswer:\\n\\nContext:\\n\\nHIV / AIDS in South Africa - Wikipedia HIV / AIDS in South Africa This\\n\\narticle needs to be updated . Please update this article to reflect recent\\n\\nevents or newly available information . ( July 2018 ) Estimated HIV\\n\\nprevalence among adults aged 15 - 49 by country in 2007 HIV / AIDS is the most\\n\\nserious health concern in South Africa . The country has the fourth - highest\\n\\nadult HIV prevalence rate in the world , according to the 2016 United Nations\\n\\nstatistics . According to a UNAids dataset sourced from the World Bank , in\\n\\n2016 the HIV prevalence rate for adults aged 15 to 49 was 27 % in Swaziland , 25\\n\\n% in Lesotho , 25 % in Botswana and 19 % in South Africa . Contents 1\\n\\nUnderstanding HIV prevalence 2 Latest data on HIV prevalence in South Africa\\n\\n3 Other statistics 3.1 By race 3.2 By gender 3.3 By pregnant women 3.4\\n\\nBy age 3.5 By province 4 Awareness campaigns 5 Co-infection with\\n\\ntuberculosis 6 History 6.1 1990 6.2 1993 6.3 1995 6.4 1996 6.5 1997\\n\\n6.6 1999 6.7 2000 6.8 2001 6.9 2002 7 Demographics 8 Aids denialism\\n\\nunder Thabo Mbeki 8.1 2000 8.2 2001 8.3 2003 8.4 2006 8.5 2007 9\\n\\nRole of the media in South Africa 's epidemic 10 See also 11 References 12\\n\\nFurther reading 13 External links Understanding HIV prevalence ( edit )\\n\\nHIV prevalence does not indicate that a country has an AIDS crisis , as HIV and\\n\\nAIDS are separate conditions . HIV prevalence , instead , indicates that people\\n\\nremain alive , despite the infection . South Africa has the largest HIV\\n\\ntreatment programme in the world . With the correct medication , HIV is a\\n\\nmanageable chronic condition , like diabetes or hypertension . A population with\\n\\na larger proportion of diabetics , means more people are receiving treatment for\\n\\nthe condition . Hence , a population with a larger proportion of HIV - positive\\n\\npeople , means more people are receiving anti-retroviral treatment . World\\n\\nBank Open Data explains the data it publishes on HI\", metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question:\\n\\nnow that's what i call music 17 songs\\n\\nAnswer:\\n\\nContext:\\n\\nNow That 's What I Call Music 17 ( UK series ) - wikipedia Now That 's What I\\n\\nCall Music 17 ( UK series ) Jump to : navigation , search This article\\n\\ndoes not cite any sources . Please help improve this article by adding citations\\n\\nto reliable sources . Unsourced material may be challenged and removed . (\\n\\nDecember 2009 ) ( Learn how and when to remove this template message ) This\\n\\narticle describes the 17th album in the UK Now ! series . It should not be\\n\\nconfused with identically - numbered albums from other Now ! series . For more\\n\\ninformation , see Now That 's What I Call Music ! 17 and Now That 's What I Call\\n\\nMusic ! discography . Now That 's What I Call Music 17 Compilation\\n\\nalbum by various artists Released 23 April 1990 Genre Pop Length\\n\\n2 : 05 : 00 Label Virgin / EMI / Polygram Series chronology Now\\n\\nThat 's What I Call Music 16 ( 1989 ) Now That 's What I Call Music 17 ( 1990\\n\\n) Now ! That 's What I Call Music 18 ( 1990 ) Now That 's What I Call\\n\\nMusic 17 or Now 17 is the 17th edition of the Now ! series in the United Kingdom\\n\\nand was released in April 1990 on vinyl , audio cassette , compact disc and VHS\\n\\n. Track listing ( edit ) CD / record / tape 1 No . Title Artist (\\n\\ns ) Length 1 . `` Blue Savannah '' Erasure 2 . `` Better World\\n\\n'' Rebel MC 3 . `` Opposites Attract '' Paula Abdul 4 . ``\\n\\nDub Be Good to Me '' Beats International 5 . `` Kingston Town ''\\n\\nUB40 6 . `` Strawberry Fields Forever '' Candy Flip 7 . `` I\\n\\nDo n't Wanna Lose You '' Tina Turner 8 . `` I Wish It Would Rain Down\\n\\n'' Phil Collins 9 . `` Step On '' Happy Mondays 10 . ``\\n\\nLoaded '' Primal Scream 11 . `` Enjoy the Silence '' Depeche Mode\\n\\n12 . `` Real Real Real '' Jesus Jones 13 . `` This Is How It Feels\\n\\n'' Inspiral Carpets 14 . `` Shine On '' The House of Love 15 .\\n\\n`` From Out of Nowhere ''\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question:\\n\\nwhen does model code of conduct come into force\\n\\nAnswer:\\n\\n<P> Election Commission of India 's Model Code of Conduct is a set of guidelines issued by the\\n\\nElection Commission of India for conduct of political parties and candidates during elections\\n\\nmainly with respect to speeches , polling day , polling booths , election manifestos , processions\\n\\nand general conduct . These set of norms has been evolved with the consensus of political parties\\n\\nwho have consented to abide by the principles embodied in the said code in its letter and spirit.\\n\\nThe Model Code of Conduct comes into force immediately on announcement of the election\\n\\nschedule by the commission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example , politicians should not\\n\\nmake hate speeches , putting one community against another or make promises about new\\n\\nprojects that may sway a voter . </P>\\n\\nContext:\\n\\nElection Commission of India 's Model code of Conduct - wikipedia Election\\n\\nCommission of India 's Model code of Conduct Jump to : navigation , search\\n\\nThis article needs more links to other articles to help integrate it into the\\n\\nencyclopedia . Please help improve this article by adding links that are\\n\\nrelevant to the context within the existing text . ( April 2014 ) ( Learn how\\n\\nand when to remove this template message ) Election Commission of India 's\\n\\nModel Code of Conduct is a set of guidelines issued by the Election Commission\\n\\nof India for conduct of political parties and candidates during elections mainly\\n\\nwith respect to speeches , polling day , polling booths , election manifestos ,\\n\\nprocessions and general conduct . These set of norms has been evolved with the\\n\\nconsensus of political parties who have consented to abide by the principles\\n\\nembodied in the said code in its letter and spirit. The Model Code of Conduct\\n\\ncomes into force immediately on announcement of the election schedule by the\\n\\ncommission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example ,\\n\\npoliticians should not make hate speeches , putting one community against\\n\\nanother or make promises about new projects that may sway a voter . For the\\n\\n2014 general election the code came into force on 5 March 2014 when the\\n\\nCommission announced the dates and remains in force till the end of the\\n\\nelectoral process . `` The Model Code of Conduct is crucial to make sure a\\n\\nlevel playing field among various contenders in the poll fray , '' said the\\n\\nChief Election Commissioner V.S. Sampath at the press conference . Main points\\n\\n( edit ) The main points of the code are : Government bodies are not to\\n\\nparticipate in any new recruitment process during the electoral process . The\\n\\ncontesting candidates and the campaigners must respect the home life of their\\n\\nrivals and should not disturb them by holding road shows or demonstrations\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content=\"Question:\\n\\nwhere is the greatest royal rumble taking place\\n\\nAnswer:\\n\\n<P> Greatest Royal Rumble was a professional wrestling pay - per - view event and WWE\\n\\nNetwork event promoted by WWE for their Raw and SmackDown brands . The event was held on\\n\\nApril 27 , 2018 at the King Abdullah Sports City 's King Abdullah International Stadium in Jeddah ,\\n\\nSaudi Arabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in the United\\n\\nStates at noon EDT , with a pre-show starting at 11 a.m. EDT . At the event , all men 's main\\n\\nroster championships were defended , in addition to a 50 - man Royal Rumble match . </P>\\n\\nContext:\\n\\nWWE Greatest Royal Rumble - Wikipedia WWE Greatest Royal Rumble Jump to :\\n\\nnavigation , search Greatest Royal Rumble Promotional poster featuring\\n\\nvarious WWE wrestlers Theme song ( s ) `` When Legends Rise '' by Godsmack\\n\\nInformation Promotion WWE Brand ( s ) Raw SmackDown Sponsor ( s\\n\\n) Saudi General Sports Authority Date April 27 , 2018 Attendance\\n\\n60,000 Venue King Abdullah International Stadium City Jeddah , Saudi\\n\\nArabia WWE Network event chronology WrestleMania 34 Greatest Royal\\n\\nRumble Backlash ( 2018 ) Greatest Royal Rumble was a professional\\n\\nwrestling pay - per - view event and WWE Network event promoted by WWE for their\\n\\nRaw and SmackDown brands . The event was held on April 27 , 2018 at the King\\n\\nAbdullah Sports City 's King Abdullah International Stadium in Jeddah , Saudi\\n\\nArabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in\\n\\nthe United States at noon EDT , with a pre-show starting at 11 a.m. EDT . At the\\n\\nevent , all men 's main roster championships were defended , in addition to a 50\\n\\nman Royal Rumble match . The card featured ten matches . In the main event ,\\n\\nBraun Strowman won the titular Greatest Royal Rumble match to become the\\n\\ninaugural Greatest Royal Rumble Champion . In the penultimate match , Brock\\n\\nLesnar retained the Universal Championship in a steel cage match against Roman\\n\\nReigns . On the undercard , the WWE Championship match between AJ Styles and\\n\\nShinsuke Nakamura resulted in a double countout , The Undertaker defeated Rusev\\n\\nin a casket match , and John Cena defeated Triple H in the opening match .\\n\\nContents ( hide ) 1 Production 1.1 Background 1.2 Storylines 2 Event\\n\\n2.1 Preliminary matches 2.2 Main event 3 Controversy 4 Results 4.1 Tag\\n\\nTeam Eliminator bracket 4.2 Greatest Royal Rumble match entrances and\\n\\neliminations 5 WWE Greatest Royal Rumble Championship 5.1 History 5.2\\n\\nChampionship belt design 5.3 Reigns 6\", metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question:\\n\\nwho died from the band faith no more\\n\\nAnswer:\\n\\n<P> Former Faith No More singer Chuck Mosley died on November 9 , 2017 , due to `` the\\n\\ndisease of addiction . '' He was 57 years old . </P>\\n\\nContext:\\n\\nFaith No More - Wikipedia Faith No More Jump to : navigation , search Faith\\n\\nNo More Faith No More performing in Portugal in 2009 Background\\n\\ninformation Also known as Faith No Man Sharp Young Men Origin\\n\\nSan Francisco , California , United States Genres Alternative metal\\n\\nfunk metal experimental rock Years active 1979 -- 1998 2009 --\\n\\npresent Labels Slash London Mordam Reclamation ! Ipecac\\n\\nAssociated acts Mr. Bungle Pop - O - Pies Website fnm.com\\n\\nMembers Mike Bordin Roddy Bottum Billy Gould Mike Patton Jon Hudson\\n\\nPast members List of Faith No More band members Faith No More ( sometimes\\n\\nabbreviated as FNM ) is an American rock band from San Francisco , California ,\\n\\nformed in 1979 . Before settling on their current name in 1982 , the band\\n\\nperformed under the names Sharp Young Men and later Faith No Man . Bassist Billy\\n\\nGould and drummer Mike Bordin are the longest remaining members of the band ,\\n\\nhaving been involved with Faith No More since its inception . The band underwent\\n\\nseveral lineup changes early in their career , along with some major changes\\n\\nlater on . The current lineup of Faith No More consists of Gould , Bordin ,\\n\\nkeyboardist / rhythm guitarist Roddy Bottum , lead guitarist Jon Hudson and\\n\\nvocalist / lyricist Mike Patton . After releasing six studio albums ,\\n\\nincluding their best - selling records The Real Thing ( 1989 ) and Angel Dust (\\n\\n1992 ) , Faith No More officially announced their breakup on April 20 , 1998 .\\n\\nThey have since reunited , embarked on The Second Coming Tour from 2009 to 2012\\n\\n, and released their seventh studio album , Sol Invictus , in May 2015 .\\n\\nContents ( hide ) 1 History 1.1 Early days ( 1979 -- 1984 ) 1.2 We Care a\\n\\nLot and Introduce Yourself ( 1985 -- 1988 ) 1.3 Mike Patton joins and The Real\\n\\nThing ( 1989 -- 1991 ) 1.4 Angel Dust ( 1992 -- 1994 ) 1.5 King for a Day\\n\\n... , Album of the Year and break - up ( 1995 -- 1998 ) 1.6 R\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content=\"Question:\\n\\nwhat is sauce for the goose is sauce for the gander examples\\n\\nAnswer:\\n\\nContext:\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander - Wikipedia\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander This page\\n\\nis an essay . It contains the advice or opinions of one or more Wikipedia\\n\\ncontributors . This page is not one of Wikipedia 's policies or guidelines , as\\n\\nit has not been thoroughly vetted by the community . Some essays represent\\n\\nwidespread norms ; others only represent minority viewpoints . Shortcuts WP\\n\\n: SAUCE WP : GOOSE WP : GANDER This page in a nutshell : This phrase\\n\\nis employed to expose holding forth a `` double standard . '' If some kind of\\n\\nbehavior is wrong , it 's probably wrong for both sides , not just one . Do n't\\n\\ndo it yourself either . There 's an old saying , `` What is sauce for the\\n\\ngoose is sauce for the gander . '' This meshes well with the Golden Rule , or\\n\\nethic of reciprocity , which is a key moral principle in many religions and\\n\\nphilosophies , and is often stated as `` Do unto others as you wish to be done\\n\\nfor you '' , or conversely , `` Do n't do unto others what you would not wish to\\n\\nbe done to you . '' Tasty sauces to enjoy on your stir - fried wikipedia . But\\n\\nare they reliable sauces ? Look up sauce for the goose in Wiktionary , the\\n\\nfree dictionary . Unfortunately , when the infighting here in Wikipedia gets\\n\\nheated , participants often forget this principle and do unto their opponents\\n\\nthings that would not be fair to be done unto them , and sometimes add insult to\\n\\ninjury by crying `` fowl '' if their opponents do in fact raise similar\\n\\nobjections to their own actions ( and those of their friends ) to the ones they\\n\\nraised against the opponents in the first place . These `` wars '' can easily\\n\\nturn both parties into hypocrites . Some of the sorts of things that violate\\n\\nthis principle include : Trying to squelch or discredit an opposing viewpoint\\n\\nby associating it with a banned editor who espoused something similar , when in\\n\\nfact some of your own viewpoints a\", metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content=\"Question:\\n\\nwho was the gospel of john written to\\n\\nAnswer:\\n\\nContext:\\n\\nGospel of John - wikipedia Gospel of John Books of the New Testament\\n\\nGospels Matthew Mark Luke John Acts Acts of the Apostles\\n\\nEpistles Romans 1 Corinthians 2 Corinthians Galatians Ephesians Philippians\\n\\nColossians 1 Thessalonians 2 Thessalonians 1 Timothy 2 Timothy Titus Philemon\\n\\nHebrews James 1 Peter 2 Peter 1 John 2 John 3 John Jude Apocalypse\\n\\nRevelation New Testament manuscripts This article is about\\n\\nthe book in the New Testament . For the film , see The Gospel of John ( film ) .\\n\\nNot to be confused with First Epistle of John . Part of a series of articles\\n\\non John in the Bible Johannine literature Gospel Epistles\\n\\nFirst Second Third Revelation Events Authorship Apostle\\n\\nBeloved disciple Evangelist Patmos Presbyter Related literature\\n\\nApocryphon Acts Signs Gospel See also Johannine Christianity\\n\\nLogos Holy Spirit in Johannine literature John 's vision of the Son of Man\\n\\nNew Testament people named John The Gospel According to John\\n\\nis the fourth of the canonical gospels . The work is anonymous , although it\\n\\nidentifies an unnamed `` disciple whom Jesus loved '' as the source of its\\n\\ntraditions . It is closely related in style and content to the three Johannine\\n\\nepistles , and most scholars treat the four books , along with the Book of\\n\\nRevelation , as a single corpus of Johannine literature , albeit not from the\\n\\nsame author . C.K. Barrett , and later Raymond E. Brown , suggested that a\\n\\ntradition developed around the `` Johannine Community '' , and that this\\n\\ntradition gave rise to the gospel . The discovery of a large number of papyrus\\n\\nfragments of manuscripts with Johannine themes has led more scholars to\\n\\nrecognize that the texts were among the most influential in the early Church .\\n\\nThe discourses contained in this gospel seem to be concerned with issues of the\\n\\nchurch -- synagogue debate at the time of composition . It is no\", metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content='Question:\\n\\nfor an asset to be considered money it must be\\n\\nAnswer:\\n\\nContext:\\n\\nAsset - wikipedia Asset This article is about the finance definition . For\\n\\nother uses , see Asset ( disambiguation ) . Part of a series on\\n\\nAccounting Historical cost Constant purchasing power Management\\n\\nTax Major types ( show ) Audit Budget Cost Forensic Financial\\n\\nFund Governmental Management Social Tax Key concepts ( show )\\n\\nAccounting period Accrual Constant purchasing power Economic entity Fair\\n\\nvalue Going concern Historical cost Matching principle Materiality\\n\\nRevenue recognition Unit of account Selected accounts ( show ) Assets\\n\\nCash Cost of goods sold Depreciation / Amortization Equity Expenses\\n\\nGoodwill Liabilities Profit Revenue Accounting standards ( show )\\n\\nGenerally - accepted principles Generally - accepted auditing standards\\n\\nConvergence International Financial Reporting Standards International\\n\\nStandards on Auditing Management Accounting Principles Financial\\n\\nstatements ( show ) Annual report Balance sheet Cash - flow Equity\\n\\nIncome Management discussion Notes to the financial statements\\n\\nBookkeeping ( show ) Bank reconciliation Debits and credits Double - entry\\n\\nsystem FIFO and LIFO Journal Ledger / General ledger T accounts Trial\\n\\nbalance Auditing ( show ) Financial Internal Firms Report\\n\\nPeople and organizations ( show ) Accountants Accounting organizations\\n\\nLuca Pacioli Development ( show ) History Research Positive\\n\\naccounting Sarbanes -- Oxley Act Business portal In\\n\\nfinancial accounting , an asset is an economic resource . Anything tangible or\\n\\nintangible that can be owned or controlled to produce value and that is held by\\n\\na company to produce positive economic value is an asset . Simply stated ,\\n\\nassets represent value of ownership that can be converted into cash ( although\\n\\ncash itself is also considered an asset ) . The balance sheet of a firm\\n\\nrecords the monetary value o', metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content='Question:\\n\\nhow many district in punjab and also write its name\\n\\nAnswer:\\n\\nContext:\\n\\nPunjab , India - Wikipedia Punjab , India This article is about a state of\\n\\nIndia . For a geographical region , see Punjab . For other uses of the name ,\\n\\nsee Punjab ( disambiguation ) . State in India Punjab State The\\n\\nonly state in India with a majority Sikh population , Punjab contains the Golden\\n\\nTemple , amongst the most important sites in Sikhism Seal Location\\n\\nof Punjab in India Coordinates ( Chandigarh ) : 30 ° 47 N 75 ° 50 E\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/\\n\\n30.79\\n\\n;\\n\\n75.84\\n\\nCoordinates\\n\\n:\\n\\n30\\n\\n°\\n\\n47\\n\\nN 75\\n\\n°\\n\\n50\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/ 30.79 ; 75.84 Country India Capital\\n\\nChandigarh Largest city Ludhiana Districts 22 Government\\n\\nGovernor VP Singh Badnore Chief Minister Captain Amarinder Singh ( INC )\\n\\nE\\n\\nE\\n\\nE\\n\\nLegislature Unicameral ( 117 seats ) Parliamentary constituency 13\\n\\nHigh Court Punjab and Haryana High Court Area Total 50,362 km (\\n\\n19,445 sq mi ) Area rank 20th Highest elevation 551 m ( 1,808 ft )\\n\\nLowest elevation 150 m ( 490 ft ) Population ( 2011 ) Total\\n\\n27,704,236 Rank 16th Density 550 / km ( 1,400 / sq mi ) Demonym\\n\\n( s ) Punjabi GDP ( 2017 -- 18 ) Total 4.65 lakh crore ( US $69\\n\\nbillion ) Per capita 142,958 ( US $2,100 ) Time zone IST ( UTC +\\n\\n05 : 30 ) ISO 3166 code IN - PB HDI 0.6614 ( medium ) HDI rank\\n\\n5th ( 2015 ) Official language Punjabi Website REMOVED_SECRET ^\\n\\nJoint Capital with Haryana . Common for Punjab , Haryana and Chandigarh .\\n\\nSymbols of Punjab Emblem Lion Capital of Ashoka with Wheat stem ( above )\\n\\nand Crossed Swords ( below ) Language Punjabi Dance Bhangra , Giddha\\n\\nAnimal Blackbuck Bird Baaz ( Accipiter gentilis ) Punjab ( /\\n\\npndb / ( listen ) ) is a state in northern India . Forming part of the\\n\\nlarger Punjab region , the state is bordered by the Indian states of Jammu and\\n\\nKashmir to the north , Himachal Pradesh to the east', metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 272.07it/s]\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/colbert/utils/amp.py:15: FutureWarning: `REMOVED_SECRET.autocast(args...)` is deprecated. Please use `REMOVED_SECRET('cuda', args...)` instead.\n",
      "  return REMOVED_SECRET.autocast() if self.activated else NullContextManager()\n",
      "100%|██████████| 1/1 [00:30<00:00, 30.43s/it]\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/REMOVED_SECRET/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [05:32<4:31:37, 332.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [07:19<2:39:58, 199.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [09:07<2:03:41, 157.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [10:55<1:46:04, 138.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [12:50<1:37:18, 129.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [14:48<1:32:18, 125.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [16:39<1:26:42, 120.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [18:44<1:25:28, 122.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [20:32<1:20:22, 117.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [22:44<1:21:28, 122.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [24:58<1:21:48, 125.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [27:05<1:19:59, 126.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [29:28<1:21:00, 131.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [31:22<1:15:38, 126.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [33:12<1:10:36, 121.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [35:19<1:09:34, 122.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [37:15<1:06:25, 120.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [39:13<1:04:05, 120.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [40:59<59:49, 115.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [42:46<56:34, 113.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [44:49<56:07, 116.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [46:36<52:55, 113.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [48:27<50:40, 112.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [50:30<50:09, 115.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [52:34<49:15, 118.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [54:36<47:48, 119.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [56:41<46:22, 120.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [58:44<44:34, 121.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [1:00:51<43:08, 123.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [1:02:52<40:49, 122.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:04:32<36:42, 115.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:06:25<34:30, 115.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:08:11<31:48, 112.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:10:16<30:56, 116.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:12:21<29:39, 118.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:14:17<27:30, 117.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:16:23<26:06, 120.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:18:39<25:01, 125.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:20:33<22:18, 121.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:22:40<20:31, 123.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:24:43<18:28, 123.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:26:31<15:50, 118.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:28:19<13:28, 115.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:30:22<11:46, 117.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [1:32:29<10:01, 120.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:34:24<07:55, 118.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [1:36:51<06:21, 127.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [1:39:35<04:36, 138.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [1:42:19<02:25, 145.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:44:21<00:00, 125.23s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(similarities)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m retrieval_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_retrieval_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m bertscore \u001b[38;5;241m=\u001b[39m calculate_bertscore(evaluation_results)\n\u001b[1;32m    108\u001b[0m semantic_similarity \u001b[38;5;241m=\u001b[39m calculate_semantic_similarity(evaluation_results)\n",
      "Cell \u001b[0;32mIn[1], line 75\u001b[0m, in \u001b[0;36mcalculate_retrieval_metrics\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     73\u001b[0m precisions, recalls, f1s \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m---> 75\u001b[0m     relevant_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelevant_docs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use first 10 words as identifier\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([doc\u001b[38;5;241m.\u001b[39msplit()[:\u001b[38;5;241m10\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)])  \u001b[38;5;66;03m# Simplification, adjust as needed\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(relevant_docs\u001b[38;5;241m.\u001b[39mintersection(retrieved_docs)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(retrieved_docs) \u001b[38;5;28;01mif\u001b[39;00m retrieved_docs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# RAG System Evaluation Notebook for Local PDFs\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score as bert_score\n",
    "import matplotlib.pyplot as plt\n",
    "from RAG_UTILS import RAGSystem, DocumentProcessor  # Import your existing RAG system\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "MODEL_ID = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
    "RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n",
    "PDF_FOLDER_PATH = \"local_database\"  # Update this to your local database path\n",
    "NUM_EVALUATION_SAMPLES = 50  # Number of questions to generate for evaluation\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = RAGSystem(\n",
    "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_id=MODEL_ID,\n",
    "    reranker_model=RERANKER_MODEL,\n",
    ")\n",
    "\n",
    "# Load and process documents\n",
    "doc_processor = DocumentProcessor(EMBEDDING_MODEL_NAME)\n",
    "raw_documents = doc_processor.load_pdfs_from_folder(PDF_FOLDER_PATH)\n",
    "processed_documents = doc_processor.split_documents(raw_documents)\n",
    "\n",
    "# Build vector database\n",
    "knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "\n",
    "# Initialize question generator\n",
    "question_generator = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\", device='cuda')\n",
    "\n",
    "def generate_questions(documents: List[dict], num_questions: int) -> List[Tuple[str, str]]:\n",
    "    questions_and_contexts = []\n",
    "    for _ in range(num_questions):\n",
    "        doc = random.choice(documents)\n",
    "        context = doc.page_content\n",
    "        question = question_generator(f\"Generate a question based on this text: {context}\", max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "        questions_and_contexts.append((question, context))\n",
    "    return questions_and_contexts\n",
    "\n",
    "# Generate evaluation questions\n",
    "eval_questions = generate_questions(processed_documents, NUM_EVALUATION_SAMPLES)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_rag(questions_and_contexts: List[Tuple[str, str]]) -> List[dict]:\n",
    "    results = []\n",
    "    for question, context in tqdm(questions_and_contexts, total=len(questions_and_contexts)):\n",
    "        answer, relevant_docs, _ = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"generated_answer\": answer,\n",
    "            \"relevant_docs\": relevant_docs\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_rag(eval_questions)\n",
    "\n",
    "# Helper functions for different metrics\n",
    "\n",
    "def calculate_retrieval_metrics(results: List[dict]) -> dict:\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for result in results:\n",
    "        relevant_docs = set([doc.split()[:10] for doc in result[\"relevant_docs\"]])  # Use first 10 words as identifier\n",
    "        retrieved_docs = set([doc.split()[:10] for doc in result[\"generated_answer\"].split('\\n')])  # Simplification, adjust as needed\n",
    "        precision = len(relevant_docs.intersection(retrieved_docs)) / len(retrieved_docs) if retrieved_docs else 0\n",
    "        recall = len(relevant_docs.intersection(retrieved_docs)) / len(relevant_docs) if relevant_docs else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return {\n",
    "        \"avg_precision\": np.mean(precisions),\n",
    "        \"avg_recall\": np.mean(recalls),\n",
    "        \"avg_f1\": np.mean(f1s)\n",
    "    }\n",
    "\n",
    "def calculate_bertscore(results: List[dict]) -> float:\n",
    "    references = [r[\"context\"] for r in results]\n",
    "    candidates = [r[\"generated_answer\"] for r in results]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def calculate_semantic_similarity(results: List[dict]) -> float:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        context_embedding = model.encode(result[\"context\"])\n",
    "        gen_embedding = model.encode(result[\"generated_answer\"])\n",
    "        similarity = np.dot(context_embedding, gen_embedding) / (REMOVED_SECRET(context_embedding) * REMOVED_SECRET(gen_embedding))\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# Calculate metrics\n",
    "retrieval_metrics = calculate_retrieval_metrics(evaluation_results)\n",
    "bertscore = calculate_bertscore(evaluation_results)\n",
    "semantic_similarity = calculate_semantic_similarity(evaluation_results)\n",
    "\n",
    "# Print results\n",
    "print(\"Retrieval Metrics:\")\n",
    "print(f\"Average Precision: {retrieval_metrics['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {retrieval_metrics['avg_recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {retrieval_metrics['avg_f1']:.4f}\")\n",
    "print(f\"BERTScore: {bertscore:.4f}\")\n",
    "print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'BERTScore', 'Semantic Similarity']\n",
    "values = [retrieval_metrics['avg_precision'], retrieval_metrics['avg_recall'], \n",
    "          retrieval_metrics['avg_f1'], bertscore, semantic_similarity]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, values)\n",
    "plt.title('RAG System Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation complete. Results saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "71795db6ad424ad7ba9ca63c99079cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `REMOVED_SECRET.GradScaler(args...)` is deprecated. Please use `REMOVED_SECRET('cuda', args...)` instead.\n",
      "  self.scaler = REMOVED_SECRET.GradScaler()\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:04<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question:\\n\\nwho owns st andrews golf course in scotland\\n\\nAnswer:\\n\\n<P> The Old Course at St Andrews is considered the oldest golf course in the world , a public\\n\\ncourse over common land in St Andrews , Fife , Scotland . It is held in trust by The St Andrews\\n\\nLinks Trust under an act of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have playing privileges on\\n\\nthe course , along with the general public . </P>\\n\\nContext:\\n\\nOld Course at St Andrews - wikipedia Old Course at St Andrews Jump to :\\n\\nnavigation , search Old Course R&A Clubhouse and 18th green in 2004 Club\\n\\ninformation\\n\\nCoordinates\\n\\n56 ° 20\\n\\n35 ''\\n\\nN 2 ° 48\\n\\n11 ''\\n\\n56.343 °\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Coordinates : 56 ° 20 35 '' N 2 ° 48 11 ''\\n\\nW\\n\\n56.343\\n\\n°\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Location St Andrews ,\\n\\nW\\n\\n/\\n\\nW\\n\\n/\\n\\nW\\n\\nScotland Established 1552 Type Public Owned by Fife Council\\n\\nOperated by St Andrews Links Trust Total holes 18 Tournaments hosted\\n\\nThe Open Championship , Alfred Dunhill Links Championship Website Old\\n\\nCourse Par 72 Length 7,305 yards ( 6,680 m ) Course record\\n\\n61 ; Ross Fisher ( 2017 ) St Andrews Location in Scotland St Andrews\\n\\nLocation in Fife , Scotland The Old Course at St Andrews is considered the\\n\\noldest golf course in the world , a public course over common land in St Andrews\\n\\n, Fife , Scotland . It is held in trust by The St Andrews Links Trust under an\\n\\nact of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have\\n\\nplaying privileges on the course , along with the general public . Contents\\n\\n( hide ) 1 History 1.1 Governance 1.2 Influence on modern golf 1.3 Old\\n\\nCourse and Bobby Jones 2 Features 3 The Open Championship 4 Scorecard\\n\\n5 Women 's British Open 6 Senior Open Championship 7 See also 8 References\\n\\n9 External links History ( edit ) The Old Course at St Andrews is\\n\\nconsidered by many to be the `` home of golf '' because the sport was first\\n\\nplayed on the Links at St Andrews in the early 15th century . Golf was becoming\\n\\nincreasingly popular in Scotland until in 1457 , when James II of Scotland\\n\\nbanned golf because he felt that young men were playing too much golf instead of\\n\\npractising their archery . The ban was upheld by the following kings of Scotland\\n\\nuntil 1502 , when King James IV became a\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question:\\n\\nequation for the velocity of an object in motion at constant acceleration\\n\\nAnswer:\\n\\nContext:\\n\\nEquations of motion - wikipedia Equations of motion Jump to : navigation ,\\n\\nsearch Classical mechanics F = m a ( \\\\ displaystyle ( \\\\ vec ( F ) ) =\\n\\nm ( \\\\ vec ( a ) ) ) Second law of motion History Timeline Branches\\n\\n( show ) Applied Celestial Continuum Dynamics Kinematics Kinetics\\n\\nStatics Statistical Fundamentals ( show ) Acceleration Angular\\n\\nmomentum Couple D'Alembert's principle Energy kinetic potential\\n\\nForce Frame of reference Impulse Inertia / Moment of inertia Mass\\n\\nMechanical power Mechanical work Moment Momentum Space Speed Time\\n\\nTorque Velocity Virtual work Formulations ( show ) Newton 's laws of\\n\\nmotion Analytical mechanics Lagrangian mechanics Hamiltonian mechanics\\n\\nRouthian mechanics Hamilton -- Jacobi equation Appell 's equation of motion\\n\\nUdwadia -- Kalaba equation Koopman -- von Neumann mechanics Core\\n\\ntopics ( show ) Damping ( ratio ) Displacement Equations of motion Euler\\n\\n's laws of motion Fictitious force Friction Harmonic oscillator\\n\\nInertial / Non-inertial reference frame Mechanics of planar particle motion\\n\\nMotion ( linear ) Newton 's law of universal gravitation Newton 's laws of\\n\\nmotion Relative velocity Rigid body dynamics Euler 's equations\\n\\nSimple harmonic motion Vibration Rotation ( show ) Circular motion\\n\\nRotating reference frame Centripetal force Centrifugal force reactive\\n\\nCoriolis force Pendulum Tangential speed Rotational speed Angular\\n\\nacceleration / displacement / frequency / velocity Scientists ( show )\\n\\nGalileo Newton Kepler Horrocks Halley Euler d'Alembert Clairaut\\n\\nLagrange Laplace Hamilton Poisson Daniel Bernoulli Johann Bernoulli\\n\\nCauchy In mathematical physics , equations of motion are\\n\\nequations that describe the behaviour of a physical system in terms of its\\n\\nmotion as a function of time . More specifically , the equations of motion\\n\\nde\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question:\\n\\nwho sang take that look off your face\\n\\nAnswer:\\n\\n<P> `` Take That Look Off Your Face '' is the title of a hit song by musical theatre composer\\n\\nAndrew Lloyd Webber . Collaborating with lyricist Don Black , it was written for the song cycle\\n\\nshow Tell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 , and\\n\\nbecame a No. 3 hit in the UK charts . The song was also popular in Ireland , and spent six weeks\\n\\nat number one . Later , Tell Me on a Sunday was combined with another Lloyd Webber work ,\\n\\nVariations , to form an entire new show , Song and Dance . </P>\\n\\nContext:\\n\\nTake that Look Off Your Face - Wikipedia Take that Look Off Your Face Jump to\\n\\n: navigation , search `` Take That Look Off Your Face '' Single by\\n\\nMarti Webb from the album Tell Me on a Sunday B - side `` Sheldon\\n\\nBloom '' Released January 1980 Format 7 '' single Recorded\\n\\n1979 Genre Pop , MOR , Theatrical Length 3 : 27 Label Polydor\\n\\nSongwriter ( s ) Andrew Lloyd Webber , Don Black Producer ( s ) Andrew\\n\\nLloyd Webber Marti Webb singles chronology `` D - Darling '' ( 1973 )\\n\\n`` Take That Look Off Your Face '' ( 1980 ) `` Tell Me on a Sunday '' ( 1980 )\\n\\n`` D - Darling '' ( 1973 ) `` Take That Look Off Your Face '' ( 1980 ) ``\\n\\nTell Me on a Sunday '' ( 1980 ) `` Take That Look Off Your Face '' is the\\n\\ntitle of a hit song by musical theatre composer Andrew Lloyd Webber .\\n\\nCollaborating with lyricist Don Black , it was written for the song cycle show\\n\\nTell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 ,\\n\\nand became a No. 3 hit in the UK charts . The song was also popular in Ireland ,\\n\\nand spent six weeks at number one . Later , Tell Me on a Sunday was combined\\n\\nwith another Lloyd Webber work , Variations , to form an entire new show , Song\\n\\nand Dance . The song is about a woman being told of her boyfriend 's\\n\\ninfidelity . The woman denies this initially , before rebuking her newsbearer (\\n\\na girlfriend ) with the revelation that she `` knew before '' and had done for\\n\\nsome time . She also spends much of the song criticising her friend for rushing\\n\\nto break the `` bad news '' to her . Despite having been written during the\\n\\ncreative process for Tell Me on a Sunday , the song was n't recorded during the\\n\\nalbum 's principal sessions . Black reminded Lloyd Webber that they had missed a\\n\\ntrack , then entitled `` You Must Be Mistaken '' . John Mole , the bass guitar\\n\\nplayer , improvised a part reminiscent of the arrangement style of Phil Spector\\n\\n, inspiring the rest of the orchestra\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content='Question:\\n\\nwho was gails most recent husband in coronation street\\n\\nAnswer:\\n\\nContext:\\n\\nGail McIntyre - wikipedia Gail McIntyre Gail McIntyre Coronation\\n\\nStreet character Portrayed by Helen Worth Duration 1974 -- First\\n\\nappearance Episode 1412 29 July 1974 Introduced by H.V. Kershaw Book\\n\\nappearances Coronation Street : The Complete Saga Norman Bates with a\\n\\nBriefcase : The story of Richard Hillman Spin - off appearances East\\n\\nStreet ( 2010 ) Classification Present ; regular Profile Other\\n\\nnames Gail Potter Gail Tilsley Gail Platt Gail McIntyre Gail Hillman\\n\\nGail Rodwell Occupation Receptionist Cleaner Waitress Factory\\n\\nWorker Newsagent Home 8 Coronation Street ( 1991 - 33 Hammond Road\\n\\n( 1985 - 1991 ) 5 Buxton Close ( 1980 - 1983 ) 5 Coronation Street ( 1979 -\\n\\n1980 , 1983 - 1985 ) 11 Coronation Street ( 1976 - 1979 ) 15a Coronation\\n\\nStreet ( 1975 - 1976 ) show Family Father Ted Page Mother\\n\\nAudrey Roberts Stepfather Alf Roberts Half - brothers Stephen Reid\\n\\nHusband Brian Tilsley ( 1979 -- 1987 , 1988 -- 1989 ) Martin Platt ( 1991\\n\\n-- 2001 ) Richard Hillman ( 2002 -- 2003 ) Joe McIntyre ( 2010 ) Michael\\n\\nRodwell ( 2015 -- 2016 ) Sons Nick Tilsley David Platt Daughters\\n\\nSarah Platt Stepdaughters Tina McIntyre Grandsons Billy Platt\\n\\nHarry Platt Max Turner ( step ) Granddaughters Bethany Platt Lily\\n\\nPlatt Grandfathers Robert Potter Grandmothers Nancy Potter\\n\\nGail Rodwell ( also Potter , Tilsley , Platt , Hillman and McIntyre ) is a\\n\\nfictional character from the British ITV soap opera , Coronation Street .\\n\\nPortrayed by Helen Worth , the character first appeared on - screen on 29 July\\n\\n1974 . As of 2018 , Gail has been on the show for 44 years , which currently\\n\\nmakes her the third longest - running character on the show after Ken Barlow and\\n\\nRita Tanner . Gail is the daughter of Audrey Roberts ( Sue Nicholls ) and Ted\\n\\nPage ( Michael Byrne ) and is the mother of Nick Tilsley (', metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content=\"Question:\\n\\nwhen did they figure out that yeast made bread rise\\n\\nAnswer:\\n\\n<P> The most common source of leavening in antiquity was to retain a piece of dough ( with\\n\\nsugar and water in ) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to produce `` a\\n\\nlighter kind of bread than other peoples . '' Parts of the ancient world that drank wine instead of\\n\\nbeer used a paste composed of grape must and flour that was allowed to begin fermenting , or\\n\\nwheat bran steeped in wine , as a source for yeast . </P>\\n\\nContext:\\n\\nHistory of bread - wikipedia History of bread Jump to : navigation , search\\n\\nSlab stele from mastaba tomb of Itjer at Giza . 4th Dynasty , 2543 - 2435 BC .\\n\\nItjer is seated at a table with slices of bread , shown vertical by convention .\\n\\nEgyptian Museum , Turin Bread was central to the formation of early human\\n\\nsocieties . From the western half of Asia , where wheat was domesticated ,\\n\\ncultivation spread north and west , to Europe and North Africa . This in turn\\n\\nled to the formation of towns , as opposed to the nomadic lifestyle , and gave\\n\\nrise to more and more sophisticated forms of societal organization . Similar\\n\\ndevelopments occurred in eastern Asia , centered on rice , and in the Americas\\n\\nwith maize . Contents ( hide ) 1 Antiquity 2 Middle Ages 3 To the\\n\\n19th century 4 Industrialization 5 See also 6 Notes Antiquity ( edit\\n\\n) Conical loaves of bread as grave goods exactly as laid out in the Great Tomb\\n\\n, North Necropolis , Gebelein , 5th Dynasty ( Old Kingdom ) , 2435 - 2305 BC .\\n\\nExcavations by Ernesto Schiaparelli , 1911 . Egyptian Museum , Turin , S. 14051\\n\\n14055 There is extensive evidence of breadmaking in Ancient Egypt in the form\\n\\nof artistic depictions , remains of structures and items used in bread making ,\\n\\nand remains of the dough and bread itself . The most common source of\\n\\nleavening in antiquity was to retain a piece of dough ( with sugar and water in\\n\\n) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to\\n\\nproduce `` a lighter kind of bread than other peoples . '' Parts of the ancient\\n\\nworld that drank wine instead of beer used a paste composed of grape must and\\n\\nflour that was allowed to begin fermenting , or wheat bran steeped in wine , as\\n\\na source for yeast . The idea of a free - standing oven that could be pre-\\n\\nheated , with a door for access , appears to have been Greek . Even in\\n\\nantiquity there were a wide variety of breads\", metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question:\\n\\nwho led the various reform movements of the 19th century\\n\\nAnswer:\\n\\nContext:\\n\\nConservation movement - wikipedia Conservation movement Jump to : navigation ,\\n\\nsearch For specific types of conservation , see Conservation ( disambiguation )\\n\\n. `` Conservationism '' redirects here . It is not to be confused with\\n\\nConservatism . Much attention has been given to preserving the natural\\n\\ncharacteristics of Hopetoun Falls , Australia , while allowing ample access for\\n\\nvisitors . Part of the Politics series Party politics Political\\n\\nspectrum Left - wing Far - left Hard - Left Extreme left\\n\\nCentre Centre - left Radical center Centre - right , Third Position\\n\\nRight - wing Far - right Hard right New right Alt - right Alt -\\n\\nlite Party platform Extremist Radical Moderate\\n\\nReformist Syncretic Third Position Conservative Fundamentalist\\n\\nReactionary Party system Non-partisan One - party\\n\\nDominant - party Two - party Multi-party Coalition Hung\\n\\nparliament Confidence and supply Minority government Rainbow coalition\\n\\nGrand coalition Full coalition National unity government Majority\\n\\ngovernment Lists Ruling parties by country Political parties by UN\\n\\ngeoscheme Political ideologies Politics portal The\\n\\nconservation movement , also known as nature conservation , is a political ,\\n\\nenvironmental and a social movement that seeks to protect natural resources\\n\\nincluding animal and plant species as well as their habitat for the future .\\n\\nThe early conservation movement included fisheries and wildlife management ,\\n\\nwater , soil conservation and sustainable forestry . The contemporary\\n\\nconservation movement has broadened from the early movement 's emphasis on use\\n\\nof sustainable yield of natural resources and preservation of wilderness areas\\n\\nto include preservation of biodiversity . Some say the conservation movement is\\n\\npart of the broader and more far - reaching environmental movement , while\\n\\nothers arg\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content=\"Question:\\n\\nwho has climbed the great wall of china\\n\\nAnswer:\\n\\nContext:\\n\\nGreat Wall of China - wikipedia Great Wall of China Jump to : navigation ,\\n\\nsearch `` Great Wall '' redirects here . For other uses , see Great Wall (\\n\\ndisambiguation ) . Great Wall of China The Great Wall of China\\n\\nat Jinshanling Map of all the wall constructions General information\\n\\nType Fortification Country China Coordinates 40 ° 41 N 117 ° 14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Coordinates : 40 ° 41 N 117\\n\\n°\\n\\n14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Technical details\\n\\nSize 21,196 km ( 13,171 mi ) UNESCO World Heritage Site Criteria\\n\\nCultural : ( i ) , ( ii ) , ( iii ) , ( iv ) , ( vi ) Reference 438\\n\\n°\\n\\n°\\n\\nE\\n\\n/\\n\\nE\\n\\nE\\n\\n/\\n\\nE\\n\\nInscription 1987 ( 11th Session ) ( edit on Wikidata ) Great\\n\\nWall of China Simplified Chinese Traditional Chinese\\n\\nLiteral meaning `` The Long Wall '' ( show ) Transcriptions\\n\\nStandard Mandarin Hanyu Pinyin Chángchéng Wade -- Giles Ch'ang -\\n\\nch'eng\\n\\nIPA\\n\\nh\\n\\n) Wu Romanization Saon sen Yue :\\n\\nCantonese\\n\\nYale Romanization\\n\\nCheung sing\\n\\ntsh\\n\\n. s )\\n\\nJyutping\\n\\nCoeng sing\\n\\nSouthern Min\\n\\nTn\\n\\ng - siân Tâi -\\n\\nlô\\n\\nTn\\n\\ng - siânn Alternative Chinese name Simplified Chinese\\n\\nTraditional Chinese Literal meaning `` The 10,000 - Mile Long Wall\\n\\n'' ( show ) Transcriptions Wu Romanization Vae - li saon - sen\\n\\nYue : Cantonese Yale Romanization Maan lei Cheung sing IPA ( màn.\\n\\nle\\n\\ni\\n\\n(\\n\\nIPA\\n\\nHokkien POJ\\n\\nh.\\n\\n(\\n\\ntsh\\n\\n. s ) Jyutping Maan - lei coeng - sing Southern Min\\n\\nTâi\\n\\n\\n\\nlô\\n\\nBn\\n\\ntn\\n\\ng - siânn The Great Wall of China is a series\\n\\nof fortifications made of stone , brick , tamped earth , wood , and other\\n\\nmaterials , generally built along an east - to - west line across the historical\\n\\nnorthern borders of China to protect the Chinese states and empires against the\\n\\nraids and invasions of the various nomadic groups of the Eu\\n\\n\\n\\nlí\", metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content='Question:\\n\\nwhen did star trek the next generation first air\\n\\nAnswer:\\n\\n<Table> <Tr> <Th colspan=\"2\"> Season </Th> <Th colspan=\"2\"> Episodes </Th> <Th\\n\\ncolspan=\"2\"> Originally aired </Th> </Tr> <Tr> <Th> First aired </Th> <Th> Last aired </Th>\\n\\n</Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 28 , 1987 ( 1987 - 09 - 28 ) </Td> <Td> May 16 , 1988 ( 1988 - 05 - 16\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 22 </Td> <Td\\n\\ncolspan=\"1\"> November 21 , 1988 ( 1988 - 11 - 21 ) </Td> <Td> July 17 , 1989 ( 1989 - 07 - 17 )\\n\\n</Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 25 , 1989 ( 1989 - 09 - 25 ) </Td> <Td> June 18 , 1990 ( 1990 - 06 - 18\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 24 , 1990 ( 1990 - 09 - 24 ) </Td> <Td> June 17 , 1991 ( 1991 - 06 - 17\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 5 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 23 , 1991 ( 1991 - 09 - 23 ) </Td> <Td> June 15 , 1992 ( 1992 - 06 - 15\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 6 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 21 , 1992 ( 1992 - 09 - 21 ) </Td> <Td> June 21 , 1993 ( 1993 - 06 - 21\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 7 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 20 , 1993 ( 1993 - 09 - 20 ) </Td> <Td> May 23 , 1994 ( 1994 - 05 - 23\\n\\n) </Td> </Tr> </Table>\\n\\nContext:\\n\\nStar Trek : the Next Generation - wikipedia Star Trek : the Next Generation\\n\\nJump to : navigation , search This article is about the television series . For\\n\\nthe games , see Star Trek : The Next Generation ( 1994 video game ) and Star\\n\\nTrek : The Next Generation : A World For All Seasons . Star Trek : The Next\\n\\nGeneration Genre Science fiction Drama Mystery Action\\n\\nadventure Created by Gene Roddenberry Based on Star Trek by Gene\\n\\nRoddenberry Starring Patrick Stewart Jonathan Frakes Brent Spiner\\n\\nLeVar Burton Denise Crosby Michael Dorn Gates McFadden Marina Sirtis\\n\\nWil Wheaton Theme music composer Alexander Courage Jerry Goldsmith\\n\\nComposer ( s ) Dennis McCarthy Jay Chattaway Ron Jones Country of origin\\n\\nUnited States Original language ( s ) English No. of seasons 7\\n\\nNo. of episodes 178 ( list of episodes ) Production Executive producer\\n\\n( s ) Gene Roddenberry ( 1987 -- 91 ) Rick Berman ( 1989 -- 94 )\\n\\nShowrunners Maurice Hurley ( 1988 -- 89 ) Michael Piller ( 1989 -- 94 )\\n\\nJeri Taylor ( 1993 -- 94 ) Cinematography Edward R. Brown ( 1987 -- 89\\n\\n) Marvin V. Rush ( 1989 -- 92 ) Jonathan West ( 1992 -- 94 ) Running\\n\\ntime 44 minutes Production company ( s ) Paramount Domestic Television\\n\\nDistributor CBS Television Distribution Budget $1.3 million per episode\\n\\nRelease Original network First - run syndication Picture format\\n\\nNTSC 480i 4 : 3 1080p 4 : 3 ( Blu - ray ) Audio format Dolby SR\\n\\nDolby Digital 5.1 ( DVD ) DTS - HD Master Audio 7.1 Blu - ray Original\\n\\nrelease September 28 , 1987 ( 1987 - 09 - 28 ) -- May 23 , 1994 ( 1994 - 05 -\\n\\n23 ) Chronology Preceded by Star Trek : The Animated Series\\n\\nFollowed by Star Trek : Deep Space Nine Related shows Star Trek TV\\n\\nseries External links Star Trek : The Next Generation at StarTrek.com\\n\\nStar Trek : The Next Generation ( abbreviated as TNG and ST : TNG ) i', metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content=\"Question:\\n\\nwhere were deep-sea hydrothermal vents first discovered 25 years ago\\n\\nAnswer:\\n\\nContext:\\n\\nHydrothermal vent - wikipedia Hydrothermal vent Jump to : navigation , search\\n\\nMarine habitats White smokers emitting liquid rich in barium , calcium ,\\n\\nsilicon and carbon dioxide at the Champagne vent , Northwest Eifuku volcano ,\\n\\nMarianas Trench Marine National Monument Littoral zone Intertidal zone\\n\\nEstuaries Kelp forests Coral reefs Ocean banks Continental shelf\\n\\nNeritic zone Straits Pelagic zone Oceanic zone Seamounts Hydrothermal\\n\\nvents Cold seeps Demersal zone Benthic zone A\\n\\nhydrothermal vent is a fissure in a planet 's surface from which geothermally\\n\\nheated water issues . Hydrothermal vents were discovered years ago in 1977 .\\n\\nHydrothermal vents are commonly found near volcanically active places , areas\\n\\nwhere tectonic plates are moving apart at spreading centers , ocean basins , and\\n\\nhotspots . Hydrothermal vents exist because the earth is both geologically\\n\\nactive and has large amounts of water on its surface and within its crust .\\n\\nCommon land types include hot springs , fumaroles and geysers . Under the sea ,\\n\\nhydrothermal vents may form features called black smokers . Relative to the\\n\\nmajority of the deep sea , the areas around submarine hydrothermal vents are\\n\\nbiologically more productive , often hosting complex communities fueled by the\\n\\nchemicals dissolved in the vent fluids . Chemosynthetic bacteria and archaea\\n\\nform the base of the food chain , supporting diverse organisms , including giant\\n\\ntube worms , clams , limpets and shrimp . Active hydrothermal vents are believed\\n\\nto exist on Jupiter 's moon Europa , and Saturn 's moon Enceladus , and it is\\n\\nspeculated that ancient hydrothermal vents once existed on Mars . Contents\\n\\n( hide ) 1 Physical properties 2 Black smokers and white smokers 3\\n\\nBiological communities 4 Biological theories 4.1 The Deep Hot Biosphere\\n\\n4.2 Hydrothermal origin of life 5 Discovery and exploration 6 Distribution\\n\\n7 Exploitation 8 Conservation 9 See also 10 References\", metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question:\\n\\nthe period of european history between ancient and modern eras\\n\\nAnswer:\\n\\nContext:\\n\\nHistory of Europe - wikipedia History of Europe Jump to : navigation , search\\n\\nThe history of Europe covers the peoples inhabiting Europe from prehistory to\\n\\nthe present . The period known as classical antiquity began with the emergence\\n\\nof the city - states of ancient Greece . Later , the Roman Empire came to\\n\\ndominate the entire Mediterranean basin . The fall of the Roman Empire in AD 476\\n\\ntraditionally marks the start of the Middle Ages . Beginning in the 14th century\\n\\na Renaissance of knowledge challenged traditional doctrines in science and\\n\\ntheology . Simultaneously , the Protestant Reformation set up Protestant\\n\\nchurches primarily in Germany , Scandinavia and England . After 1800 , the\\n\\nIndustrial Revolution brought prosperity to Britain and Western Europe . The\\n\\nmain powers set up colonies in most of the Americas and Africa , and parts of\\n\\nAsia . In the 20th century , World War I , and World War II resulted in massive\\n\\nnumbers of deaths . The Cold War dominated European geo - politics from 1947 to\\n\\n1989 . Unification into a European Union moved forward after 1950 , with some\\n\\nsetbacks . Today , most countries west of Russia belong to the NATO military\\n\\nalliance , along with the United States and Canada . Europe depicted by Antwerp\\n\\ncartographer Abraham Ortelius in 1595 Contents ( hide ) 1 Overview 2\\n\\nPrehistory 3 Minoans and Mycenae 2700 -- 1100 BC 4 Classical antiquity 4.1\\n\\nAncient Greece 4.2 The rise of Rome 4.3 Decline of the Roman Empire 4.4\\n\\nLate Antiquity and Migration Period 5 Middle Ages 5.1 Byzantium 5.2\\n\\nEarly Middle Ages 5.2. 1 Feudal Christendom 5.3 High Middle Ages 5.3. 1\\n\\nA divided church 5.3. 2 Holy wars 5.4 Late Middle Ages 6 Early modern\\n\\nEurope 6.1 Renaissance 6.2 Exploration and trade 6.3 Reformation 6.4\\n\\nMercantilism and colonial expansion 6.5 Crisis of the 17th century 6.6 Age\\n\\nof Absolutism 6.6. 1 Thirty Years ' War 1618 -- 1648 6.6. 2 War of the\\n\\nSpanish Succession 6.6. 3 Prussia 6.6. 4 Rus\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question:\\n\\nwho sang the most wonderful summer of my life\\n\\nAnswer:\\n\\n<P> Jackie Ward ( born Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an\\n\\nAmerican singer , regarded as a `` one - hit wonder '' of 1963 million - selling song `` Wonderful\\n\\nSummer '' . However , using her real name she was highly accomplished and successful singing in\\n\\ngroups . Ward 's voice is heard in U.S. television series , motion pictures , advertisements , and\\n\\npop records . She is one of the real singers of the hits attributed to The Partridge Family . </P>\\n\\nContext:\\n\\nRobin Ward ( singer ) - wikipedia Robin Ward ( singer ) This article may\\n\\nneed to be rewritten entirely to comply with Wikipedia 's quality standards .\\n\\nYou can help . The discussion page may contain suggestions . ( January 2018 )\\n\\nRobin Ward Birth name Jacqueline McDonnell Also known as Jackie Ward\\n\\n1941 ( age 76 -- 77 ) Hawaii , USA Genres Pop , TV theme songs , Movie\\n\\nsongs , Advertising Occupation ( s ) Singer Instruments Voice\\n\\nYears active 1954 -- 1979 Labels Dot Records Associated acts\\n\\nPartridge Family , Ray Conniff Singers , Ron Hicklin Singers Jackie Ward (\\n\\nborn Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an American\\n\\nsinger , regarded as a `` one - hit wonder '' of 1963 million - selling song ``\\n\\nWonderful Summer '' . However , using her real name she was highly accomplished\\n\\nand successful singing in groups . Ward 's voice is heard in U.S. television\\n\\nseries , motion pictures , advertisements , and pop records . She is one of the\\n\\nreal singers of the hits attributed to The Partridge Family . Contents 1\\n\\nBiography 1.1 Early years 1.2 `` Wonderful Summer '' 1.3 Post `` Robin\\n\\nWard '' TV , movies , and records singing 1.4 The Partridge Family 2\\n\\nReferences 3 External links Biography ( edit ) Early years ( edit )\\n\\nWard was born Jacqueline McDonnell in 1941 to a military family in Hawaii ( her\\n\\nfather served in the US Navy ) and raised in Nebraska . Her first public singing\\n\\nperformances were with her two sisters in a Nebraska church when she was eight\\n\\nyears old . After the trio won a national talent search run by Horace Heidt ,\\n\\nthey moved to Los Angeles to seek work in the music industry . At the age of\\n\\n13 , Ward was hired by Los Angeles television station KTLA to sing on a Your Hit\\n\\nParade - like program , Bandstand Revue ; Ward performed popular hits for four\\n\\nyears . Then she started a career of singing on demo and released recordings .\\n\\nOne 1962 session was singing the `` la la\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question:\\n\\nhow many beverly hills cops movies are there\\n\\nAnswer:\\n\\n<P> Beverly Hills Cop is a series of American action comedy films and an unaired television pilot\\n\\nbased on characters created by Daniel Petrie , Jr. and Danilo Bach . The films star Eddie Murphy\\n\\nas Axel Foley , a street - smart Detroit cop who travels to Beverly Hills , California to investigate\\n\\ncrimes , even though it is out of his jurisdiction . There , he meets Detective Billy Rosewood (\\n\\nJudge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and Lieutenant Andrew Bogomil ( Ronny\\n\\nCox ) . Ashton and Cox do not appear in Beverly Hills Cop III . Murphy , Reinhold , and Gil Hill ,\\n\\nwho plays Axel 's boss , Inspector Todd , are the only actors who appear in all three films . Harold\\n\\nFaltermeyer produced the now famous `` Axel F '' theme song heard throughout the series . The\\n\\nseries as a whole have been distributed by Paramount Pictures . The films have made a total of $\\n\\n735,534,503 at the worldwide box office . </P>\\n\\nContext:\\n\\nBeverly Hills Cop ( film series ) - wikipedia Beverly Hills Cop ( film series )\\n\\nJump to : navigation , search Beverly Hills Cop Directed by\\n\\nMartin Brest ( I ) Tony Scott ( II ) John Landis ( III ) Adil El Arbi ( IV\\n\\n) Bilall Fallah ( IV ) Produced by Jerry Bruckheimer ( I - II , IV )\\n\\nDon Simpson ( I - II ) Mace Neufeld ( III ) Robert Rehme ( III ) Eddie\\n\\nMurphy ( IV ) Screenplay by Daniel Petrie , Jr . ( I ) Larry\\n\\nFerguson ( II ) Warren Skaaren ( II ) Steven E. de Souza ( III ) Josh\\n\\nAppelbaum ( IV ) André Nemec ( IV ) Story by Danilo Bach ( I )\\n\\nDaniel Petrie , Jr . ( I ) Eddie Murphy ( II ) Robert D. Wachs ( II )\\n\\nSteven E. de Souza ( III ) Josh Appelbaum ( IV ) André Nemec ( IV )\\n\\nStarring Eddie Murphy Judge Reinhold John Ashton ( l - ll , lV ) Gil\\n\\nHill ( l - lll ) Ronny Cox ( I - II ) Brandon T. Jackson ( Unaired pilot )\\n\\nMusic by Harold Faltermeyer ( I - II ) Nile Rodgers ( III )\\n\\nCinematography Bruce Surtees ( I ) Jeffrey L. Kimball ( II ) Mac Ahlberg\\n\\n( III ) Dante Spinotti ( IV ) Edited by Billy Weber ( I - II )\\n\\nArthur Coburn ( I ) Chris Lebenzon ( II ) Michael Tronick ( II ) Dale\\n\\nBeldin ( III ) Production company Simpson / Bruckheimer ( I - II )\\n\\nEddie Murphy Productions ( I - III ) Distributed by Paramount Pictures\\n\\nRelease date 1984 - 1994 Running time 312 minutes Country United\\n\\nStates Language English Budget $85 million Box office $735.5\\n\\nmillion Beverly Hills Cop is a series of American action comedy films and an\\n\\nunaired television pilot based on characters created by Daniel Petrie , Jr. and\\n\\nDanilo Bach . The films star Eddie Murphy as Axel Foley , a street - smart\\n\\nDetroit cop who travels to Beverly Hills , California to investigate crimes ,\\n\\neven though it is out of his jurisdiction . There , he meets Detective Billy\\n\\nRosewood ( Judge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and\\n\\nLieu\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question:\\n\\ndale carnegie how to win and influence friends pdf\\n\\nAnswer:\\n\\nContext:\\n\\nHow to Win Friends and Influence people - wikipedia How to Win Friends and\\n\\nInfluence people Jump to : navigation , search For the Terrorvision album , see\\n\\nHow to Make Friends and Influence People . How to Win Friends and Influence\\n\\nPeople First edition , 11th printing ( February 1937 ) Author Dale\\n\\nCarnegie Country United States Language English Subject Self -\\n\\nhelp Genre Non-fiction Publisher Simon and Schuster ( 1936 )\\n\\nPublication date October 1936 Media type Print ( hardcover / paperback )\\n\\nPages 291 pp ISBN 1 - 4391 - 6734 - 6 OCLC 40137494 How to Win\\n\\nFriends and Influence People is a self - help book written by Dale Carnegie ,\\n\\npublished in 1936 . Over 30 million copies have been sold world - wide , making\\n\\nit one of the best - selling books of all time . In 2011 , it was number 19 on\\n\\nTime Magazine 's list of the 100 most influential books . In 1934 , Leon\\n\\nShimkin of the publishing firm Simon & Schuster took one of Carnegie 's 14 -\\n\\nweek courses ; afterward , Shimkin persuaded Carnegie to let a stenographer take\\n\\nnotes from the course to be revised for publication . The original book\\n\\ncontained colorful anecdotes and insightful wisdom , and gave instruction in\\n\\nhandling people , `` winning '' friends , bringing people to your way of\\n\\nthinking , being a great leader , and successfully navigating home life .\\n\\nCarnegie combined age - old truisms with the emerging field of psychology to\\n\\npresent a handbook in human relations which was interesting and accessible .\\n\\nEmphasizing using others ' egotistical tendencies to one 's advantage , Carnegie\\n\\nmaintained that success could be found by charm , appreciation , and personality\\n\\n. The book sold exceptionally well from the start , going through 17 editions in\\n\\nits first year alone . In 1981 , a revised edition containing updated language\\n\\nand anecdotes was released . The revised edition reduced the number of sections\\n\\nfrom six to four , eliminating sections on effectiv\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question:\\n\\nthe human tendency to mimic other peoples behavior is an example of\\n\\nAnswer:\\n\\n<P> Mirroring is the behaviour in which one person subconsciously imitates the gesture , speech\\n\\npattern , or attitude of another . Mirroring often occurs in social situations , particularly in the\\n\\ncompany of close friends or family . The concept often affects other individuals ' notions about\\n\\nthe individual that is exhibiting mirroring behaviors , which can lead to the individual building\\n\\nrapport with others . </P>\\n\\nContext:\\n\\nMirroring ( psychology ) - wikipedia Mirroring ( psychology ) This\\n\\narticle needs additional citations for verification . Please help improve this\\n\\narticle by adding citations to reliable sources . Unsourced material may be\\n\\nchallenged and removed . ( August 2015 ) ( Learn how and when to remove this\\n\\ntemplate message ) Mirroring in an argument . Mirroring is the behaviour in\\n\\nwhich one person subconsciously imitates the gesture , speech pattern , or\\n\\nattitude of another . Mirroring often occurs in social situations , particularly\\n\\nin the company of close friends or family . The concept often affects other\\n\\nindividuals ' notions about the individual that is exhibiting mirroring\\n\\nbehaviors , which can lead to the individual building rapport with others .\\n\\nMirroring is the subconscious replication of another person 's nonverbal signals\\n\\n. This concept takes place in everyday interactions , and often goes unnoticed\\n\\nby both the person enacting the mirroring behaviors as well as the individual\\n\\nwho is being mirrored . The activation of mirror neurons takes place within the\\n\\nindividual who begins to mirror another 's movements , and allows them a greater\\n\\nconnection and understanding with the individual who they are mirroring , as\\n\\nwell as allowing the individual who is being mirrored to feel a stronger\\n\\nconnection with the other individual . Mirroring is distinct from conscious\\n\\nimitation under the premise that while the latter is a conscious , typically\\n\\novert effort to copy another person , mirroring is subconsciously done during\\n\\nthe act and often goes unnoticed . The display of mirroring often begins as\\n\\nearly as infancy , as babies begin to mimic individuals around them and\\n\\nestablish connections with particular body movements . The ability to mimic\\n\\nanother person 's actions allows the infant to establish a sense of empathy and\\n\\nthus begin to understand another person 's emotions . The infant continues to\\n\\nestablish connections with other individual 's emotions and subsequent\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question:\\n\\nwho invented the use of electricity during the industrial revolution\\n\\nAnswer:\\n\\nContext:\\n\\nIndustrial Revolution - wikipedia Industrial Revolution Jump to : navigation ,\\n\\nsearch A Roberts loom in a weaving shed in 1835 . Textiles were the leading\\n\\nindustry of the Industrial Revolution and mechanized factories , powered by a\\n\\ncentral water wheel or steam engine , were the new workplace . The Industrial\\n\\nRevolution was the transition to new manufacturing processes in the period from\\n\\nabout 1760 to sometime between 1820 and 1840 . This transition included going\\n\\nfrom hand production methods to machines , new chemical manufacturing and iron\\n\\nproduction processes , the increasing use of steam power , the development of\\n\\nmachine tools and the rise of the factory system . Textiles were the dominant\\n\\nindustry of the Industrial Revolution in terms of employment , value of output\\n\\nand capital invested . The textile industry was also the first to use modern\\n\\nproduction methods . The Industrial Revolution began in Great Britain , and\\n\\nmany of the technological innovations were of British origin . By the mid-18th\\n\\ncentury Britain was the world 's leading commercial nation , controlling a\\n\\nglobal trading empire with colonies in North America and Africa , and with some\\n\\npolitical influence on the Indian subcontinent , through the activities of the\\n\\nEast India Company . The development of trade and the rise of business were\\n\\nmajor causes of the Industrial Revolution . The Industrial Revolution marks a\\n\\nmajor turning point in history ; almost every aspect of daily life was\\n\\ninfluenced in some way . In particular , average income and population began to\\n\\nexhibit unprecedented sustained growth . Some economists say that the major\\n\\nimpact of the Industrial Revolution was that the standard of living for the\\n\\ngeneral population began to increase consistently for the first time in history\\n\\n, although others have said that it did not begin to meaningfully improve until\\n\\nthe late 19th and 20th centuries . GDP per capita was broadly stable before\\n\\nthe Industrial Revolution and the emergence of\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question:\\n\\nhow is the head of the church of england\\n\\nAnswer:\\n\\n<P> The Church of England ( C of E ) is the Established Church of England . The Archbishop of\\n\\nCanterbury is the most senior cleric , although the monarch is the supreme governor . The Church\\n\\nof England is also the mother church of the international Anglican Communion . It traces its\\n\\nhistory to the Christian church recorded as existing in the Roman province of Britain by the third\\n\\ncentury , and to the 6th - century Gregorian mission to Kent led by Augustine of Canterbury .\\n\\n</P>\\n\\nContext:\\n\\nChurch of England - wikipedia Church of England `` C of E '' redirects here .\\n\\nFor other uses , see Council of Europe . Anglican state church of England\\n\\nChurch of England Abbreviation C of E Orientation Anglican\\n\\nPolity Episcopal Supreme Governor Queen Elizabeth II Primate\\n\\nArchbishop Justin Welby Associations Anglican Communion Porvoo Communion\\n\\nRegion England , Wales ( cross-border parishes ) Isle of Man Channel Islands\\n\\nContinental Europe Headquarters Church House , Westminster , England ,\\n\\nUnited Kingdom Separated from Roman Catholic Church ( 1534 )\\n\\nSeparations English Dissenters ( 1534 onwards ) Methodists ( 18th century )\\n\\nPlymouth Brethren ( 1820s ) Free Church of England ( 1844 ) Members 25\\n\\nmillion Official website churchofengland.org Part of a series on\\n\\nAnglicanism Theology ( show ) Christian theology Anglican doctrine\\n\\nThirty - nine Articles Books of Homilies Caroline Divines Lambeth Quadrilateral\\n\\nEpiscopal polity Sacraments Mary Ministry and worship ( show ) Ministry\\n\\nMusic Eucharist King James Version ( Book of Common Prayer ) Liturgical year\\n\\nChurchmanship ( High , Low , Central , Broad ) Monasticism Saints\\n\\nChristianity ( show ) Jesus Christ Paul Christian Church First seven Ecumenical\\n\\nCouncils Background and history ( show ) Celtic Christianity Augustine of\\n\\nCanterbury Bede Medieval cathedral architecture Henry VIII English Reformation\\n\\nThomas Cranmer Dissolution of Monasteries Church of England Edward VI Elizabeth\\n\\nI Parker Hooker James I Charles I Laud Nonjuring schism Anglo - Catholicism\\n\\nOxford Movement Anglican Communion ( show ) Anglican Communion history\\n\\nArchbishop of Canterbury Anglican Communion Primates ' Meetings Lambeth\\n\\nConference Bishops Anglican Consultative Council Ecumenism Ordination of women\\n\\nWindsor Report Continuing Anglicanism ( show ) Anglican realignment\\n\\nBartonville Agreement Congress of St. Louis North American Anglican Conference\\n\\nAnglicanism portal\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content='Question:\\n\\nwho holds the most women\\'s wimbledon titles\\n\\nAnswer:\\n\\n<Table> Wimbledon Ladies \\' Singles Champions <Tr> <Th> Location </Th> <Td> London\\n\\nUnited Kingdom </Td> </Tr> <Tr> <Th> Venue </Th> <Td> AELTC </Td> </Tr> <Tr> <Th>\\n\\nGoverning body </Th> <Td> AELTC / LTA </Td> </Tr> <Tr> <Th> Created </Th> <Td> 1884 (\\n\\nestablished ) Open Era : 1968 ( 51 editions ) </Td> </Tr> <Tr> <Th> Surface </Th> <Td>\\n\\nGrass ( 1884 -- Present ) </Td> </Tr> <Tr> <Th> Prize money </Th> <Td> £ 2,000,000 ( 2016\\n\\n) </Td> </Tr> <Tr> <Th> Trophy </Th> <Td> Venus Rosewater Dish </Td> </Tr> <Tr> <Th>\\n\\nWebsite </Th> <Td> REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html </Td>\\n\\n</Tr> <Tr> <Th colspan=\"2\"> Most titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 7\\n\\n: Dorothea Lambert Chambers ( challenge round ) 8 : Helen Wills Moody ( regular ) </Td> </Tr>\\n\\n<Tr> <Th> Open era </Th> <Td> 9 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\">\\n\\nMost consecutive titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 3 : Lottie Dod\\n\\nSuzanne Lenglen ( challenge round ) 4 : Helen Wills Moody ( regular ) </Td> </Tr> <Tr> <Th>\\n\\nOpen era </Th> <Td> 6 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\"> Current\\n\\nchampion </Th> </Tr> <Tr> <Td colspan=\"2\"> Angelique Kerber ( 1st singles title ) </Td>\\n\\n</Tr> </Table>\\n\\nContext:\\n\\nList of Wimbledon Ladies \\' Singles champions - wikipedia List of Wimbledon\\n\\nLadies \\' Singles champions Wimbledon Ladies \\' Singles Champions Location\\n\\nLondon United Kingdom Venue AELTC Governing body AELTC / LTA\\n\\nCreated 1884 ( established ) Open Era : 1968 ( 51 editions ) Surface\\n\\nGrass ( 1884 -- Present ) Prize money £ 2,000,000 ( 2016 ) Trophy\\n\\nVenus Rosewater Dish Website\\n\\REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html Most\\n\\ntitles Amateur era 7 : Dorothea Lambert Chambers ( challenge round ) 8 :\\n\\nHelen Wills Moody ( regular ) Open era 9 : Martina Navratilova Most\\n\\nconsecutive titles Amateur era 3 : Lottie Dod Suzanne Lenglen ( challenge\\n\\nround ) 4 : Helen Wills Moody ( regular ) Open era 6 : Martina Navratilova\\n\\nCurrent champion Angelique Kerber ( 1st singles title ) The\\n\\nChampionships , Wimbledon is an annual tennis tournament first contested in 1877\\n\\nand played on outdoor grass courts at the All England Lawn Tennis and Croquet\\n\\nClub ( AELTC ) in the Wimbledon suburb of London , United Kingdom . The Ladies \\'\\n\\nSingles was started in 1884 . Contents 1 History 2 Champions 2.1\\n\\nAmateur Era 2.2 Open Era 3 Statistics 3.1 Multiple champions 3.2\\n\\nChampionships by country 4 See also 5 Notes 6 References 7 External\\n\\nlinks History ( edit ) Wimbledon has historically been played in the last\\n\\nweek of June and the first week of July ( though changed to the first two weeks\\n\\nof July in 2017 ) , and has been chronologically the third of the four Grand\\n\\nSlam tournaments of the tennis season since 1987 . The event was not held from\\n\\n1915 to 1918 because of World War I and again from 1940 to 1945 because of World\\n\\nWar II . The Ladies \\' Singles \\' rules have undergone several changes since the\\n\\nfirst edition . From 1886 until 1921 , the event started with a knockout phase ,\\n\\nthe All Comers \\' Singles , whose winner then faced the defending champion in a\\n\\nchallenge round . The All', metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content=\"Question:\\n\\nhow many goals scored ronaldo in his career\\n\\nAnswer:\\n\\n<P> Cristiano Ronaldo dos Santos Aveiro GOIH ComM ( European Portuguese : ( kitjnu\\n\\nonadu ) ; born 5 February 1985 ) is a Portuguese professional footballer who plays as a forward\\n\\nfor Italian club Juventus and the Portugal national team . Often considered the best player in the\\n\\nworld and regarded by many as one of the greatest players of all time , Ronaldo has a record -\\n\\ntying five Ballon d'Or awards , the most for a European player , and is the first player to win four\\n\\nEuropean Golden Shoes . He has won 26 trophies in his career , including five league titles , five\\n\\nUEFA Champions League titles and one UEFA European Championship . A prolific goalscorer ,\\n\\nRonaldo holds the records for most official goals scored in Europe 's top - five leagues ( 395 ) , the\\n\\nUEFA Champions League ( 120 ) , the UEFA European Championship ( 9 ) , as well as those for\\n\\nmost assists in the UEFA Champions League ( 34 ) and the UEFA European Championship ( 6 ) .\\n\\nHe has scored over 670 senior career goals for club and country . </P>\\n\\nContext:\\n\\nCristiano Ronaldo - wikipedia Cristiano Ronaldo Portuguese footballer For\\n\\nthe Brazilian footballer , see Ronaldo ( Brazilian footballer ) . This name uses\\n\\nPortuguese naming customs . The first or maternal family name is Santos and the\\n\\nsecond or paternal family name is Aveiro . Cristiano Ronaldo Cristiano\\n\\nRonaldo with Portugal at the 2018 FIFA World Cup Full name Cristiano\\n\\nRonaldo dos Santos Aveiro Date of birth ( 1985 - 02 - 05 ) 5 February 1985\\n\\n( age 33 ) Place of birth Funchal , Madeira , Portugal Height 1.85 m\\n\\n( 6 ft 1 in ) Playing position Forward Club information Current\\n\\nteam Juventus Number 7 Youth career 1992 -- 1995 Andorinha\\n\\n1995 -- 1997 Nacional 1997 -- 2002 Sporting CP Senior career *\\n\\nYears Team Apps ( Gls ) 2002 -- 2003 Sporting CP B ( 0 )\\n\\n2002 -- 2003 Sporting CP 25 ( 3 ) 2003 -- 2009 Manchester United\\n\\n196 ( 84 ) 2009 -- 2018 Real Madrid 292 ( 311 ) 2018 --\\n\\nJuventus ( 0 ) National team Portugal U15 9 ( 7 ) 2001 --\\n\\n2002 Portugal U17 7 ( 5 ) 2003 Portugal U20 5 ( 1 ) 2002 --\\n\\n2003 Portugal U21 10 ( 3 ) Portugal U23 ( 2 ) 2003 --\\n\\nPortugal 154 ( 85 ) Honours ( show ) Men 's football\\n\\nRepresenting Portugal UEFA European Championship 2004 Portugal\\n\\n2012 Poland & Ukraine 2016 France FIFA Confederations Cup\\n\\n2017 Russia * Senior club appearances and goals counted for the\\n\\ndomestic league only and correct as of 25 August 2018 National team caps and\\n\\ngoals correct as of 30 June 2018 This article is part of a series\\n\\nabout Cristiano Ronaldo Portuguese professional footballer\\n\\nInternational goals Career achievements Comparisons to Lionel Messi\\n\\nNamesakes Cristiano Ronaldo Campus Futebol Cristiano Ronaldo International\\n\\nAirport Galaxy CR7 Museu CR7 Films Cristiano Ronaldo : The World at\\n\\nHis Feet Ronaldo\", metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the orange stuff on my sushi\\n\\nAnswer:\\n\\n<P> The eggs are small , ranging from 0.5 to 0.8 mm . For comparison , tobiko is larger than\\n\\nmasago ( capelin roe ) , but smaller than ikura ( salmon roe ) . Natural tobiko has a red - orange\\n\\ncolor , a mild smoky or salty taste , and a crunchy texture . </P>\\n\\nContext:\\n\\nTobiko - wikipedia Tobiko Jump to : navigation , search This article\\n\\nneeds additional citations for verification . Please help improve this article\\n\\nby adding citations to reliable sources . Unsourced material may be challenged\\n\\nand removed . ( February 2013 ) ( Learn how and when to remove this template\\n\\nmessage ) Tobiko in varying colors , served as sushi Tobiko ( ) is the\\n\\nJapanese word for flying fish roe . It is most widely known for its use in\\n\\ncreating certain types of sushi . The eggs are small , ranging from 0.5 to 0.8\\n\\nmm . For comparison , tobiko is larger than masago ( capelin roe ) , but smaller\\n\\nthan ikura ( salmon roe ) . Natural tobiko has a red - orange color , a mild\\n\\nsmoky or salty taste , and a crunchy texture . Tobiko , shown in its natural\\n\\ncolor , topping grilled Albacore tuna Sometimes tobiko is colored to change its\\n\\nappearance , other natural ingredients are used to accomplish the change , such\\n\\nas squid ink to make it black , yuzu to make it pale orange ( almost yellow ) ,\\n\\nor even wasabi to make it green and spicy . Sometimes a serving of tobiko\\n\\ncontains several pieces , each having a different color . When prepared as\\n\\nsashimi , it may be presented on avocado halves or wedges . Tobiko is used in\\n\\nthe creation of many other Japanese dishes . Often , tobiko is used as an\\n\\ningredient in California rolls . Frequently , masago ( capelin or smelt roe )\\n\\nis substituted for tobiko , due to its similar appearance and flavor . The\\n\\nsmaller size of the individual eggs is apparent to the experienced diner ,\\n\\nhowever . References ( edit ) Wikimedia Commons has media related to\\n\\nTobiko . Jump up ^ `` Tobiko vs Masago Difference '' . Expert answer\\n\\nQuestion. 2016 - 11 - 16 . Retrieved 2016 - 11 - 16 . Jump up ^ Food Republic\\n\\nhttp://REMOVED_SECRET/2013/04/19/what-tobiko-and-whats-different-colors .\\n\\nRetrieved 18 October 2014 . Missing or empty title = ( help ) Sushi\\n\\nHistory of sushi List of sushi and sashimi ingr\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question:\\n\\nwho was the first president to get his picture taken\\n\\nAnswer:\\n\\nContext:\\n\\nList of United States Presidential Firsts - wikipedia List of United States\\n\\nPresidential Firsts Jump to : navigation , search This article needs\\n\\nadditional citations for verification . Please help improve this article by\\n\\nadding citations to reliable sources . Unsourced material may be challenged and\\n\\nremoved . ( January 2017 ) ( Learn how and when to remove this template message\\n\\n) This list lists achievements and distinctions of various Presidents of the\\n\\nUnited States . It includes distinctions achieved in their earlier life and\\n\\npost-presidencies . Due to some confusion surrounding sovereignty of nations\\n\\nduring presidential visits , only nations that were independent , sovereign , or\\n\\nrecognized by the United States during the presidency are listed here as a\\n\\nprecedent . Contents ( hide ) 1 George Washington ( 1789 - 1797 ) 2 John\\n\\nAdams ( 1797 - 1801 ) 3 Thomas Jefferson ( 1801 - 1809 ) 4 James Madison (\\n\\n1809 - 1817 ) 5 James Monroe ( 1817 - 1825 ) 6 John Quincy Adams ( 1825 -\\n\\n1829 ) 7 Andrew Jackson ( 1829 - 1837 ) 8 Martin Van Buren ( 1837 - 1841 )\\n\\n9 William Henry Harrison ( 1841 ) 10 John Tyler ( 1841 - 1845 ) 11 James K.\\n\\nPolk ( 1845 - 1849 ) 12 Zachary Taylor ( 1849 - 1850 ) 13 Millard Fillmore (\\n\\n1850 - 1853 ) 14 Franklin Pierce ( 1853 - 1857 ) 15 James Buchanan ( 1857 -\\n\\n1861 ) 16 Abraham Lincoln ( 1861 - 1865 ) 17 Andrew Johnson ( 1865 - 1869 )\\n\\n18 Ulysses S. Grant ( 1869 - 1877 ) 19 Rutherford B. Hayes ( 1877 - 1881 )\\n\\n20 James A. Garfield ( 1881 ) 21 Chester A. Arthur ( 1881 - 1885 ) 22 Grover\\n\\nCleveland ( 1885 - 1889 ; 1893 - 1897 ) 23 Benjamin Harrison ( 1889 - 1893 )\\n\\n24 William McKinley ( 1897 - 1901 ) 25 Theodore Roosevelt ( 1901 - 1909 ) 26\\n\\nWilliam Howard Taft ( 1909 - 1913 ) 27 Woodrow Wilson ( 1913 - 1921 ) 28\\n\\nWarren G. Harding ( 1921 - 1923 ) 29 Calvin Coolidge ( 1923 - 1929 ) 30\\n\\nHerbert Hoover ( 1929 - 1933 ) 31 Franklin D. Roosevelt ( 1933 - 1945 ) 32\\n\\nHarry S. Truman ( 1945 - 1953 ) 3', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the moral of the ant and the grasshopper\\n\\nAnswer:\\n\\n<P> The story has been used to teach the virtues of hard work and the perils of improvidence .\\n\\nSome versions state a moral at the end along the lines of `` Idleness brings want '' , `` To work\\n\\ntoday is to eat tomorrow '' , `` Beware of winter before it comes '' . In La Fontaine 's Fables no\\n\\nfinal judgment is made , although it has been argued that the author is there making sly fun of\\n\\nhis own notoriously improvident ways . But the point of view in most retellings of the fable is\\n\\nsupportive of the ant . It is also influenced by the commendation in the biblical Book of Proverbs ,\\n\\nwhich mentions the ant twice . The first proverb admonishes , `` Go to the ant , you sluggard !\\n\\nConsider her ways and be wise , which having no captain , overseer or ruler , provides her\\n\\nsupplies in the summer , and gathers her food in the harvest '' ( 6.6 - 9 ) . Later , in a parallel\\n\\nsaying of Agur , the insects figure among the ' four things that are little upon the earth but they\\n\\nare exceeding wise . The ants are a people not strong , yet they provide their food in the summer\\n\\n. ' ( 30.24 - 5 ) </P>\\n\\nContext:\\n\\nThe ant and the grasshopper - wikipedia The ant and the grasshopper Jump to :\\n\\nnavigation , search Coloured print of La Fontaine 's fable by Jean - Baptiste\\n\\nOudry The Ant and the Grasshopper , alternatively titled The Grasshopper and\\n\\nthe Ant ( or Ants ) , is one of Aesop 's Fables , numbered 373 in the Perry\\n\\nIndex . The fable describes how a hungry grasshopper begs for food from an ant\\n\\nwhen winter comes and is refused . The situation sums up moral lessons about the\\n\\nvirtues of hard work and planning for the future . Even in Classical times ,\\n\\nhowever , the advice was mistrusted and an alternative story represented the ant\\n\\n's industry as mean and self - serving . Jean de la Fontaine 's delicately\\n\\nironical retelling in French later widened the debate to cover the themes of\\n\\ncompassion and charity . Since the 18th century the grasshopper has been seen as\\n\\nthe type of the artist and the question of the place of culture in society has\\n\\nalso been included . Argument over the fable 's ambivalent meaning has generally\\n\\nbeen conducted through adaptation or reinterpretation of the fable in literature\\n\\n, arts and music . Contents ( hide ) 1 Fable and counter-fable 2 In art\\n\\n3 Later adaptations 4 Musical settings 5 Film and television treatments 6\\n\\nMoral and artistic debate 7 See also 8 References 9 External links\\n\\nFable and counter-fable ( edit ) The fable concerns a grasshopper ( in the\\n\\noriginal , a cicada ) that has spent the summer singing while the ant ( or ants\\n\\nin some versions ) worked to store up food for winter . When that season arrives\\n\\n, the grasshopper finds itself dying of hunger and begs the ant for food .\\n\\nHowever , the ant rebukes its idleness and tells it to dance the winter away now\\n\\n. Versions of the fable are found in the verse collections of Babrius ( 140 )\\n\\nand Avianus ( 34 ) , and in several prose collections including those attributed\\n\\nto Syntipas and Aphthonius of Antioch . The fable 's Greek original cicada is\\n\\nkept in the Latin and Romance\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content=\"Question:\\n\\nwhich city has the highest hiv rate in south africa\\n\\nAnswer:\\n\\nContext:\\n\\nHIV / AIDS in South Africa - Wikipedia HIV / AIDS in South Africa This\\n\\narticle needs to be updated . Please update this article to reflect recent\\n\\nevents or newly available information . ( July 2018 ) Estimated HIV\\n\\nprevalence among adults aged 15 - 49 by country in 2007 HIV / AIDS is the most\\n\\nserious health concern in South Africa . The country has the fourth - highest\\n\\nadult HIV prevalence rate in the world , according to the 2016 United Nations\\n\\nstatistics . According to a UNAids dataset sourced from the World Bank , in\\n\\n2016 the HIV prevalence rate for adults aged 15 to 49 was 27 % in Swaziland , 25\\n\\n% in Lesotho , 25 % in Botswana and 19 % in South Africa . Contents 1\\n\\nUnderstanding HIV prevalence 2 Latest data on HIV prevalence in South Africa\\n\\n3 Other statistics 3.1 By race 3.2 By gender 3.3 By pregnant women 3.4\\n\\nBy age 3.5 By province 4 Awareness campaigns 5 Co-infection with\\n\\ntuberculosis 6 History 6.1 1990 6.2 1993 6.3 1995 6.4 1996 6.5 1997\\n\\n6.6 1999 6.7 2000 6.8 2001 6.9 2002 7 Demographics 8 Aids denialism\\n\\nunder Thabo Mbeki 8.1 2000 8.2 2001 8.3 2003 8.4 2006 8.5 2007 9\\n\\nRole of the media in South Africa 's epidemic 10 See also 11 References 12\\n\\nFurther reading 13 External links Understanding HIV prevalence ( edit )\\n\\nHIV prevalence does not indicate that a country has an AIDS crisis , as HIV and\\n\\nAIDS are separate conditions . HIV prevalence , instead , indicates that people\\n\\nremain alive , despite the infection . South Africa has the largest HIV\\n\\ntreatment programme in the world . With the correct medication , HIV is a\\n\\nmanageable chronic condition , like diabetes or hypertension . A population with\\n\\na larger proportion of diabetics , means more people are receiving treatment for\\n\\nthe condition . Hence , a population with a larger proportion of HIV - positive\\n\\npeople , means more people are receiving anti-retroviral treatment . World\\n\\nBank Open Data explains the data it publishes on HI\", metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question:\\n\\nnow that's what i call music 17 songs\\n\\nAnswer:\\n\\nContext:\\n\\nNow That 's What I Call Music 17 ( UK series ) - wikipedia Now That 's What I\\n\\nCall Music 17 ( UK series ) Jump to : navigation , search This article\\n\\ndoes not cite any sources . Please help improve this article by adding citations\\n\\nto reliable sources . Unsourced material may be challenged and removed . (\\n\\nDecember 2009 ) ( Learn how and when to remove this template message ) This\\n\\narticle describes the 17th album in the UK Now ! series . It should not be\\n\\nconfused with identically - numbered albums from other Now ! series . For more\\n\\ninformation , see Now That 's What I Call Music ! 17 and Now That 's What I Call\\n\\nMusic ! discography . Now That 's What I Call Music 17 Compilation\\n\\nalbum by various artists Released 23 April 1990 Genre Pop Length\\n\\n2 : 05 : 00 Label Virgin / EMI / Polygram Series chronology Now\\n\\nThat 's What I Call Music 16 ( 1989 ) Now That 's What I Call Music 17 ( 1990\\n\\n) Now ! That 's What I Call Music 18 ( 1990 ) Now That 's What I Call\\n\\nMusic 17 or Now 17 is the 17th edition of the Now ! series in the United Kingdom\\n\\nand was released in April 1990 on vinyl , audio cassette , compact disc and VHS\\n\\n. Track listing ( edit ) CD / record / tape 1 No . Title Artist (\\n\\ns ) Length 1 . `` Blue Savannah '' Erasure 2 . `` Better World\\n\\n'' Rebel MC 3 . `` Opposites Attract '' Paula Abdul 4 . ``\\n\\nDub Be Good to Me '' Beats International 5 . `` Kingston Town ''\\n\\nUB40 6 . `` Strawberry Fields Forever '' Candy Flip 7 . `` I\\n\\nDo n't Wanna Lose You '' Tina Turner 8 . `` I Wish It Would Rain Down\\n\\n'' Phil Collins 9 . `` Step On '' Happy Mondays 10 . ``\\n\\nLoaded '' Primal Scream 11 . `` Enjoy the Silence '' Depeche Mode\\n\\n12 . `` Real Real Real '' Jesus Jones 13 . `` This Is How It Feels\\n\\n'' Inspiral Carpets 14 . `` Shine On '' The House of Love 15 .\\n\\n`` From Out of Nowhere ''\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question:\\n\\nwhen does model code of conduct come into force\\n\\nAnswer:\\n\\n<P> Election Commission of India 's Model Code of Conduct is a set of guidelines issued by the\\n\\nElection Commission of India for conduct of political parties and candidates during elections\\n\\nmainly with respect to speeches , polling day , polling booths , election manifestos , processions\\n\\nand general conduct . These set of norms has been evolved with the consensus of political parties\\n\\nwho have consented to abide by the principles embodied in the said code in its letter and spirit.\\n\\nThe Model Code of Conduct comes into force immediately on announcement of the election\\n\\nschedule by the commission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example , politicians should not\\n\\nmake hate speeches , putting one community against another or make promises about new\\n\\nprojects that may sway a voter . </P>\\n\\nContext:\\n\\nElection Commission of India 's Model code of Conduct - wikipedia Election\\n\\nCommission of India 's Model code of Conduct Jump to : navigation , search\\n\\nThis article needs more links to other articles to help integrate it into the\\n\\nencyclopedia . Please help improve this article by adding links that are\\n\\nrelevant to the context within the existing text . ( April 2014 ) ( Learn how\\n\\nand when to remove this template message ) Election Commission of India 's\\n\\nModel Code of Conduct is a set of guidelines issued by the Election Commission\\n\\nof India for conduct of political parties and candidates during elections mainly\\n\\nwith respect to speeches , polling day , polling booths , election manifestos ,\\n\\nprocessions and general conduct . These set of norms has been evolved with the\\n\\nconsensus of political parties who have consented to abide by the principles\\n\\nembodied in the said code in its letter and spirit. The Model Code of Conduct\\n\\ncomes into force immediately on announcement of the election schedule by the\\n\\ncommission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example ,\\n\\npoliticians should not make hate speeches , putting one community against\\n\\nanother or make promises about new projects that may sway a voter . For the\\n\\n2014 general election the code came into force on 5 March 2014 when the\\n\\nCommission announced the dates and remains in force till the end of the\\n\\nelectoral process . `` The Model Code of Conduct is crucial to make sure a\\n\\nlevel playing field among various contenders in the poll fray , '' said the\\n\\nChief Election Commissioner V.S. Sampath at the press conference . Main points\\n\\n( edit ) The main points of the code are : Government bodies are not to\\n\\nparticipate in any new recruitment process during the electoral process . The\\n\\ncontesting candidates and the campaigners must respect the home life of their\\n\\nrivals and should not disturb them by holding road shows or demonstrations\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content=\"Question:\\n\\nwhere is the greatest royal rumble taking place\\n\\nAnswer:\\n\\n<P> Greatest Royal Rumble was a professional wrestling pay - per - view event and WWE\\n\\nNetwork event promoted by WWE for their Raw and SmackDown brands . The event was held on\\n\\nApril 27 , 2018 at the King Abdullah Sports City 's King Abdullah International Stadium in Jeddah ,\\n\\nSaudi Arabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in the United\\n\\nStates at noon EDT , with a pre-show starting at 11 a.m. EDT . At the event , all men 's main\\n\\nroster championships were defended , in addition to a 50 - man Royal Rumble match . </P>\\n\\nContext:\\n\\nWWE Greatest Royal Rumble - Wikipedia WWE Greatest Royal Rumble Jump to :\\n\\nnavigation , search Greatest Royal Rumble Promotional poster featuring\\n\\nvarious WWE wrestlers Theme song ( s ) `` When Legends Rise '' by Godsmack\\n\\nInformation Promotion WWE Brand ( s ) Raw SmackDown Sponsor ( s\\n\\n) Saudi General Sports Authority Date April 27 , 2018 Attendance\\n\\n60,000 Venue King Abdullah International Stadium City Jeddah , Saudi\\n\\nArabia WWE Network event chronology WrestleMania 34 Greatest Royal\\n\\nRumble Backlash ( 2018 ) Greatest Royal Rumble was a professional\\n\\nwrestling pay - per - view event and WWE Network event promoted by WWE for their\\n\\nRaw and SmackDown brands . The event was held on April 27 , 2018 at the King\\n\\nAbdullah Sports City 's King Abdullah International Stadium in Jeddah , Saudi\\n\\nArabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in\\n\\nthe United States at noon EDT , with a pre-show starting at 11 a.m. EDT . At the\\n\\nevent , all men 's main roster championships were defended , in addition to a 50\\n\\nman Royal Rumble match . The card featured ten matches . In the main event ,\\n\\nBraun Strowman won the titular Greatest Royal Rumble match to become the\\n\\ninaugural Greatest Royal Rumble Champion . In the penultimate match , Brock\\n\\nLesnar retained the Universal Championship in a steel cage match against Roman\\n\\nReigns . On the undercard , the WWE Championship match between AJ Styles and\\n\\nShinsuke Nakamura resulted in a double countout , The Undertaker defeated Rusev\\n\\nin a casket match , and John Cena defeated Triple H in the opening match .\\n\\nContents ( hide ) 1 Production 1.1 Background 1.2 Storylines 2 Event\\n\\n2.1 Preliminary matches 2.2 Main event 3 Controversy 4 Results 4.1 Tag\\n\\nTeam Eliminator bracket 4.2 Greatest Royal Rumble match entrances and\\n\\neliminations 5 WWE Greatest Royal Rumble Championship 5.1 History 5.2\\n\\nChampionship belt design 5.3 Reigns 6\", metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question:\\n\\nwho died from the band faith no more\\n\\nAnswer:\\n\\n<P> Former Faith No More singer Chuck Mosley died on November 9 , 2017 , due to `` the\\n\\ndisease of addiction . '' He was 57 years old . </P>\\n\\nContext:\\n\\nFaith No More - Wikipedia Faith No More Jump to : navigation , search Faith\\n\\nNo More Faith No More performing in Portugal in 2009 Background\\n\\ninformation Also known as Faith No Man Sharp Young Men Origin\\n\\nSan Francisco , California , United States Genres Alternative metal\\n\\nfunk metal experimental rock Years active 1979 -- 1998 2009 --\\n\\npresent Labels Slash London Mordam Reclamation ! Ipecac\\n\\nAssociated acts Mr. Bungle Pop - O - Pies Website fnm.com\\n\\nMembers Mike Bordin Roddy Bottum Billy Gould Mike Patton Jon Hudson\\n\\nPast members List of Faith No More band members Faith No More ( sometimes\\n\\nabbreviated as FNM ) is an American rock band from San Francisco , California ,\\n\\nformed in 1979 . Before settling on their current name in 1982 , the band\\n\\nperformed under the names Sharp Young Men and later Faith No Man . Bassist Billy\\n\\nGould and drummer Mike Bordin are the longest remaining members of the band ,\\n\\nhaving been involved with Faith No More since its inception . The band underwent\\n\\nseveral lineup changes early in their career , along with some major changes\\n\\nlater on . The current lineup of Faith No More consists of Gould , Bordin ,\\n\\nkeyboardist / rhythm guitarist Roddy Bottum , lead guitarist Jon Hudson and\\n\\nvocalist / lyricist Mike Patton . After releasing six studio albums ,\\n\\nincluding their best - selling records The Real Thing ( 1989 ) and Angel Dust (\\n\\n1992 ) , Faith No More officially announced their breakup on April 20 , 1998 .\\n\\nThey have since reunited , embarked on The Second Coming Tour from 2009 to 2012\\n\\n, and released their seventh studio album , Sol Invictus , in May 2015 .\\n\\nContents ( hide ) 1 History 1.1 Early days ( 1979 -- 1984 ) 1.2 We Care a\\n\\nLot and Introduce Yourself ( 1985 -- 1988 ) 1.3 Mike Patton joins and The Real\\n\\nThing ( 1989 -- 1991 ) 1.4 Angel Dust ( 1992 -- 1994 ) 1.5 King for a Day\\n\\n... , Album of the Year and break - up ( 1995 -- 1998 ) 1.6 R\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content=\"Question:\\n\\nwhat is sauce for the goose is sauce for the gander examples\\n\\nAnswer:\\n\\nContext:\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander - Wikipedia\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander This page\\n\\nis an essay . It contains the advice or opinions of one or more Wikipedia\\n\\ncontributors . This page is not one of Wikipedia 's policies or guidelines , as\\n\\nit has not been thoroughly vetted by the community . Some essays represent\\n\\nwidespread norms ; others only represent minority viewpoints . Shortcuts WP\\n\\n: SAUCE WP : GOOSE WP : GANDER This page in a nutshell : This phrase\\n\\nis employed to expose holding forth a `` double standard . '' If some kind of\\n\\nbehavior is wrong , it 's probably wrong for both sides , not just one . Do n't\\n\\ndo it yourself either . There 's an old saying , `` What is sauce for the\\n\\ngoose is sauce for the gander . '' This meshes well with the Golden Rule , or\\n\\nethic of reciprocity , which is a key moral principle in many religions and\\n\\nphilosophies , and is often stated as `` Do unto others as you wish to be done\\n\\nfor you '' , or conversely , `` Do n't do unto others what you would not wish to\\n\\nbe done to you . '' Tasty sauces to enjoy on your stir - fried wikipedia . But\\n\\nare they reliable sauces ? Look up sauce for the goose in Wiktionary , the\\n\\nfree dictionary . Unfortunately , when the infighting here in Wikipedia gets\\n\\nheated , participants often forget this principle and do unto their opponents\\n\\nthings that would not be fair to be done unto them , and sometimes add insult to\\n\\ninjury by crying `` fowl '' if their opponents do in fact raise similar\\n\\nobjections to their own actions ( and those of their friends ) to the ones they\\n\\nraised against the opponents in the first place . These `` wars '' can easily\\n\\nturn both parties into hypocrites . Some of the sorts of things that violate\\n\\nthis principle include : Trying to squelch or discredit an opposing viewpoint\\n\\nby associating it with a banned editor who espoused something similar , when in\\n\\nfact some of your own viewpoints a\", metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content=\"Question:\\n\\nwho was the gospel of john written to\\n\\nAnswer:\\n\\nContext:\\n\\nGospel of John - wikipedia Gospel of John Books of the New Testament\\n\\nGospels Matthew Mark Luke John Acts Acts of the Apostles\\n\\nEpistles Romans 1 Corinthians 2 Corinthians Galatians Ephesians Philippians\\n\\nColossians 1 Thessalonians 2 Thessalonians 1 Timothy 2 Timothy Titus Philemon\\n\\nHebrews James 1 Peter 2 Peter 1 John 2 John 3 John Jude Apocalypse\\n\\nRevelation New Testament manuscripts This article is about\\n\\nthe book in the New Testament . For the film , see The Gospel of John ( film ) .\\n\\nNot to be confused with First Epistle of John . Part of a series of articles\\n\\non John in the Bible Johannine literature Gospel Epistles\\n\\nFirst Second Third Revelation Events Authorship Apostle\\n\\nBeloved disciple Evangelist Patmos Presbyter Related literature\\n\\nApocryphon Acts Signs Gospel See also Johannine Christianity\\n\\nLogos Holy Spirit in Johannine literature John 's vision of the Son of Man\\n\\nNew Testament people named John The Gospel According to John\\n\\nis the fourth of the canonical gospels . The work is anonymous , although it\\n\\nidentifies an unnamed `` disciple whom Jesus loved '' as the source of its\\n\\ntraditions . It is closely related in style and content to the three Johannine\\n\\nepistles , and most scholars treat the four books , along with the Book of\\n\\nRevelation , as a single corpus of Johannine literature , albeit not from the\\n\\nsame author . C.K. Barrett , and later Raymond E. Brown , suggested that a\\n\\ntradition developed around the `` Johannine Community '' , and that this\\n\\ntradition gave rise to the gospel . The discovery of a large number of papyrus\\n\\nfragments of manuscripts with Johannine themes has led more scholars to\\n\\nrecognize that the texts were among the most influential in the early Church .\\n\\nThe discourses contained in this gospel seem to be concerned with issues of the\\n\\nchurch -- synagogue debate at the time of composition . It is no\", metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content='Question:\\n\\nfor an asset to be considered money it must be\\n\\nAnswer:\\n\\nContext:\\n\\nAsset - wikipedia Asset This article is about the finance definition . For\\n\\nother uses , see Asset ( disambiguation ) . Part of a series on\\n\\nAccounting Historical cost Constant purchasing power Management\\n\\nTax Major types ( show ) Audit Budget Cost Forensic Financial\\n\\nFund Governmental Management Social Tax Key concepts ( show )\\n\\nAccounting period Accrual Constant purchasing power Economic entity Fair\\n\\nvalue Going concern Historical cost Matching principle Materiality\\n\\nRevenue recognition Unit of account Selected accounts ( show ) Assets\\n\\nCash Cost of goods sold Depreciation / Amortization Equity Expenses\\n\\nGoodwill Liabilities Profit Revenue Accounting standards ( show )\\n\\nGenerally - accepted principles Generally - accepted auditing standards\\n\\nConvergence International Financial Reporting Standards International\\n\\nStandards on Auditing Management Accounting Principles Financial\\n\\nstatements ( show ) Annual report Balance sheet Cash - flow Equity\\n\\nIncome Management discussion Notes to the financial statements\\n\\nBookkeeping ( show ) Bank reconciliation Debits and credits Double - entry\\n\\nsystem FIFO and LIFO Journal Ledger / General ledger T accounts Trial\\n\\nbalance Auditing ( show ) Financial Internal Firms Report\\n\\nPeople and organizations ( show ) Accountants Accounting organizations\\n\\nLuca Pacioli Development ( show ) History Research Positive\\n\\naccounting Sarbanes -- Oxley Act Business portal In\\n\\nfinancial accounting , an asset is an economic resource . Anything tangible or\\n\\nintangible that can be owned or controlled to produce value and that is held by\\n\\na company to produce positive economic value is an asset . Simply stated ,\\n\\nassets represent value of ownership that can be converted into cash ( although\\n\\ncash itself is also considered an asset ) . The balance sheet of a firm\\n\\nrecords the monetary value o', metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content='Question:\\n\\nhow many district in punjab and also write its name\\n\\nAnswer:\\n\\nContext:\\n\\nPunjab , India - Wikipedia Punjab , India This article is about a state of\\n\\nIndia . For a geographical region , see Punjab . For other uses of the name ,\\n\\nsee Punjab ( disambiguation ) . State in India Punjab State The\\n\\nonly state in India with a majority Sikh population , Punjab contains the Golden\\n\\nTemple , amongst the most important sites in Sikhism Seal Location\\n\\nof Punjab in India Coordinates ( Chandigarh ) : 30 ° 47 N 75 ° 50 E\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/\\n\\n30.79\\n\\n;\\n\\n75.84\\n\\nCoordinates\\n\\n:\\n\\n30\\n\\n°\\n\\n47\\n\\nN 75\\n\\n°\\n\\n50\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/ 30.79 ; 75.84 Country India Capital\\n\\nChandigarh Largest city Ludhiana Districts 22 Government\\n\\nGovernor VP Singh Badnore Chief Minister Captain Amarinder Singh ( INC )\\n\\nE\\n\\nE\\n\\nE\\n\\nLegislature Unicameral ( 117 seats ) Parliamentary constituency 13\\n\\nHigh Court Punjab and Haryana High Court Area Total 50,362 km (\\n\\n19,445 sq mi ) Area rank 20th Highest elevation 551 m ( 1,808 ft )\\n\\nLowest elevation 150 m ( 490 ft ) Population ( 2011 ) Total\\n\\n27,704,236 Rank 16th Density 550 / km ( 1,400 / sq mi ) Demonym\\n\\n( s ) Punjabi GDP ( 2017 -- 18 ) Total 4.65 lakh crore ( US $69\\n\\nbillion ) Per capita 142,958 ( US $2,100 ) Time zone IST ( UTC +\\n\\n05 : 30 ) ISO 3166 code IN - PB HDI 0.6614 ( medium ) HDI rank\\n\\n5th ( 2015 ) Official language Punjabi Website REMOVED_SECRET ^\\n\\nJoint Capital with Haryana . Common for Punjab , Haryana and Chandigarh .\\n\\nSymbols of Punjab Emblem Lion Capital of Ashoka with Wheat stem ( above )\\n\\nand Crossed Swords ( below ) Language Punjabi Dance Bhangra , Giddha\\n\\nAnimal Blackbuck Bird Baaz ( Accipiter gentilis ) Punjab ( /\\n\\npndb / ( listen ) ) is a state in northern India . Forming part of the\\n\\nlarger Punjab region , the state is bordered by the Indian states of Jammu and\\n\\nKashmir to the north , Himachal Pradesh to the east', metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 174.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to processed_pdfs.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m processed_documents \u001b[38;5;241m=\u001b[39m load_from_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_pdfs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Build vector database\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m knowledge_index \u001b[38;5;241m=\u001b[39m \u001b[43mrag_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vector_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Initialize question generator\u001b[39;00m\n\u001b[1;32m     64\u001b[0m question_generator \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2text-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-cnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/codes/langers/RAG_UTILS.py:248\u001b[0m, in \u001b[0;36mRAGSystem.build_vector_database\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_vector_database\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: List[LangchainDocument]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Builds a FAISS vector database from the provided documents.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m        FAISS: FAISS vector database.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDistanceStrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOSINE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codes/langers/.venv/lib/python3.10/site-packages/langchain_core/vectorstores.py:548\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[VST],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VST:\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return VectorStore initialized from documents and embeddings.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    549\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/codes/langers/.venv/lib/python3.10/site-packages/langchain_core/vectorstores.py:548\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[VST],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VST:\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return VectorStore initialized from documents and embeddings.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    549\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# Complete RAG System Evaluation Notebook for Local PDFs\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score as bert_score\n",
    "import matplotlib.pyplot as plt\n",
    "from RAG_UTILS import RAGSystem, DocumentProcessor  # Import your existing RAG system\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "MODEL_ID = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
    "RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n",
    "PDF_FOLDER_PATH = \"local_database\"  # Update this to your local database path\n",
    "NUM_EVALUATION_SAMPLES = 50  # Number of questions to generate for evaluation\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = RAGSystem(\n",
    "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_id=MODEL_ID,\n",
    "    reranker_model=RERANKER_MODEL,\n",
    ")\n",
    "\n",
    "# Function to convert PDFs to CSV\n",
    "def convert_pdfs_to_csv(pdf_folder_path: str, output_csv_path: str):\n",
    "    doc_processor = DocumentProcessor(EMBEDDING_MODEL_NAME)\n",
    "    raw_documents = doc_processor.load_pdfs_from_folder(pdf_folder_path)\n",
    "    processed_documents = doc_processor.split_documents(raw_documents)\n",
    "    \n",
    "    data = []\n",
    "    for doc in processed_documents:\n",
    "        data.append({\n",
    "            \"content\": doc.page_content,\n",
    "            \"source\": REMOVED_SECRET(\"source\", \"\"),\n",
    "            \"page\": REMOVED_SECRET(\"page\", \"\")\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"CSV file saved to {output_csv_path}\")\n",
    "\n",
    "# Convert PDFs to CSV (run this once)\n",
    "convert_pdfs_to_csv(PDF_FOLDER_PATH, \"processed_pdfs.csv\")\n",
    "\n",
    "# Function to load data from CSV\n",
    "def load_from_csv(csv_path: str) -> List[dict]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df.to_dict('records')\n",
    "\n",
    "# Load processed documents from CSV\n",
    "processed_documents = load_from_csv(\"processed_pdfs.csv\")\n",
    "\n",
    "# Build vector database\n",
    "knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "\n",
    "# Initialize question generator\n",
    "question_generator = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\", device='cuda')\n",
    "\n",
    "def generate_questions(documents: List[dict], num_questions: int) -> List[Tuple[str, str]]:\n",
    "    questions_and_contexts = []\n",
    "    for _ in range(num_questions):\n",
    "        doc = random.choice(documents)\n",
    "        context = doc['content']\n",
    "        question = question_generator(f\"Generate a question based on this text: {context}\", max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "        questions_and_contexts.append((question, context))\n",
    "    return questions_and_contexts\n",
    "\n",
    "# Generate evaluation questions\n",
    "eval_questions = generate_questions(processed_documents, NUM_EVALUATION_SAMPLES)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_rag(questions_and_contexts: List[Tuple[str, str]]) -> List[dict]:\n",
    "    results = []\n",
    "    for question, context in tqdm(questions_and_contexts, total=len(questions_and_contexts)):\n",
    "        answer, relevant_docs, _ = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"generated_answer\": answer,\n",
    "            \"relevant_docs\": relevant_docs\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_rag(eval_questions)\n",
    "\n",
    "# Helper functions for different metrics\n",
    "\n",
    "def calculate_retrieval_metrics(results: List[dict]) -> dict:\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for result in results:\n",
    "        relevant_docs = set(tuple(doc.split()[:10]) for doc in result[\"relevant_docs\"])  # Use first 10 words as identifier\n",
    "        retrieved_docs = set(tuple(doc.split()[:10]) for doc in result[\"generated_answer\"].split('\\n'))  # Simplification, adjust as needed\n",
    "        precision = len(relevant_docs.intersection(retrieved_docs)) / len(retrieved_docs) if retrieved_docs else 0\n",
    "        recall = len(relevant_docs.intersection(retrieved_docs)) / len(relevant_docs) if relevant_docs else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return {\n",
    "        \"avg_precision\": np.mean(precisions),\n",
    "        \"avg_recall\": np.mean(recalls),\n",
    "        \"avg_f1\": np.mean(f1s)\n",
    "    }\n",
    "\n",
    "def calculate_bertscore(results: List[dict]) -> float:\n",
    "    references = [r[\"context\"] for r in results]\n",
    "    candidates = [r[\"generated_answer\"] for r in results]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def calculate_semantic_similarity(results: List[dict]) -> float:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        context_embedding = model.encode(result[\"context\"])\n",
    "        gen_embedding = model.encode(result[\"generated_answer\"])\n",
    "        similarity = np.dot(context_embedding, gen_embedding) / (REMOVED_SECRET(context_embedding) * REMOVED_SECRET(gen_embedding))\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# Calculate metrics\n",
    "retrieval_metrics = calculate_retrieval_metrics(evaluation_results)\n",
    "bertscore = calculate_bertscore(evaluation_results)\n",
    "semantic_similarity = calculate_semantic_similarity(evaluation_results)\n",
    "\n",
    "# Print results\n",
    "print(\"Retrieval Metrics:\")\n",
    "print(f\"Average Precision: {retrieval_metrics['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {retrieval_metrics['avg_recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {retrieval_metrics['avg_f1']:.4f}\")\n",
    "print(f\"BERTScore: {bertscore:.4f}\")\n",
    "print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'BERTScore', 'Semantic Similarity']\n",
    "values = [retrieval_metrics['avg_precision'], retrieval_metrics['avg_recall'], \n",
    "          retrieval_metrics['avg_f1'], bertscore, semantic_similarity]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, values)\n",
    "plt.title('RAG System Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation complete. Results saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "baf47a3230e44a11896f477882d0d9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `REMOVED_SECRET.GradScaler(args...)` is deprecated. Please use `REMOVED_SECRET('cuda', args...)` instead.\n",
      "  self.scaler = REMOVED_SECRET.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vector database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating evaluation questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating questions:   0%|          | 0/7 [00:00<?, ?it/s]/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1282: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n",
      "Generating questions:   0%|          | 0/7 [00:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Generate evaluation questions\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating evaluation questions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m eval_questions \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EVALUATION_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Evaluation function\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_rag\u001b[39m(questions_and_contexts: List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mdict\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[1], line 79\u001b[0m, in \u001b[0;36mgenerate_questions\u001b[0;34m(dataloader, num_questions)\u001b[0m\n\u001b[1;32m     73\u001b[0m contexts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     74\u001b[0m questions \u001b[38;5;241m=\u001b[39m question_generator(\n\u001b[1;32m     75\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate a question based on this text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m contexts],\n\u001b[1;32m     76\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     77\u001b[0m     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0m questions_and_contexts\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m([q[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m questions], contexts)))\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(questions_and_contexts) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_questions:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m contexts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     74\u001b[0m questions \u001b[38;5;241m=\u001b[39m question_generator(\n\u001b[1;32m     75\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate a question based on this text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m contexts],\n\u001b[1;32m     76\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     77\u001b[0m     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0m questions_and_contexts\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m([\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m questions], contexts)))\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(questions_and_contexts) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_questions:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Optimized RAG System Evaluation Notebook with Dataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score as bert_score\n",
    "import matplotlib.pyplot as plt\n",
    "from RAG_UTILS import RAGSystem, DocumentProcessor, LangchainDocument  # Import your existing RAG system\n",
    "from REMOVED_SECRET import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "MODEL_ID = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
    "RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n",
    "PDF_FOLDER_PATH = \"local_database\"  # Update this to your local database path\n",
    "CSV_PATH = \"processed_pdfs.csv\"\n",
    "NUM_EVALUATION_SAMPLES = 50  # Number of questions to generate for evaluation\n",
    "BATCH_SIZE = 8  # Adjust based on your GPU memory\n",
    "\n",
    "# Custom Dataset\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.documents[idx]\n",
    "    \n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = RAGSystem(\n",
    "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_id=MODEL_ID,\n",
    "    reranker_model=RERANKER_MODEL,\n",
    ")\n",
    "\n",
    "# Function to load data from CSV\n",
    "def load_from_csv(csv_path: str) -> List[LangchainDocument]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return [\n",
    "        LangchainDocument(page_content=row['content'], metadata={\"source\": row['source'], \"page\": row['page']})\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "# Load processed documents from CSV\n",
    "processed_documents = load_from_csv(CSV_PATH)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "document_dataset = DocumentDataset(processed_documents)\n",
    "document_dataloader = DataLoader(document_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "# Build vector database\n",
    "print(\"Building vector database...\")\n",
    "knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "\n",
    "# Initialize question generator\n",
    "question_generator = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\", device=0 if REMOVED_SECRET() else -1)\n",
    "\n",
    "def generate_questions(dataloader: DataLoader, num_questions: int) -> List[Tuple[str, str]]:\n",
    "    questions_and_contexts = []\n",
    "    for batch in tqdm(dataloader, desc=\"Generating questions\", total=min(len(dataloader), num_questions // BATCH_SIZE + 1)):\n",
    "        contexts = [doc.page_content for doc in batch]\n",
    "        questions = question_generator(\n",
    "            [f\"Generate a question based on this text: {context}\" for context in contexts],\n",
    "            max_length=50,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        questions_and_contexts.extend(list(zip([q[0]['generated_text'] for q in questions], contexts)))\n",
    "        if len(questions_and_contexts) >= num_questions:\n",
    "            break\n",
    "    return questions_and_contexts[:num_questions]\n",
    "\n",
    "# Generate evaluation questions\n",
    "print(\"Generating evaluation questions...\")\n",
    "eval_questions = generate_questions(document_dataloader, NUM_EVALUATION_SAMPLES)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_rag(questions_and_contexts: List[Tuple[str, str]]) -> List[dict]:\n",
    "    results = []\n",
    "    for question, context in tqdm(questions_and_contexts, desc=\"Evaluating RAG system\"):\n",
    "        answer, relevant_docs, _ = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"generated_answer\": answer,\n",
    "            \"relevant_docs\": relevant_docs\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Running RAG system evaluation...\")\n",
    "evaluation_results = evaluate_rag(eval_questions)\n",
    "\n",
    "def calculate_retrieval_metrics(results: List[dict]) -> dict:\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for result in results:\n",
    "        relevant_docs = set(tuple(doc.split()[:10]) for doc in result[\"relevant_docs\"])  # Use first 10 words as identifier\n",
    "        retrieved_docs = set(tuple(doc.split()[:10]) for doc in result[\"generated_answer\"].split('\\n'))  # Simplification, adjust as needed\n",
    "        precision = len(relevant_docs.intersection(retrieved_docs)) / len(retrieved_docs) if retrieved_docs else 0\n",
    "        recall = len(relevant_docs.intersection(retrieved_docs)) / len(relevant_docs) if relevant_docs else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return {\n",
    "        \"avg_precision\": np.mean(precisions),\n",
    "        \"avg_recall\": np.mean(recalls),\n",
    "        \"avg_f1\": np.mean(f1s)\n",
    "    }\n",
    "\n",
    "def calculate_bertscore(results: List[dict]) -> float:\n",
    "    references = [r[\"context\"] for r in results]\n",
    "    candidates = [r[\"generated_answer\"] for r in results]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def calculate_semantic_similarity(results: List[dict]) -> float:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        context_embedding = model.encode(result[\"context\"])\n",
    "        gen_embedding = model.encode(result[\"generated_answer\"])\n",
    "        similarity = np.dot(context_embedding, gen_embedding) / (REMOVED_SECRET(context_embedding) * REMOVED_SECRET(gen_embedding))\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Calculating evaluation metrics...\")\n",
    "retrieval_metrics = calculate_retrieval_metrics(evaluation_results)\n",
    "bertscore = calculate_bertscore(evaluation_results)\n",
    "semantic_similarity = calculate_semantic_similarity(evaluation_results)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRetrieval Metrics:\")\n",
    "print(f\"Average Precision: {retrieval_metrics['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {retrieval_metrics['avg_recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {retrieval_metrics['avg_f1']:.4f}\")\n",
    "print(f\"BERTScore: {bertscore:.4f}\")\n",
    "print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'BERTScore', 'Semantic Similarity']\n",
    "values = [retrieval_metrics['avg_precision'], retrieval_metrics['avg_recall'], \n",
    "          retrieval_metrics['avg_f1'], bertscore, semantic_similarity]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, values)\n",
    "plt.title('RAG System Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation complete. Results saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "bad196470bee4d6a8f2131574c6f758a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `REMOVED_SECRET.GradScaler(args...)` is deprecated. Please use `REMOVED_SECRET('cuda', args...)` instead.\n",
      "  self.scaler = REMOVED_SECRET.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vector database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating evaluation questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating questions:   0%|          | 0/7 [00:00<?, ?it/s]/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1282: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n",
      "Generating questions:  86%|████████▌ | 6/7 [02:21<00:23, 23.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RAG system evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/colbert/utils/amp.py:15: FutureWarning: `REMOVED_SECRET.autocast(args...)` is deprecated. Please use `REMOVED_SECRET('cuda', args...)` instead.\n",
      "  return REMOVED_SECRET.autocast() if self.activated else NullContextManager()\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/REMOVED_SECRET/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:   2%|▏         | 1/50 [02:11<1:47:10, 131.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:   4%|▍         | 2/50 [04:50<1:58:24, 148.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:   6%|▌         | 3/50 [07:47<2:06:03, 160.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:   8%|▊         | 4/50 [10:42<2:07:46, 166.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  10%|█         | 5/50 [13:22<2:03:14, 164.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  12%|█▏        | 6/50 [16:10<2:01:18, 165.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  14%|█▍        | 7/50 [19:02<2:00:08, 167.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  16%|█▌        | 8/50 [21:54<1:58:15, 168.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  18%|█▊        | 9/50 [24:40<1:54:55, 168.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  20%|██        | 10/50 [27:36<1:53:34, 170.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  22%|██▏       | 11/50 [29:51<1:43:48, 159.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  24%|██▍       | 12/50 [32:23<1:39:34, 157.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  26%|██▌       | 13/50 [35:12<1:39:15, 160.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  28%|██▊       | 14/50 [38:06<1:38:52, 164.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  30%|███       | 15/50 [41:00<1:37:49, 167.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  32%|███▏      | 16/50 [43:17<1:29:41, 158.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  34%|███▍      | 17/50 [45:48<1:25:48, 156.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  36%|███▌      | 18/50 [48:53<1:27:53, 164.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  38%|███▊      | 19/50 [51:42<1:25:50, 166.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  40%|████      | 20/50 [54:08<1:20:03, 160.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  42%|████▏     | 21/50 [57:01<1:19:18, 164.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  44%|████▍     | 22/50 [59:28<1:14:05, 158.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  46%|████▌     | 23/50 [1:02:01<1:10:42, 157.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  48%|████▊     | 24/50 [1:04:53<1:09:59, 161.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  50%|█████     | 25/50 [1:07:41<1:08:03, 163.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  52%|█████▏    | 26/50 [1:10:06<1:03:14, 158.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  54%|█████▍    | 27/50 [1:12:31<59:05, 154.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  56%|█████▌    | 28/50 [1:14:38<53:26, 145.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  58%|█████▊    | 29/50 [1:17:24<53:10, 151.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  60%|██████    | 30/50 [1:20:39<54:57, 164.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  62%|██████▏   | 31/50 [1:24:56<1:00:56, 192.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  64%|██████▍   | 32/50 [1:27:39<55:06, 183.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:24<00:00, 24.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  66%|██████▌   | 33/50 [1:31:54<58:07, 205.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  68%|██████▊   | 34/50 [1:35:36<56:03, 210.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  70%|███████   | 35/50 [1:39:10<52:49, 211.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  72%|███████▏  | 36/50 [1:41:51<45:45, 196.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  74%|███████▍  | 37/50 [1:44:31<40:09, 185.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  76%|███████▌  | 38/50 [1:47:22<36:12, 181.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:42<00:00, 42.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  78%|███████▊  | 39/50 [1:50:54<34:52, 190.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  80%|████████  | 40/50 [1:54:03<31:40, 190.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  82%|████████▏ | 41/50 [1:56:34<26:45, 178.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  84%|████████▍ | 42/50 [1:59:21<23:18, 174.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:22<00:00, 22.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  86%|████████▌ | 43/50 [2:03:09<22:14, 190.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  88%|████████▊ | 44/50 [2:05:29<17:33, 175.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  90%|█████████ | 45/50 [2:08:45<15:08, 181.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  92%|█████████▏| 46/50 [2:11:52<12:13, 183.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  94%|█████████▍| 47/50 [2:15:18<09:30, 190.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  96%|█████████▌| 48/50 [2:19:57<07:13, 216.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:  98%|█████████▊| 49/50 [2:24:20<03:50, 230.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "=> Reranking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked to 1 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system: 100%|██████████| 50/50 [2:32:01<00:00, 182.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "d0c65039651541ad8088e52140d0ef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['REMOVED_SECRET.bias', 'REMOVED_SECRET.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "dd509c973e9f458184c915ede8cc5f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "d90c67a9e8964a6d8d20e8c8828693b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 665.04 seconds, 0.08 sentences/sec\n",
      "\n",
      "Retrieval Metrics:\n",
      "Average Precision: 0.0117\n",
      "Average Recall: 0.0400\n",
      "Average F1 Score: 0.0180\n",
      "BERTScore: 0.5262\n",
      "Semantic Similarity: 0.2411\n"
     ]
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETSUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Results saved to 'rag_evaluation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Optimized RAG System Evaluation Notebook with Corrected Question Generation\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score as bert_score\n",
    "import matplotlib.pyplot as plt\n",
    "from RAG_UTILS import RAGSystem, DocumentProcessor, LangchainDocument  # Import your existing RAG system\n",
    "from REMOVED_SECRET import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "MODEL_ID = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
    "RERANKER_MODEL = None\n",
    "PDF_FOLDER_PATH = \"local_database\"  # Update this to your local database path\n",
    "CSV_PATH = \"processed_pdfs.csv\"\n",
    "NUM_EVALUATION_SAMPLES = 50  # Number of questions to generate for evaluation\n",
    "BATCH_SIZE = 8  # Adjust based on your GPU memory\n",
    "\n",
    "# Custom Dataset\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.documents[idx]\n",
    "\n",
    "# Custom collate function\n",
    "def custom_collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = RAGSystem(\n",
    "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_id=MODEL_ID,\n",
    "    reranker_model=RERANKER_MODEL,\n",
    ")\n",
    "\n",
    "# Function to load data from CSV\n",
    "def load_from_csv(csv_path: str) -> List[LangchainDocument]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return [\n",
    "        LangchainDocument(page_content=row['content'], metadata={\"source\": row['source'], \"page\": row['page']})\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "# Load processed documents from CSV\n",
    "processed_documents = load_from_csv(CSV_PATH)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "document_dataset = DocumentDataset(processed_documents)\n",
    "document_dataloader = DataLoader(document_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Build vector database\n",
    "print(\"Building vector database...\")\n",
    "knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "\n",
    "# Initialize question generator\n",
    "question_generator = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\", device=0 if REMOVED_SECRET() else -1)\n",
    "\n",
    "def generate_questions(dataloader: DataLoader, num_questions: int) -> List[Tuple[str, str]]:\n",
    "    questions_and_contexts = []\n",
    "    for batch in tqdm(dataloader, desc=\"Generating questions\", total=min(len(dataloader), num_questions // BATCH_SIZE + 1)):\n",
    "        contexts = [doc.page_content for doc in batch]\n",
    "        questions = question_generator(\n",
    "            [f\"Generate a question based on this text: {context[:500]}\" for context in contexts],  # Limit context length\n",
    "            max_length=50,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        questions_and_contexts.extend(list(zip([q['generated_text'] for q in questions], contexts)))\n",
    "        if len(questions_and_contexts) >= num_questions:\n",
    "            break\n",
    "    return questions_and_contexts[:num_questions]\n",
    "\n",
    "# Generate evaluation questions\n",
    "print(\"Generating evaluation questions...\")\n",
    "eval_questions = generate_questions(document_dataloader, NUM_EVALUATION_SAMPLES)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_rag(questions_and_contexts: List[Tuple[str, str]]) -> List[dict]:\n",
    "    results = []\n",
    "    for question, context in tqdm(questions_and_contexts, desc=\"Evaluating RAG system\"):\n",
    "        answer, relevant_docs, _ = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"generated_answer\": answer,\n",
    "            \"relevant_docs\": relevant_docs\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Running RAG system evaluation...\")\n",
    "evaluation_results = evaluate_rag(eval_questions)\n",
    "\n",
    "# Helper functions for different metrics\n",
    "def calculate_retrieval_metrics(results: List[dict]) -> dict:\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for result in results:\n",
    "        relevant_docs = set(tuple(doc.split()[:10]) for doc in result[\"relevant_docs\"])  # Use first 10 words as identifier\n",
    "        retrieved_docs = set(tuple(doc.split()[:10]) for doc in result[\"generated_answer\"].split('\\n'))  # Simplification, adjust as needed\n",
    "        precision = len(relevant_docs.intersection(retrieved_docs)) / len(retrieved_docs) if retrieved_docs else 0\n",
    "        recall = len(relevant_docs.intersection(retrieved_docs)) / len(relevant_docs) if relevant_docs else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return {\n",
    "        \"avg_precision\": np.mean(precisions),\n",
    "        \"avg_recall\": np.mean(recalls),\n",
    "        \"avg_f1\": np.mean(f1s)\n",
    "    }\n",
    "\n",
    "def calculate_bertscore(results: List[dict]) -> float:\n",
    "    references = [r[\"context\"] for r in results]\n",
    "    candidates = [r[\"generated_answer\"] for r in results]\n",
    "    P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=True)\n",
    "    return F1.mean().item()\n",
    "\n",
    "def calculate_semantic_similarity(results: List[dict]) -> float:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        context_embedding = model.encode(result[\"context\"])\n",
    "        gen_embedding = model.encode(result[\"generated_answer\"])\n",
    "        similarity = np.dot(context_embedding, gen_embedding) / (REMOVED_SECRET(context_embedding) * REMOVED_SECRET(gen_embedding))\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Calculating evaluation metrics...\")\n",
    "retrieval_metrics = calculate_retrieval_metrics(evaluation_results)\n",
    "bertscore = calculate_bertscore(evaluation_results)\n",
    "semantic_similarity = calculate_semantic_similarity(evaluation_results)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRetrieval Metrics:\")\n",
    "print(f\"Average Precision: {retrieval_metrics['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {retrieval_metrics['avg_recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {retrieval_metrics['avg_f1']:.4f}\")\n",
    "print(f\"BERTScore: {bertscore:.4f}\")\n",
    "print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'BERTScore', 'Semantic Similarity']\n",
    "values = [retrieval_metrics['avg_precision'], retrieval_metrics['avg_recall'], \n",
    "          retrieval_metrics['avg_f1'], bertscore, semantic_similarity]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, values)\n",
    "plt.title('RAG System Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation complete. Results saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/accelerate/utils/modeling.py:1405: UserWarning: Current model requires 5120 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "2df5116b8f8d442bad0e22fba9727226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vector database...\n",
      "Vector database built in 6.42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating evaluation questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating questions:   0%|          | 0/50 [00:00<?, ?it/s]/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1282: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n",
      "Generating questions:  20%|██        | 10/50 [04:30<15:42, 23.57s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Generating questions: 100%|██████████| 50/50 [13:57<00:00, 16.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions generated in 837.18 seconds\n",
      "Running RAG system evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG system:   0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RAGSystem' object has no attribute 'knowledge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning RAG system evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 101\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_questions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m total_eval_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_eval_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 74\u001b[0m, in \u001b[0;36mevaluate_rag\u001b[0;34m(questions_and_contexts)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question, context \u001b[38;5;129;01min\u001b[39;00m tqdm(questions_and_contexts, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating RAG system\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Retrieve documents\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 74\u001b[0m     relevant_docs \u001b[38;5;241m=\u001b[39m \u001b[43mrag_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknowledge_index\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query\u001b[38;5;241m=\u001b[39mquestion, k\u001b[38;5;241m=\u001b[39mNUM_RETRIEVED_DOCS)\n\u001b[1;32m     75\u001b[0m     retrieve_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# Generate answer\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RAGSystem' object has no attribute 'knowledge_index'"
     ]
    }
   ],
   "source": [
    "# Optimized RAG System Evaluation Notebook\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score as bert_score\n",
    "import matplotlib.pyplot as plt\n",
    "from RAG_UTILS import RAGSystem, DocumentProcessor, LangchainDocument  # Import your existing RAG system\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "MODEL_ID = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
    "RERANKER_MODEL = None  # Set to None to skip reranking\n",
    "CSV_PATH = \"processed_pdfs.csv\"\n",
    "NUM_EVALUATION_SAMPLES = 50\n",
    "NUM_RETRIEVED_DOCS = 5  # Reduced from 30 to 5\n",
    "MAX_NEW_TOKENS = 100  # Set maximum output length to 100 tokens\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = RAGSystem(\n",
    "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    model_id=MODEL_ID,\n",
    "    reranker_model=RERANKER_MODEL,\n",
    ")\n",
    "\n",
    "# Load processed documents from CSV\n",
    "def load_from_csv(csv_path: str) -> List[LangchainDocument]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return [\n",
    "        LangchainDocument(page_content=row['content'], metadata={\"source\": row['source'], \"page\": row['page']})\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "processed_documents = load_from_csv(CSV_PATH)\n",
    "\n",
    "# Build vector database\n",
    "print(\"Building vector database...\")\n",
    "start_time = time.time()\n",
    "knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "print(f\"Vector database built in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Initialize question generator\n",
    "question_generator = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\", device=0 if REMOVED_SECRET() else -1)\n",
    "\n",
    "def generate_questions(documents: List[LangchainDocument], num_questions: int) -> List[Tuple[str, str]]:\n",
    "    questions_and_contexts = []\n",
    "    for _ in tqdm(range(num_questions), desc=\"Generating questions\"):\n",
    "        doc = random.choice(documents)\n",
    "        context = doc.page_content[:500]  # Limit context length\n",
    "        question = question_generator(f\"Generate a question based on this text: {context}\", max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "        questions_and_contexts.append((question, context))\n",
    "    return questions_and_contexts\n",
    "\n",
    "# Generate evaluation questions\n",
    "print(\"Generating evaluation questions...\")\n",
    "start_time = time.time()\n",
    "eval_questions = generate_questions(processed_documents, NUM_EVALUATION_SAMPLES)\n",
    "print(f\"Questions generated in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Modified evaluation function\n",
    "def evaluate_rag(questions_and_contexts: List[Tuple[str, str]]) -> List[dict]:\n",
    "    results = []\n",
    "    for question, context in tqdm(questions_and_contexts, desc=\"Evaluating RAG system\"):\n",
    "        # Retrieve documents\n",
    "        start_time = time.time()\n",
    "        relevant_docs = REMOVED_SECRET(query=question, k=NUM_RETRIEVED_DOCS)\n",
    "        retrieve_time = time.time() - start_time\n",
    "        \n",
    "        # Generate answer\n",
    "        start_time = time.time()\n",
    "        answer, _, _ = rag_system.answer_with_rag(\n",
    "            question=question,\n",
    "            knowledge_index=knowledge_index,\n",
    "            num_retrieved_docs=NUM_RETRIEVED_DOCS,\n",
    "            num_docs_final=NUM_RETRIEVED_DOCS,  # No reranking, so use all retrieved docs\n",
    "            max_new_tokens=MAX_NEW_TOKENS\n",
    "        )\n",
    "        generate_time = time.time() - start_time\n",
    "        \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"context\": context,\n",
    "            \"generated_answer\": answer,\n",
    "            \"relevant_docs\": [doc.page_content for doc in relevant_docs],\n",
    "            \"retrieve_time\": retrieve_time,\n",
    "            \"generate_time\": generate_time\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Running RAG system evaluation...\")\n",
    "start_time = time.time()\n",
    "evaluation_results = evaluate_rag(eval_questions)\n",
    "total_eval_time = time.time() - start_time\n",
    "print(f\"Evaluation completed in {total_eval_time:.2f} seconds\")\n",
    "\n",
    "# Helper functions for different metrics\n",
    "def calculate_retrieval_metrics(results: List[dict]) -> dict:\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for result in results:\n",
    "        relevant_set = set(result[\"context\"].split())\n",
    "        retrieved_set = set(result[\"generated_answer\"].split())\n",
    "        precision = len(relevant_set.intersection(retrieved_set)) / len(retrieved_set) if retrieved_set else 0\n",
    "        recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set) if relevant_set else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    return {\n",
    "        \"avg_precision\": np.mean(precisions),\n",
    "        \"avg_recall\": np.mean(recalls),\n",
    "        \"avg_f1\": np.mean(f1s)\n",
    "    }\n",
    "\n",
    "def calculate_semantic_similarity(results: List[dict]) -> float:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        context_embedding = model.encode(result[\"context\"])\n",
    "        gen_embedding = model.encode(result[\"generated_answer\"])\n",
    "        similarity = np.dot(context_embedding, gen_embedding) / (REMOVED_SECRET(context_embedding) * REMOVED_SECRET(gen_embedding))\n",
    "        similarities.append(similarity)\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Calculating evaluation metrics...\")\n",
    "start_time = time.time()\n",
    "retrieval_metrics = calculate_retrieval_metrics(evaluation_results)\n",
    "semantic_similarity = calculate_semantic_similarity(evaluation_results)\n",
    "print(f\"Metrics calculated in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRetrieval Metrics:\")\n",
    "print(f\"Average Precision: {retrieval_metrics['avg_precision']:.4f}\")\n",
    "print(f\"Average Recall: {retrieval_metrics['avg_recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {retrieval_metrics['avg_f1']:.4f}\")\n",
    "print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n",
    "\n",
    "# Calculate and print timing statistics\n",
    "retrieve_times = [r['retrieve_time'] for r in evaluation_results]\n",
    "generate_times = [r['generate_time'] for r in evaluation_results]\n",
    "print(f\"\\nAverage retrieval time: {np.mean(retrieve_times):.2f} seconds\")\n",
    "print(f\"Average generation time: {np.mean(generate_times):.2f} seconds\")\n",
    "print(f\"Total evaluation time: {total_eval_time:.2f} seconds\")\n",
    "\n",
    "# Visualize results\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'Semantic Similarity']\n",
    "values = [retrieval_metrics['avg_precision'], retrieval_metrics['avg_recall'], \n",
    "          retrieval_metrics['avg_f1'], semantic_similarity]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, values)\n",
    "plt.title('RAG System Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "results_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation complete. Results saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDFs to CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading PDFs: 100%|██████████| 30/30 [00:03<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question:\\n\\nwho owns st andrews golf course in scotland\\n\\nAnswer:\\n\\n<P> The Old Course at St Andrews is considered the oldest golf course in the world , a public\\n\\ncourse over common land in St Andrews , Fife , Scotland . It is held in trust by The St Andrews\\n\\nLinks Trust under an act of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have playing privileges on\\n\\nthe course , along with the general public . </P>\\n\\nContext:\\n\\nOld Course at St Andrews - wikipedia Old Course at St Andrews Jump to :\\n\\nnavigation , search Old Course R&A Clubhouse and 18th green in 2004 Club\\n\\ninformation\\n\\nCoordinates\\n\\n56 ° 20\\n\\n35 ''\\n\\nN 2 ° 48\\n\\n11 ''\\n\\n56.343 °\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Coordinates : 56 ° 20 35 '' N 2 ° 48 11 ''\\n\\nW\\n\\n56.343\\n\\n°\\n\\nN\\n\\n2.803\\n\\n°\\n\\n/ 56.343 ; - 2.803 Location St Andrews ,\\n\\nW\\n\\n/\\n\\nW\\n\\n/\\n\\nW\\n\\nScotland Established 1552 Type Public Owned by Fife Council\\n\\nOperated by St Andrews Links Trust Total holes 18 Tournaments hosted\\n\\nThe Open Championship , Alfred Dunhill Links Championship Website Old\\n\\nCourse Par 72 Length 7,305 yards ( 6,680 m ) Course record\\n\\n61 ; Ross Fisher ( 2017 ) St Andrews Location in Scotland St Andrews\\n\\nLocation in Fife , Scotland The Old Course at St Andrews is considered the\\n\\noldest golf course in the world , a public course over common land in St Andrews\\n\\n, Fife , Scotland . It is held in trust by The St Andrews Links Trust under an\\n\\nact of Parliament . The Royal and Ancient Golf Club of St Andrews club house\\n\\nsits adjacent to the first tee , although it is but one of many clubs that have\\n\\nplaying privileges on the course , along with the general public . Contents\\n\\n( hide ) 1 History 1.1 Governance 1.2 Influence on modern golf 1.3 Old\\n\\nCourse and Bobby Jones 2 Features 3 The Open Championship 4 Scorecard\\n\\n5 Women 's British Open 6 Senior Open Championship 7 See also 8 References\\n\\n9 External links History ( edit ) The Old Course at St Andrews is\\n\\nconsidered by many to be the `` home of golf '' because the sport was first\\n\\nplayed on the Links at St Andrews in the early 15th century . Golf was becoming\\n\\nincreasingly popular in Scotland until in 1457 , when James II of Scotland\\n\\nbanned golf because he felt that young men were playing too much golf instead of\\n\\npractising their archery . The ban was upheld by the following kings of Scotland\\n\\nuntil 1502 , when King James IV became a\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question:\\n\\nequation for the velocity of an object in motion at constant acceleration\\n\\nAnswer:\\n\\nContext:\\n\\nEquations of motion - wikipedia Equations of motion Jump to : navigation ,\\n\\nsearch Classical mechanics F = m a ( \\\\ displaystyle ( \\\\ vec ( F ) ) =\\n\\nm ( \\\\ vec ( a ) ) ) Second law of motion History Timeline Branches\\n\\n( show ) Applied Celestial Continuum Dynamics Kinematics Kinetics\\n\\nStatics Statistical Fundamentals ( show ) Acceleration Angular\\n\\nmomentum Couple D'Alembert's principle Energy kinetic potential\\n\\nForce Frame of reference Impulse Inertia / Moment of inertia Mass\\n\\nMechanical power Mechanical work Moment Momentum Space Speed Time\\n\\nTorque Velocity Virtual work Formulations ( show ) Newton 's laws of\\n\\nmotion Analytical mechanics Lagrangian mechanics Hamiltonian mechanics\\n\\nRouthian mechanics Hamilton -- Jacobi equation Appell 's equation of motion\\n\\nUdwadia -- Kalaba equation Koopman -- von Neumann mechanics Core\\n\\ntopics ( show ) Damping ( ratio ) Displacement Equations of motion Euler\\n\\n's laws of motion Fictitious force Friction Harmonic oscillator\\n\\nInertial / Non-inertial reference frame Mechanics of planar particle motion\\n\\nMotion ( linear ) Newton 's law of universal gravitation Newton 's laws of\\n\\nmotion Relative velocity Rigid body dynamics Euler 's equations\\n\\nSimple harmonic motion Vibration Rotation ( show ) Circular motion\\n\\nRotating reference frame Centripetal force Centrifugal force reactive\\n\\nCoriolis force Pendulum Tangential speed Rotational speed Angular\\n\\nacceleration / displacement / frequency / velocity Scientists ( show )\\n\\nGalileo Newton Kepler Horrocks Halley Euler d'Alembert Clairaut\\n\\nLagrange Laplace Hamilton Poisson Daniel Bernoulli Johann Bernoulli\\n\\nCauchy In mathematical physics , equations of motion are\\n\\nequations that describe the behaviour of a physical system in terms of its\\n\\nmotion as a function of time . More specifically , the equations of motion\\n\\nde\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question:\\n\\nwho sang take that look off your face\\n\\nAnswer:\\n\\n<P> `` Take That Look Off Your Face '' is the title of a hit song by musical theatre composer\\n\\nAndrew Lloyd Webber . Collaborating with lyricist Don Black , it was written for the song cycle\\n\\nshow Tell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 , and\\n\\nbecame a No. 3 hit in the UK charts . The song was also popular in Ireland , and spent six weeks\\n\\nat number one . Later , Tell Me on a Sunday was combined with another Lloyd Webber work ,\\n\\nVariations , to form an entire new show , Song and Dance . </P>\\n\\nContext:\\n\\nTake that Look Off Your Face - Wikipedia Take that Look Off Your Face Jump to\\n\\n: navigation , search `` Take That Look Off Your Face '' Single by\\n\\nMarti Webb from the album Tell Me on a Sunday B - side `` Sheldon\\n\\nBloom '' Released January 1980 Format 7 '' single Recorded\\n\\n1979 Genre Pop , MOR , Theatrical Length 3 : 27 Label Polydor\\n\\nSongwriter ( s ) Andrew Lloyd Webber , Don Black Producer ( s ) Andrew\\n\\nLloyd Webber Marti Webb singles chronology `` D - Darling '' ( 1973 )\\n\\n`` Take That Look Off Your Face '' ( 1980 ) `` Tell Me on a Sunday '' ( 1980 )\\n\\n`` D - Darling '' ( 1973 ) `` Take That Look Off Your Face '' ( 1980 ) ``\\n\\nTell Me on a Sunday '' ( 1980 ) `` Take That Look Off Your Face '' is the\\n\\ntitle of a hit song by musical theatre composer Andrew Lloyd Webber .\\n\\nCollaborating with lyricist Don Black , it was written for the song cycle show\\n\\nTell Me on a Sunday in 1978 . It was sung and released by Marti Webb in 1980 ,\\n\\nand became a No. 3 hit in the UK charts . The song was also popular in Ireland ,\\n\\nand spent six weeks at number one . Later , Tell Me on a Sunday was combined\\n\\nwith another Lloyd Webber work , Variations , to form an entire new show , Song\\n\\nand Dance . The song is about a woman being told of her boyfriend 's\\n\\ninfidelity . The woman denies this initially , before rebuking her newsbearer (\\n\\na girlfriend ) with the revelation that she `` knew before '' and had done for\\n\\nsome time . She also spends much of the song criticising her friend for rushing\\n\\nto break the `` bad news '' to her . Despite having been written during the\\n\\ncreative process for Tell Me on a Sunday , the song was n't recorded during the\\n\\nalbum 's principal sessions . Black reminded Lloyd Webber that they had missed a\\n\\ntrack , then entitled `` You Must Be Mistaken '' . John Mole , the bass guitar\\n\\nplayer , improvised a part reminiscent of the arrangement style of Phil Spector\\n\\n, inspiring the rest of the orchestra\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content='Question:\\n\\nwho was gails most recent husband in coronation street\\n\\nAnswer:\\n\\nContext:\\n\\nGail McIntyre - wikipedia Gail McIntyre Gail McIntyre Coronation\\n\\nStreet character Portrayed by Helen Worth Duration 1974 -- First\\n\\nappearance Episode 1412 29 July 1974 Introduced by H.V. Kershaw Book\\n\\nappearances Coronation Street : The Complete Saga Norman Bates with a\\n\\nBriefcase : The story of Richard Hillman Spin - off appearances East\\n\\nStreet ( 2010 ) Classification Present ; regular Profile Other\\n\\nnames Gail Potter Gail Tilsley Gail Platt Gail McIntyre Gail Hillman\\n\\nGail Rodwell Occupation Receptionist Cleaner Waitress Factory\\n\\nWorker Newsagent Home 8 Coronation Street ( 1991 - 33 Hammond Road\\n\\n( 1985 - 1991 ) 5 Buxton Close ( 1980 - 1983 ) 5 Coronation Street ( 1979 -\\n\\n1980 , 1983 - 1985 ) 11 Coronation Street ( 1976 - 1979 ) 15a Coronation\\n\\nStreet ( 1975 - 1976 ) show Family Father Ted Page Mother\\n\\nAudrey Roberts Stepfather Alf Roberts Half - brothers Stephen Reid\\n\\nHusband Brian Tilsley ( 1979 -- 1987 , 1988 -- 1989 ) Martin Platt ( 1991\\n\\n-- 2001 ) Richard Hillman ( 2002 -- 2003 ) Joe McIntyre ( 2010 ) Michael\\n\\nRodwell ( 2015 -- 2016 ) Sons Nick Tilsley David Platt Daughters\\n\\nSarah Platt Stepdaughters Tina McIntyre Grandsons Billy Platt\\n\\nHarry Platt Max Turner ( step ) Granddaughters Bethany Platt Lily\\n\\nPlatt Grandfathers Robert Potter Grandmothers Nancy Potter\\n\\nGail Rodwell ( also Potter , Tilsley , Platt , Hillman and McIntyre ) is a\\n\\nfictional character from the British ITV soap opera , Coronation Street .\\n\\nPortrayed by Helen Worth , the character first appeared on - screen on 29 July\\n\\n1974 . As of 2018 , Gail has been on the show for 44 years , which currently\\n\\nmakes her the third longest - running character on the show after Ken Barlow and\\n\\nRita Tanner . Gail is the daughter of Audrey Roberts ( Sue Nicholls ) and Ted\\n\\nPage ( Michael Byrne ) and is the mother of Nick Tilsley (', metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content=\"Question:\\n\\nwhen did they figure out that yeast made bread rise\\n\\nAnswer:\\n\\n<P> The most common source of leavening in antiquity was to retain a piece of dough ( with\\n\\nsugar and water in ) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to produce `` a\\n\\nlighter kind of bread than other peoples . '' Parts of the ancient world that drank wine instead of\\n\\nbeer used a paste composed of grape must and flour that was allowed to begin fermenting , or\\n\\nwheat bran steeped in wine , as a source for yeast . </P>\\n\\nContext:\\n\\nHistory of bread - wikipedia History of bread Jump to : navigation , search\\n\\nSlab stele from mastaba tomb of Itjer at Giza . 4th Dynasty , 2543 - 2435 BC .\\n\\nItjer is seated at a table with slices of bread , shown vertical by convention .\\n\\nEgyptian Museum , Turin Bread was central to the formation of early human\\n\\nsocieties . From the western half of Asia , where wheat was domesticated ,\\n\\ncultivation spread north and west , to Europe and North Africa . This in turn\\n\\nled to the formation of towns , as opposed to the nomadic lifestyle , and gave\\n\\nrise to more and more sophisticated forms of societal organization . Similar\\n\\ndevelopments occurred in eastern Asia , centered on rice , and in the Americas\\n\\nwith maize . Contents ( hide ) 1 Antiquity 2 Middle Ages 3 To the\\n\\n19th century 4 Industrialization 5 See also 6 Notes Antiquity ( edit\\n\\n) Conical loaves of bread as grave goods exactly as laid out in the Great Tomb\\n\\n, North Necropolis , Gebelein , 5th Dynasty ( Old Kingdom ) , 2435 - 2305 BC .\\n\\nExcavations by Ernesto Schiaparelli , 1911 . Egyptian Museum , Turin , S. 14051\\n\\n14055 There is extensive evidence of breadmaking in Ancient Egypt in the form\\n\\nof artistic depictions , remains of structures and items used in bread making ,\\n\\nand remains of the dough and bread itself . The most common source of\\n\\nleavening in antiquity was to retain a piece of dough ( with sugar and water in\\n\\n) from the previous day to utilize as a form of sourdough starter . Pliny the\\n\\nElder reported that the Gauls and Iberians used the foam skimmed from beer to\\n\\nproduce `` a lighter kind of bread than other peoples . '' Parts of the ancient\\n\\nworld that drank wine instead of beer used a paste composed of grape must and\\n\\nflour that was allowed to begin fermenting , or wheat bran steeped in wine , as\\n\\na source for yeast . The idea of a free - standing oven that could be pre-\\n\\nheated , with a door for access , appears to have been Greek . Even in\\n\\nantiquity there were a wide variety of breads\", metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question:\\n\\nwho led the various reform movements of the 19th century\\n\\nAnswer:\\n\\nContext:\\n\\nConservation movement - wikipedia Conservation movement Jump to : navigation ,\\n\\nsearch For specific types of conservation , see Conservation ( disambiguation )\\n\\n. `` Conservationism '' redirects here . It is not to be confused with\\n\\nConservatism . Much attention has been given to preserving the natural\\n\\ncharacteristics of Hopetoun Falls , Australia , while allowing ample access for\\n\\nvisitors . Part of the Politics series Party politics Political\\n\\nspectrum Left - wing Far - left Hard - Left Extreme left\\n\\nCentre Centre - left Radical center Centre - right , Third Position\\n\\nRight - wing Far - right Hard right New right Alt - right Alt -\\n\\nlite Party platform Extremist Radical Moderate\\n\\nReformist Syncretic Third Position Conservative Fundamentalist\\n\\nReactionary Party system Non-partisan One - party\\n\\nDominant - party Two - party Multi-party Coalition Hung\\n\\nparliament Confidence and supply Minority government Rainbow coalition\\n\\nGrand coalition Full coalition National unity government Majority\\n\\ngovernment Lists Ruling parties by country Political parties by UN\\n\\ngeoscheme Political ideologies Politics portal The\\n\\nconservation movement , also known as nature conservation , is a political ,\\n\\nenvironmental and a social movement that seeks to protect natural resources\\n\\nincluding animal and plant species as well as their habitat for the future .\\n\\nThe early conservation movement included fisheries and wildlife management ,\\n\\nwater , soil conservation and sustainable forestry . The contemporary\\n\\nconservation movement has broadened from the early movement 's emphasis on use\\n\\nof sustainable yield of natural resources and preservation of wilderness areas\\n\\nto include preservation of biodiversity . Some say the conservation movement is\\n\\npart of the broader and more far - reaching environmental movement , while\\n\\nothers arg\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content=\"Question:\\n\\nwho has climbed the great wall of china\\n\\nAnswer:\\n\\nContext:\\n\\nGreat Wall of China - wikipedia Great Wall of China Jump to : navigation ,\\n\\nsearch `` Great Wall '' redirects here . For other uses , see Great Wall (\\n\\ndisambiguation ) . Great Wall of China The Great Wall of China\\n\\nat Jinshanling Map of all the wall constructions General information\\n\\nType Fortification Country China Coordinates 40 ° 41 N 117 ° 14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Coordinates : 40 ° 41 N 117\\n\\n°\\n\\n14\\n\\n40.68\\n\\n°\\n\\nN\\n\\n117.23\\n\\n/ 40.68 ; 117.23 Technical details\\n\\nSize 21,196 km ( 13,171 mi ) UNESCO World Heritage Site Criteria\\n\\nCultural : ( i ) , ( ii ) , ( iii ) , ( iv ) , ( vi ) Reference 438\\n\\n°\\n\\n°\\n\\nE\\n\\n/\\n\\nE\\n\\nE\\n\\n/\\n\\nE\\n\\nInscription 1987 ( 11th Session ) ( edit on Wikidata ) Great\\n\\nWall of China Simplified Chinese Traditional Chinese\\n\\nLiteral meaning `` The Long Wall '' ( show ) Transcriptions\\n\\nStandard Mandarin Hanyu Pinyin Chángchéng Wade -- Giles Ch'ang -\\n\\nch'eng\\n\\nIPA\\n\\nh\\n\\n) Wu Romanization Saon sen Yue :\\n\\nCantonese\\n\\nYale Romanization\\n\\nCheung sing\\n\\ntsh\\n\\n. s )\\n\\nJyutping\\n\\nCoeng sing\\n\\nSouthern Min\\n\\nTn\\n\\ng - siân Tâi -\\n\\nlô\\n\\nTn\\n\\ng - siânn Alternative Chinese name Simplified Chinese\\n\\nTraditional Chinese Literal meaning `` The 10,000 - Mile Long Wall\\n\\n'' ( show ) Transcriptions Wu Romanization Vae - li saon - sen\\n\\nYue : Cantonese Yale Romanization Maan lei Cheung sing IPA ( màn.\\n\\nle\\n\\ni\\n\\n(\\n\\nIPA\\n\\nHokkien POJ\\n\\nh.\\n\\n(\\n\\ntsh\\n\\n. s ) Jyutping Maan - lei coeng - sing Southern Min\\n\\nTâi\\n\\n\\n\\nlô\\n\\nBn\\n\\ntn\\n\\ng - siânn The Great Wall of China is a series\\n\\nof fortifications made of stone , brick , tamped earth , wood , and other\\n\\nmaterials , generally built along an east - to - west line across the historical\\n\\nnorthern borders of China to protect the Chinese states and empires against the\\n\\nraids and invasions of the various nomadic groups of the Eu\\n\\n\\n\\nlí\", metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content='Question:\\n\\nwhen did star trek the next generation first air\\n\\nAnswer:\\n\\n<Table> <Tr> <Th colspan=\"2\"> Season </Th> <Th colspan=\"2\"> Episodes </Th> <Th\\n\\ncolspan=\"2\"> Originally aired </Th> </Tr> <Tr> <Th> First aired </Th> <Th> Last aired </Th>\\n\\n</Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 28 , 1987 ( 1987 - 09 - 28 ) </Td> <Td> May 16 , 1988 ( 1988 - 05 - 16\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 22 </Td> <Td\\n\\ncolspan=\"1\"> November 21 , 1988 ( 1988 - 11 - 21 ) </Td> <Td> July 17 , 1989 ( 1989 - 07 - 17 )\\n\\n</Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 25 , 1989 ( 1989 - 09 - 25 ) </Td> <Td> June 18 , 1990 ( 1990 - 06 - 18\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 24 , 1990 ( 1990 - 09 - 24 ) </Td> <Td> June 17 , 1991 ( 1991 - 06 - 17\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 5 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 23 , 1991 ( 1991 - 09 - 23 ) </Td> <Td> June 15 , 1992 ( 1992 - 06 - 15\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 6 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 21 , 1992 ( 1992 - 09 - 21 ) </Td> <Td> June 21 , 1993 ( 1993 - 06 - 21\\n\\n) </Td> </Tr> <Tr> <Td> </Td> <Td colspan=\"1\"> 7 </Td> <Td colspan=\"2\"> 26 </Td> <Td\\n\\ncolspan=\"1\"> September 20 , 1993 ( 1993 - 09 - 20 ) </Td> <Td> May 23 , 1994 ( 1994 - 05 - 23\\n\\n) </Td> </Tr> </Table>\\n\\nContext:\\n\\nStar Trek : the Next Generation - wikipedia Star Trek : the Next Generation\\n\\nJump to : navigation , search This article is about the television series . For\\n\\nthe games , see Star Trek : The Next Generation ( 1994 video game ) and Star\\n\\nTrek : The Next Generation : A World For All Seasons . Star Trek : The Next\\n\\nGeneration Genre Science fiction Drama Mystery Action\\n\\nadventure Created by Gene Roddenberry Based on Star Trek by Gene\\n\\nRoddenberry Starring Patrick Stewart Jonathan Frakes Brent Spiner\\n\\nLeVar Burton Denise Crosby Michael Dorn Gates McFadden Marina Sirtis\\n\\nWil Wheaton Theme music composer Alexander Courage Jerry Goldsmith\\n\\nComposer ( s ) Dennis McCarthy Jay Chattaway Ron Jones Country of origin\\n\\nUnited States Original language ( s ) English No. of seasons 7\\n\\nNo. of episodes 178 ( list of episodes ) Production Executive producer\\n\\n( s ) Gene Roddenberry ( 1987 -- 91 ) Rick Berman ( 1989 -- 94 )\\n\\nShowrunners Maurice Hurley ( 1988 -- 89 ) Michael Piller ( 1989 -- 94 )\\n\\nJeri Taylor ( 1993 -- 94 ) Cinematography Edward R. Brown ( 1987 -- 89\\n\\n) Marvin V. Rush ( 1989 -- 92 ) Jonathan West ( 1992 -- 94 ) Running\\n\\ntime 44 minutes Production company ( s ) Paramount Domestic Television\\n\\nDistributor CBS Television Distribution Budget $1.3 million per episode\\n\\nRelease Original network First - run syndication Picture format\\n\\nNTSC 480i 4 : 3 1080p 4 : 3 ( Blu - ray ) Audio format Dolby SR\\n\\nDolby Digital 5.1 ( DVD ) DTS - HD Master Audio 7.1 Blu - ray Original\\n\\nrelease September 28 , 1987 ( 1987 - 09 - 28 ) -- May 23 , 1994 ( 1994 - 05 -\\n\\n23 ) Chronology Preceded by Star Trek : The Animated Series\\n\\nFollowed by Star Trek : Deep Space Nine Related shows Star Trek TV\\n\\nseries External links Star Trek : The Next Generation at StarTrek.com\\n\\nStar Trek : The Next Generation ( abbreviated as TNG and ST : TNG ) i', metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content=\"Question:\\n\\nwhere were deep-sea hydrothermal vents first discovered 25 years ago\\n\\nAnswer:\\n\\nContext:\\n\\nHydrothermal vent - wikipedia Hydrothermal vent Jump to : navigation , search\\n\\nMarine habitats White smokers emitting liquid rich in barium , calcium ,\\n\\nsilicon and carbon dioxide at the Champagne vent , Northwest Eifuku volcano ,\\n\\nMarianas Trench Marine National Monument Littoral zone Intertidal zone\\n\\nEstuaries Kelp forests Coral reefs Ocean banks Continental shelf\\n\\nNeritic zone Straits Pelagic zone Oceanic zone Seamounts Hydrothermal\\n\\nvents Cold seeps Demersal zone Benthic zone A\\n\\nhydrothermal vent is a fissure in a planet 's surface from which geothermally\\n\\nheated water issues . Hydrothermal vents were discovered years ago in 1977 .\\n\\nHydrothermal vents are commonly found near volcanically active places , areas\\n\\nwhere tectonic plates are moving apart at spreading centers , ocean basins , and\\n\\nhotspots . Hydrothermal vents exist because the earth is both geologically\\n\\nactive and has large amounts of water on its surface and within its crust .\\n\\nCommon land types include hot springs , fumaroles and geysers . Under the sea ,\\n\\nhydrothermal vents may form features called black smokers . Relative to the\\n\\nmajority of the deep sea , the areas around submarine hydrothermal vents are\\n\\nbiologically more productive , often hosting complex communities fueled by the\\n\\nchemicals dissolved in the vent fluids . Chemosynthetic bacteria and archaea\\n\\nform the base of the food chain , supporting diverse organisms , including giant\\n\\ntube worms , clams , limpets and shrimp . Active hydrothermal vents are believed\\n\\nto exist on Jupiter 's moon Europa , and Saturn 's moon Enceladus , and it is\\n\\nspeculated that ancient hydrothermal vents once existed on Mars . Contents\\n\\n( hide ) 1 Physical properties 2 Black smokers and white smokers 3\\n\\nBiological communities 4 Biological theories 4.1 The Deep Hot Biosphere\\n\\n4.2 Hydrothermal origin of life 5 Discovery and exploration 6 Distribution\\n\\n7 Exploitation 8 Conservation 9 See also 10 References\", metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question:\\n\\nthe period of european history between ancient and modern eras\\n\\nAnswer:\\n\\nContext:\\n\\nHistory of Europe - wikipedia History of Europe Jump to : navigation , search\\n\\nThe history of Europe covers the peoples inhabiting Europe from prehistory to\\n\\nthe present . The period known as classical antiquity began with the emergence\\n\\nof the city - states of ancient Greece . Later , the Roman Empire came to\\n\\ndominate the entire Mediterranean basin . The fall of the Roman Empire in AD 476\\n\\ntraditionally marks the start of the Middle Ages . Beginning in the 14th century\\n\\na Renaissance of knowledge challenged traditional doctrines in science and\\n\\ntheology . Simultaneously , the Protestant Reformation set up Protestant\\n\\nchurches primarily in Germany , Scandinavia and England . After 1800 , the\\n\\nIndustrial Revolution brought prosperity to Britain and Western Europe . The\\n\\nmain powers set up colonies in most of the Americas and Africa , and parts of\\n\\nAsia . In the 20th century , World War I , and World War II resulted in massive\\n\\nnumbers of deaths . The Cold War dominated European geo - politics from 1947 to\\n\\n1989 . Unification into a European Union moved forward after 1950 , with some\\n\\nsetbacks . Today , most countries west of Russia belong to the NATO military\\n\\nalliance , along with the United States and Canada . Europe depicted by Antwerp\\n\\ncartographer Abraham Ortelius in 1595 Contents ( hide ) 1 Overview 2\\n\\nPrehistory 3 Minoans and Mycenae 2700 -- 1100 BC 4 Classical antiquity 4.1\\n\\nAncient Greece 4.2 The rise of Rome 4.3 Decline of the Roman Empire 4.4\\n\\nLate Antiquity and Migration Period 5 Middle Ages 5.1 Byzantium 5.2\\n\\nEarly Middle Ages 5.2. 1 Feudal Christendom 5.3 High Middle Ages 5.3. 1\\n\\nA divided church 5.3. 2 Holy wars 5.4 Late Middle Ages 6 Early modern\\n\\nEurope 6.1 Renaissance 6.2 Exploration and trade 6.3 Reformation 6.4\\n\\nMercantilism and colonial expansion 6.5 Crisis of the 17th century 6.6 Age\\n\\nof Absolutism 6.6. 1 Thirty Years ' War 1618 -- 1648 6.6. 2 War of the\\n\\nSpanish Succession 6.6. 3 Prussia 6.6. 4 Rus\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question:\\n\\nwho sang the most wonderful summer of my life\\n\\nAnswer:\\n\\n<P> Jackie Ward ( born Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an\\n\\nAmerican singer , regarded as a `` one - hit wonder '' of 1963 million - selling song `` Wonderful\\n\\nSummer '' . However , using her real name she was highly accomplished and successful singing in\\n\\ngroups . Ward 's voice is heard in U.S. television series , motion pictures , advertisements , and\\n\\npop records . She is one of the real singers of the hits attributed to The Partridge Family . </P>\\n\\nContext:\\n\\nRobin Ward ( singer ) - wikipedia Robin Ward ( singer ) This article may\\n\\nneed to be rewritten entirely to comply with Wikipedia 's quality standards .\\n\\nYou can help . The discussion page may contain suggestions . ( January 2018 )\\n\\nRobin Ward Birth name Jacqueline McDonnell Also known as Jackie Ward\\n\\n1941 ( age 76 -- 77 ) Hawaii , USA Genres Pop , TV theme songs , Movie\\n\\nsongs , Advertising Occupation ( s ) Singer Instruments Voice\\n\\nYears active 1954 -- 1979 Labels Dot Records Associated acts\\n\\nPartridge Family , Ray Conniff Singers , Ron Hicklin Singers Jackie Ward (\\n\\nborn Jacqueline McDonnell , 1941 ) , better known as Robin Ward , is an American\\n\\nsinger , regarded as a `` one - hit wonder '' of 1963 million - selling song ``\\n\\nWonderful Summer '' . However , using her real name she was highly accomplished\\n\\nand successful singing in groups . Ward 's voice is heard in U.S. television\\n\\nseries , motion pictures , advertisements , and pop records . She is one of the\\n\\nreal singers of the hits attributed to The Partridge Family . Contents 1\\n\\nBiography 1.1 Early years 1.2 `` Wonderful Summer '' 1.3 Post `` Robin\\n\\nWard '' TV , movies , and records singing 1.4 The Partridge Family 2\\n\\nReferences 3 External links Biography ( edit ) Early years ( edit )\\n\\nWard was born Jacqueline McDonnell in 1941 to a military family in Hawaii ( her\\n\\nfather served in the US Navy ) and raised in Nebraska . Her first public singing\\n\\nperformances were with her two sisters in a Nebraska church when she was eight\\n\\nyears old . After the trio won a national talent search run by Horace Heidt ,\\n\\nthey moved to Los Angeles to seek work in the music industry . At the age of\\n\\n13 , Ward was hired by Los Angeles television station KTLA to sing on a Your Hit\\n\\nParade - like program , Bandstand Revue ; Ward performed popular hits for four\\n\\nyears . Then she started a career of singing on demo and released recordings .\\n\\nOne 1962 session was singing the `` la la\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question:\\n\\nhow many beverly hills cops movies are there\\n\\nAnswer:\\n\\n<P> Beverly Hills Cop is a series of American action comedy films and an unaired television pilot\\n\\nbased on characters created by Daniel Petrie , Jr. and Danilo Bach . The films star Eddie Murphy\\n\\nas Axel Foley , a street - smart Detroit cop who travels to Beverly Hills , California to investigate\\n\\ncrimes , even though it is out of his jurisdiction . There , he meets Detective Billy Rosewood (\\n\\nJudge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and Lieutenant Andrew Bogomil ( Ronny\\n\\nCox ) . Ashton and Cox do not appear in Beverly Hills Cop III . Murphy , Reinhold , and Gil Hill ,\\n\\nwho plays Axel 's boss , Inspector Todd , are the only actors who appear in all three films . Harold\\n\\nFaltermeyer produced the now famous `` Axel F '' theme song heard throughout the series . The\\n\\nseries as a whole have been distributed by Paramount Pictures . The films have made a total of $\\n\\n735,534,503 at the worldwide box office . </P>\\n\\nContext:\\n\\nBeverly Hills Cop ( film series ) - wikipedia Beverly Hills Cop ( film series )\\n\\nJump to : navigation , search Beverly Hills Cop Directed by\\n\\nMartin Brest ( I ) Tony Scott ( II ) John Landis ( III ) Adil El Arbi ( IV\\n\\n) Bilall Fallah ( IV ) Produced by Jerry Bruckheimer ( I - II , IV )\\n\\nDon Simpson ( I - II ) Mace Neufeld ( III ) Robert Rehme ( III ) Eddie\\n\\nMurphy ( IV ) Screenplay by Daniel Petrie , Jr . ( I ) Larry\\n\\nFerguson ( II ) Warren Skaaren ( II ) Steven E. de Souza ( III ) Josh\\n\\nAppelbaum ( IV ) André Nemec ( IV ) Story by Danilo Bach ( I )\\n\\nDaniel Petrie , Jr . ( I ) Eddie Murphy ( II ) Robert D. Wachs ( II )\\n\\nSteven E. de Souza ( III ) Josh Appelbaum ( IV ) André Nemec ( IV )\\n\\nStarring Eddie Murphy Judge Reinhold John Ashton ( l - ll , lV ) Gil\\n\\nHill ( l - lll ) Ronny Cox ( I - II ) Brandon T. Jackson ( Unaired pilot )\\n\\nMusic by Harold Faltermeyer ( I - II ) Nile Rodgers ( III )\\n\\nCinematography Bruce Surtees ( I ) Jeffrey L. Kimball ( II ) Mac Ahlberg\\n\\n( III ) Dante Spinotti ( IV ) Edited by Billy Weber ( I - II )\\n\\nArthur Coburn ( I ) Chris Lebenzon ( II ) Michael Tronick ( II ) Dale\\n\\nBeldin ( III ) Production company Simpson / Bruckheimer ( I - II )\\n\\nEddie Murphy Productions ( I - III ) Distributed by Paramount Pictures\\n\\nRelease date 1984 - 1994 Running time 312 minutes Country United\\n\\nStates Language English Budget $85 million Box office $735.5\\n\\nmillion Beverly Hills Cop is a series of American action comedy films and an\\n\\nunaired television pilot based on characters created by Daniel Petrie , Jr. and\\n\\nDanilo Bach . The films star Eddie Murphy as Axel Foley , a street - smart\\n\\nDetroit cop who travels to Beverly Hills , California to investigate crimes ,\\n\\neven though it is out of his jurisdiction . There , he meets Detective Billy\\n\\nRosewood ( Judge Reinhold ) , Sergeant John Taggart ( John Ashton ) , and\\n\\nLieu\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question:\\n\\ndale carnegie how to win and influence friends pdf\\n\\nAnswer:\\n\\nContext:\\n\\nHow to Win Friends and Influence people - wikipedia How to Win Friends and\\n\\nInfluence people Jump to : navigation , search For the Terrorvision album , see\\n\\nHow to Make Friends and Influence People . How to Win Friends and Influence\\n\\nPeople First edition , 11th printing ( February 1937 ) Author Dale\\n\\nCarnegie Country United States Language English Subject Self -\\n\\nhelp Genre Non-fiction Publisher Simon and Schuster ( 1936 )\\n\\nPublication date October 1936 Media type Print ( hardcover / paperback )\\n\\nPages 291 pp ISBN 1 - 4391 - 6734 - 6 OCLC 40137494 How to Win\\n\\nFriends and Influence People is a self - help book written by Dale Carnegie ,\\n\\npublished in 1936 . Over 30 million copies have been sold world - wide , making\\n\\nit one of the best - selling books of all time . In 2011 , it was number 19 on\\n\\nTime Magazine 's list of the 100 most influential books . In 1934 , Leon\\n\\nShimkin of the publishing firm Simon & Schuster took one of Carnegie 's 14 -\\n\\nweek courses ; afterward , Shimkin persuaded Carnegie to let a stenographer take\\n\\nnotes from the course to be revised for publication . The original book\\n\\ncontained colorful anecdotes and insightful wisdom , and gave instruction in\\n\\nhandling people , `` winning '' friends , bringing people to your way of\\n\\nthinking , being a great leader , and successfully navigating home life .\\n\\nCarnegie combined age - old truisms with the emerging field of psychology to\\n\\npresent a handbook in human relations which was interesting and accessible .\\n\\nEmphasizing using others ' egotistical tendencies to one 's advantage , Carnegie\\n\\nmaintained that success could be found by charm , appreciation , and personality\\n\\n. The book sold exceptionally well from the start , going through 17 editions in\\n\\nits first year alone . In 1981 , a revised edition containing updated language\\n\\nand anecdotes was released . The revised edition reduced the number of sections\\n\\nfrom six to four , eliminating sections on effectiv\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question:\\n\\nthe human tendency to mimic other peoples behavior is an example of\\n\\nAnswer:\\n\\n<P> Mirroring is the behaviour in which one person subconsciously imitates the gesture , speech\\n\\npattern , or attitude of another . Mirroring often occurs in social situations , particularly in the\\n\\ncompany of close friends or family . The concept often affects other individuals ' notions about\\n\\nthe individual that is exhibiting mirroring behaviors , which can lead to the individual building\\n\\nrapport with others . </P>\\n\\nContext:\\n\\nMirroring ( psychology ) - wikipedia Mirroring ( psychology ) This\\n\\narticle needs additional citations for verification . Please help improve this\\n\\narticle by adding citations to reliable sources . Unsourced material may be\\n\\nchallenged and removed . ( August 2015 ) ( Learn how and when to remove this\\n\\ntemplate message ) Mirroring in an argument . Mirroring is the behaviour in\\n\\nwhich one person subconsciously imitates the gesture , speech pattern , or\\n\\nattitude of another . Mirroring often occurs in social situations , particularly\\n\\nin the company of close friends or family . The concept often affects other\\n\\nindividuals ' notions about the individual that is exhibiting mirroring\\n\\nbehaviors , which can lead to the individual building rapport with others .\\n\\nMirroring is the subconscious replication of another person 's nonverbal signals\\n\\n. This concept takes place in everyday interactions , and often goes unnoticed\\n\\nby both the person enacting the mirroring behaviors as well as the individual\\n\\nwho is being mirrored . The activation of mirror neurons takes place within the\\n\\nindividual who begins to mirror another 's movements , and allows them a greater\\n\\nconnection and understanding with the individual who they are mirroring , as\\n\\nwell as allowing the individual who is being mirrored to feel a stronger\\n\\nconnection with the other individual . Mirroring is distinct from conscious\\n\\nimitation under the premise that while the latter is a conscious , typically\\n\\novert effort to copy another person , mirroring is subconsciously done during\\n\\nthe act and often goes unnoticed . The display of mirroring often begins as\\n\\nearly as infancy , as babies begin to mimic individuals around them and\\n\\nestablish connections with particular body movements . The ability to mimic\\n\\nanother person 's actions allows the infant to establish a sense of empathy and\\n\\nthus begin to understand another person 's emotions . The infant continues to\\n\\nestablish connections with other individual 's emotions and subsequent\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question:\\n\\nwho invented the use of electricity during the industrial revolution\\n\\nAnswer:\\n\\nContext:\\n\\nIndustrial Revolution - wikipedia Industrial Revolution Jump to : navigation ,\\n\\nsearch A Roberts loom in a weaving shed in 1835 . Textiles were the leading\\n\\nindustry of the Industrial Revolution and mechanized factories , powered by a\\n\\ncentral water wheel or steam engine , were the new workplace . The Industrial\\n\\nRevolution was the transition to new manufacturing processes in the period from\\n\\nabout 1760 to sometime between 1820 and 1840 . This transition included going\\n\\nfrom hand production methods to machines , new chemical manufacturing and iron\\n\\nproduction processes , the increasing use of steam power , the development of\\n\\nmachine tools and the rise of the factory system . Textiles were the dominant\\n\\nindustry of the Industrial Revolution in terms of employment , value of output\\n\\nand capital invested . The textile industry was also the first to use modern\\n\\nproduction methods . The Industrial Revolution began in Great Britain , and\\n\\nmany of the technological innovations were of British origin . By the mid-18th\\n\\ncentury Britain was the world 's leading commercial nation , controlling a\\n\\nglobal trading empire with colonies in North America and Africa , and with some\\n\\npolitical influence on the Indian subcontinent , through the activities of the\\n\\nEast India Company . The development of trade and the rise of business were\\n\\nmajor causes of the Industrial Revolution . The Industrial Revolution marks a\\n\\nmajor turning point in history ; almost every aspect of daily life was\\n\\ninfluenced in some way . In particular , average income and population began to\\n\\nexhibit unprecedented sustained growth . Some economists say that the major\\n\\nimpact of the Industrial Revolution was that the standard of living for the\\n\\ngeneral population began to increase consistently for the first time in history\\n\\n, although others have said that it did not begin to meaningfully improve until\\n\\nthe late 19th and 20th centuries . GDP per capita was broadly stable before\\n\\nthe Industrial Revolution and the emergence of\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question:\\n\\nhow is the head of the church of england\\n\\nAnswer:\\n\\n<P> The Church of England ( C of E ) is the Established Church of England . The Archbishop of\\n\\nCanterbury is the most senior cleric , although the monarch is the supreme governor . The Church\\n\\nof England is also the mother church of the international Anglican Communion . It traces its\\n\\nhistory to the Christian church recorded as existing in the Roman province of Britain by the third\\n\\ncentury , and to the 6th - century Gregorian mission to Kent led by Augustine of Canterbury .\\n\\n</P>\\n\\nContext:\\n\\nChurch of England - wikipedia Church of England `` C of E '' redirects here .\\n\\nFor other uses , see Council of Europe . Anglican state church of England\\n\\nChurch of England Abbreviation C of E Orientation Anglican\\n\\nPolity Episcopal Supreme Governor Queen Elizabeth II Primate\\n\\nArchbishop Justin Welby Associations Anglican Communion Porvoo Communion\\n\\nRegion England , Wales ( cross-border parishes ) Isle of Man Channel Islands\\n\\nContinental Europe Headquarters Church House , Westminster , England ,\\n\\nUnited Kingdom Separated from Roman Catholic Church ( 1534 )\\n\\nSeparations English Dissenters ( 1534 onwards ) Methodists ( 18th century )\\n\\nPlymouth Brethren ( 1820s ) Free Church of England ( 1844 ) Members 25\\n\\nmillion Official website churchofengland.org Part of a series on\\n\\nAnglicanism Theology ( show ) Christian theology Anglican doctrine\\n\\nThirty - nine Articles Books of Homilies Caroline Divines Lambeth Quadrilateral\\n\\nEpiscopal polity Sacraments Mary Ministry and worship ( show ) Ministry\\n\\nMusic Eucharist King James Version ( Book of Common Prayer ) Liturgical year\\n\\nChurchmanship ( High , Low , Central , Broad ) Monasticism Saints\\n\\nChristianity ( show ) Jesus Christ Paul Christian Church First seven Ecumenical\\n\\nCouncils Background and history ( show ) Celtic Christianity Augustine of\\n\\nCanterbury Bede Medieval cathedral architecture Henry VIII English Reformation\\n\\nThomas Cranmer Dissolution of Monasteries Church of England Edward VI Elizabeth\\n\\nI Parker Hooker James I Charles I Laud Nonjuring schism Anglo - Catholicism\\n\\nOxford Movement Anglican Communion ( show ) Anglican Communion history\\n\\nArchbishop of Canterbury Anglican Communion Primates ' Meetings Lambeth\\n\\nConference Bishops Anglican Consultative Council Ecumenism Ordination of women\\n\\nWindsor Report Continuing Anglicanism ( show ) Anglican realignment\\n\\nBartonville Agreement Congress of St. Louis North American Anglican Conference\\n\\nAnglicanism portal\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content='Question:\\n\\nwho holds the most women\\'s wimbledon titles\\n\\nAnswer:\\n\\n<Table> Wimbledon Ladies \\' Singles Champions <Tr> <Th> Location </Th> <Td> London\\n\\nUnited Kingdom </Td> </Tr> <Tr> <Th> Venue </Th> <Td> AELTC </Td> </Tr> <Tr> <Th>\\n\\nGoverning body </Th> <Td> AELTC / LTA </Td> </Tr> <Tr> <Th> Created </Th> <Td> 1884 (\\n\\nestablished ) Open Era : 1968 ( 51 editions ) </Td> </Tr> <Tr> <Th> Surface </Th> <Td>\\n\\nGrass ( 1884 -- Present ) </Td> </Tr> <Tr> <Th> Prize money </Th> <Td> £ 2,000,000 ( 2016\\n\\n) </Td> </Tr> <Tr> <Th> Trophy </Th> <Td> Venus Rosewater Dish </Td> </Tr> <Tr> <Th>\\n\\nWebsite </Th> <Td> REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html </Td>\\n\\n</Tr> <Tr> <Th colspan=\"2\"> Most titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 7\\n\\n: Dorothea Lambert Chambers ( challenge round ) 8 : Helen Wills Moody ( regular ) </Td> </Tr>\\n\\n<Tr> <Th> Open era </Th> <Td> 9 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\">\\n\\nMost consecutive titles </Th> </Tr> <Tr> <Th> Amateur era </Th> <Td> 3 : Lottie Dod\\n\\nSuzanne Lenglen ( challenge round ) 4 : Helen Wills Moody ( regular ) </Td> </Tr> <Tr> <Th>\\n\\nOpen era </Th> <Td> 6 : Martina Navratilova </Td> </Tr> <Tr> <Th colspan=\"2\"> Current\\n\\nchampion </Th> </Tr> <Tr> <Td colspan=\"2\"> Angelique Kerber ( 1st singles title ) </Td>\\n\\n</Tr> </Table>\\n\\nContext:\\n\\nList of Wimbledon Ladies \\' Singles champions - wikipedia List of Wimbledon\\n\\nLadies \\' Singles champions Wimbledon Ladies \\' Singles Champions Location\\n\\nLondon United Kingdom Venue AELTC Governing body AELTC / LTA\\n\\nCreated 1884 ( established ) Open Era : 1968 ( 51 editions ) Surface\\n\\nGrass ( 1884 -- Present ) Prize money £ 2,000,000 ( 2016 ) Trophy\\n\\nVenus Rosewater Dish Website\\n\\REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.html Most\\n\\ntitles Amateur era 7 : Dorothea Lambert Chambers ( challenge round ) 8 :\\n\\nHelen Wills Moody ( regular ) Open era 9 : Martina Navratilova Most\\n\\nconsecutive titles Amateur era 3 : Lottie Dod Suzanne Lenglen ( challenge\\n\\nround ) 4 : Helen Wills Moody ( regular ) Open era 6 : Martina Navratilova\\n\\nCurrent champion Angelique Kerber ( 1st singles title ) The\\n\\nChampionships , Wimbledon is an annual tennis tournament first contested in 1877\\n\\nand played on outdoor grass courts at the All England Lawn Tennis and Croquet\\n\\nClub ( AELTC ) in the Wimbledon suburb of London , United Kingdom . The Ladies \\'\\n\\nSingles was started in 1884 . Contents 1 History 2 Champions 2.1\\n\\nAmateur Era 2.2 Open Era 3 Statistics 3.1 Multiple champions 3.2\\n\\nChampionships by country 4 See also 5 Notes 6 References 7 External\\n\\nlinks History ( edit ) Wimbledon has historically been played in the last\\n\\nweek of June and the first week of July ( though changed to the first two weeks\\n\\nof July in 2017 ) , and has been chronologically the third of the four Grand\\n\\nSlam tournaments of the tennis season since 1987 . The event was not held from\\n\\n1915 to 1918 because of World War I and again from 1940 to 1945 because of World\\n\\nWar II . The Ladies \\' Singles \\' rules have undergone several changes since the\\n\\nfirst edition . From 1886 until 1921 , the event started with a knockout phase ,\\n\\nthe All Comers \\' Singles , whose winner then faced the defending champion in a\\n\\nchallenge round . The All', metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content=\"Question:\\n\\nhow many goals scored ronaldo in his career\\n\\nAnswer:\\n\\n<P> Cristiano Ronaldo dos Santos Aveiro GOIH ComM ( European Portuguese : ( kitjnu\\n\\nonadu ) ; born 5 February 1985 ) is a Portuguese professional footballer who plays as a forward\\n\\nfor Italian club Juventus and the Portugal national team . Often considered the best player in the\\n\\nworld and regarded by many as one of the greatest players of all time , Ronaldo has a record -\\n\\ntying five Ballon d'Or awards , the most for a European player , and is the first player to win four\\n\\nEuropean Golden Shoes . He has won 26 trophies in his career , including five league titles , five\\n\\nUEFA Champions League titles and one UEFA European Championship . A prolific goalscorer ,\\n\\nRonaldo holds the records for most official goals scored in Europe 's top - five leagues ( 395 ) , the\\n\\nUEFA Champions League ( 120 ) , the UEFA European Championship ( 9 ) , as well as those for\\n\\nmost assists in the UEFA Champions League ( 34 ) and the UEFA European Championship ( 6 ) .\\n\\nHe has scored over 670 senior career goals for club and country . </P>\\n\\nContext:\\n\\nCristiano Ronaldo - wikipedia Cristiano Ronaldo Portuguese footballer For\\n\\nthe Brazilian footballer , see Ronaldo ( Brazilian footballer ) . This name uses\\n\\nPortuguese naming customs . The first or maternal family name is Santos and the\\n\\nsecond or paternal family name is Aveiro . Cristiano Ronaldo Cristiano\\n\\nRonaldo with Portugal at the 2018 FIFA World Cup Full name Cristiano\\n\\nRonaldo dos Santos Aveiro Date of birth ( 1985 - 02 - 05 ) 5 February 1985\\n\\n( age 33 ) Place of birth Funchal , Madeira , Portugal Height 1.85 m\\n\\n( 6 ft 1 in ) Playing position Forward Club information Current\\n\\nteam Juventus Number 7 Youth career 1992 -- 1995 Andorinha\\n\\n1995 -- 1997 Nacional 1997 -- 2002 Sporting CP Senior career *\\n\\nYears Team Apps ( Gls ) 2002 -- 2003 Sporting CP B ( 0 )\\n\\n2002 -- 2003 Sporting CP 25 ( 3 ) 2003 -- 2009 Manchester United\\n\\n196 ( 84 ) 2009 -- 2018 Real Madrid 292 ( 311 ) 2018 --\\n\\nJuventus ( 0 ) National team Portugal U15 9 ( 7 ) 2001 --\\n\\n2002 Portugal U17 7 ( 5 ) 2003 Portugal U20 5 ( 1 ) 2002 --\\n\\n2003 Portugal U21 10 ( 3 ) Portugal U23 ( 2 ) 2003 --\\n\\nPortugal 154 ( 85 ) Honours ( show ) Men 's football\\n\\nRepresenting Portugal UEFA European Championship 2004 Portugal\\n\\n2012 Poland & Ukraine 2016 France FIFA Confederations Cup\\n\\n2017 Russia * Senior club appearances and goals counted for the\\n\\ndomestic league only and correct as of 25 August 2018 National team caps and\\n\\ngoals correct as of 30 June 2018 This article is part of a series\\n\\nabout Cristiano Ronaldo Portuguese professional footballer\\n\\nInternational goals Career achievements Comparisons to Lionel Messi\\n\\nNamesakes Cristiano Ronaldo Campus Futebol Cristiano Ronaldo International\\n\\nAirport Galaxy CR7 Museu CR7 Films Cristiano Ronaldo : The World at\\n\\nHis Feet Ronaldo\", metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the orange stuff on my sushi\\n\\nAnswer:\\n\\n<P> The eggs are small , ranging from 0.5 to 0.8 mm . For comparison , tobiko is larger than\\n\\nmasago ( capelin roe ) , but smaller than ikura ( salmon roe ) . Natural tobiko has a red - orange\\n\\ncolor , a mild smoky or salty taste , and a crunchy texture . </P>\\n\\nContext:\\n\\nTobiko - wikipedia Tobiko Jump to : navigation , search This article\\n\\nneeds additional citations for verification . Please help improve this article\\n\\nby adding citations to reliable sources . Unsourced material may be challenged\\n\\nand removed . ( February 2013 ) ( Learn how and when to remove this template\\n\\nmessage ) Tobiko in varying colors , served as sushi Tobiko ( ) is the\\n\\nJapanese word for flying fish roe . It is most widely known for its use in\\n\\ncreating certain types of sushi . The eggs are small , ranging from 0.5 to 0.8\\n\\nmm . For comparison , tobiko is larger than masago ( capelin roe ) , but smaller\\n\\nthan ikura ( salmon roe ) . Natural tobiko has a red - orange color , a mild\\n\\nsmoky or salty taste , and a crunchy texture . Tobiko , shown in its natural\\n\\ncolor , topping grilled Albacore tuna Sometimes tobiko is colored to change its\\n\\nappearance , other natural ingredients are used to accomplish the change , such\\n\\nas squid ink to make it black , yuzu to make it pale orange ( almost yellow ) ,\\n\\nor even wasabi to make it green and spicy . Sometimes a serving of tobiko\\n\\ncontains several pieces , each having a different color . When prepared as\\n\\nsashimi , it may be presented on avocado halves or wedges . Tobiko is used in\\n\\nthe creation of many other Japanese dishes . Often , tobiko is used as an\\n\\ningredient in California rolls . Frequently , masago ( capelin or smelt roe )\\n\\nis substituted for tobiko , due to its similar appearance and flavor . The\\n\\nsmaller size of the individual eggs is apparent to the experienced diner ,\\n\\nhowever . References ( edit ) Wikimedia Commons has media related to\\n\\nTobiko . Jump up ^ `` Tobiko vs Masago Difference '' . Expert answer\\n\\nQuestion. 2016 - 11 - 16 . Retrieved 2016 - 11 - 16 . Jump up ^ Food Republic\\n\\nhttp://REMOVED_SECRET/2013/04/19/what-tobiko-and-whats-different-colors .\\n\\nRetrieved 18 October 2014 . Missing or empty title = ( help ) Sushi\\n\\nHistory of sushi List of sushi and sashimi ingr\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question:\\n\\nwho was the first president to get his picture taken\\n\\nAnswer:\\n\\nContext:\\n\\nList of United States Presidential Firsts - wikipedia List of United States\\n\\nPresidential Firsts Jump to : navigation , search This article needs\\n\\nadditional citations for verification . Please help improve this article by\\n\\nadding citations to reliable sources . Unsourced material may be challenged and\\n\\nremoved . ( January 2017 ) ( Learn how and when to remove this template message\\n\\n) This list lists achievements and distinctions of various Presidents of the\\n\\nUnited States . It includes distinctions achieved in their earlier life and\\n\\npost-presidencies . Due to some confusion surrounding sovereignty of nations\\n\\nduring presidential visits , only nations that were independent , sovereign , or\\n\\nrecognized by the United States during the presidency are listed here as a\\n\\nprecedent . Contents ( hide ) 1 George Washington ( 1789 - 1797 ) 2 John\\n\\nAdams ( 1797 - 1801 ) 3 Thomas Jefferson ( 1801 - 1809 ) 4 James Madison (\\n\\n1809 - 1817 ) 5 James Monroe ( 1817 - 1825 ) 6 John Quincy Adams ( 1825 -\\n\\n1829 ) 7 Andrew Jackson ( 1829 - 1837 ) 8 Martin Van Buren ( 1837 - 1841 )\\n\\n9 William Henry Harrison ( 1841 ) 10 John Tyler ( 1841 - 1845 ) 11 James K.\\n\\nPolk ( 1845 - 1849 ) 12 Zachary Taylor ( 1849 - 1850 ) 13 Millard Fillmore (\\n\\n1850 - 1853 ) 14 Franklin Pierce ( 1853 - 1857 ) 15 James Buchanan ( 1857 -\\n\\n1861 ) 16 Abraham Lincoln ( 1861 - 1865 ) 17 Andrew Johnson ( 1865 - 1869 )\\n\\n18 Ulysses S. Grant ( 1869 - 1877 ) 19 Rutherford B. Hayes ( 1877 - 1881 )\\n\\n20 James A. Garfield ( 1881 ) 21 Chester A. Arthur ( 1881 - 1885 ) 22 Grover\\n\\nCleveland ( 1885 - 1889 ; 1893 - 1897 ) 23 Benjamin Harrison ( 1889 - 1893 )\\n\\n24 William McKinley ( 1897 - 1901 ) 25 Theodore Roosevelt ( 1901 - 1909 ) 26\\n\\nWilliam Howard Taft ( 1909 - 1913 ) 27 Woodrow Wilson ( 1913 - 1921 ) 28\\n\\nWarren G. Harding ( 1921 - 1923 ) 29 Calvin Coolidge ( 1923 - 1929 ) 30\\n\\nHerbert Hoover ( 1929 - 1933 ) 31 Franklin D. Roosevelt ( 1933 - 1945 ) 32\\n\\nHarry S. Truman ( 1945 - 1953 ) 3', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question:\\n\\nwhat is the moral of the ant and the grasshopper\\n\\nAnswer:\\n\\n<P> The story has been used to teach the virtues of hard work and the perils of improvidence .\\n\\nSome versions state a moral at the end along the lines of `` Idleness brings want '' , `` To work\\n\\ntoday is to eat tomorrow '' , `` Beware of winter before it comes '' . In La Fontaine 's Fables no\\n\\nfinal judgment is made , although it has been argued that the author is there making sly fun of\\n\\nhis own notoriously improvident ways . But the point of view in most retellings of the fable is\\n\\nsupportive of the ant . It is also influenced by the commendation in the biblical Book of Proverbs ,\\n\\nwhich mentions the ant twice . The first proverb admonishes , `` Go to the ant , you sluggard !\\n\\nConsider her ways and be wise , which having no captain , overseer or ruler , provides her\\n\\nsupplies in the summer , and gathers her food in the harvest '' ( 6.6 - 9 ) . Later , in a parallel\\n\\nsaying of Agur , the insects figure among the ' four things that are little upon the earth but they\\n\\nare exceeding wise . The ants are a people not strong , yet they provide their food in the summer\\n\\n. ' ( 30.24 - 5 ) </P>\\n\\nContext:\\n\\nThe ant and the grasshopper - wikipedia The ant and the grasshopper Jump to :\\n\\nnavigation , search Coloured print of La Fontaine 's fable by Jean - Baptiste\\n\\nOudry The Ant and the Grasshopper , alternatively titled The Grasshopper and\\n\\nthe Ant ( or Ants ) , is one of Aesop 's Fables , numbered 373 in the Perry\\n\\nIndex . The fable describes how a hungry grasshopper begs for food from an ant\\n\\nwhen winter comes and is refused . The situation sums up moral lessons about the\\n\\nvirtues of hard work and planning for the future . Even in Classical times ,\\n\\nhowever , the advice was mistrusted and an alternative story represented the ant\\n\\n's industry as mean and self - serving . Jean de la Fontaine 's delicately\\n\\nironical retelling in French later widened the debate to cover the themes of\\n\\ncompassion and charity . Since the 18th century the grasshopper has been seen as\\n\\nthe type of the artist and the question of the place of culture in society has\\n\\nalso been included . Argument over the fable 's ambivalent meaning has generally\\n\\nbeen conducted through adaptation or reinterpretation of the fable in literature\\n\\n, arts and music . Contents ( hide ) 1 Fable and counter-fable 2 In art\\n\\n3 Later adaptations 4 Musical settings 5 Film and television treatments 6\\n\\nMoral and artistic debate 7 See also 8 References 9 External links\\n\\nFable and counter-fable ( edit ) The fable concerns a grasshopper ( in the\\n\\noriginal , a cicada ) that has spent the summer singing while the ant ( or ants\\n\\nin some versions ) worked to store up food for winter . When that season arrives\\n\\n, the grasshopper finds itself dying of hunger and begs the ant for food .\\n\\nHowever , the ant rebukes its idleness and tells it to dance the winter away now\\n\\n. Versions of the fable are found in the verse collections of Babrius ( 140 )\\n\\nand Avianus ( 34 ) , and in several prose collections including those attributed\\n\\nto Syntipas and Aphthonius of Antioch . The fable 's Greek original cicada is\\n\\nkept in the Latin and Romance\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content=\"Question:\\n\\nwhich city has the highest hiv rate in south africa\\n\\nAnswer:\\n\\nContext:\\n\\nHIV / AIDS in South Africa - Wikipedia HIV / AIDS in South Africa This\\n\\narticle needs to be updated . Please update this article to reflect recent\\n\\nevents or newly available information . ( July 2018 ) Estimated HIV\\n\\nprevalence among adults aged 15 - 49 by country in 2007 HIV / AIDS is the most\\n\\nserious health concern in South Africa . The country has the fourth - highest\\n\\nadult HIV prevalence rate in the world , according to the 2016 United Nations\\n\\nstatistics . According to a UNAids dataset sourced from the World Bank , in\\n\\n2016 the HIV prevalence rate for adults aged 15 to 49 was 27 % in Swaziland , 25\\n\\n% in Lesotho , 25 % in Botswana and 19 % in South Africa . Contents 1\\n\\nUnderstanding HIV prevalence 2 Latest data on HIV prevalence in South Africa\\n\\n3 Other statistics 3.1 By race 3.2 By gender 3.3 By pregnant women 3.4\\n\\nBy age 3.5 By province 4 Awareness campaigns 5 Co-infection with\\n\\ntuberculosis 6 History 6.1 1990 6.2 1993 6.3 1995 6.4 1996 6.5 1997\\n\\n6.6 1999 6.7 2000 6.8 2001 6.9 2002 7 Demographics 8 Aids denialism\\n\\nunder Thabo Mbeki 8.1 2000 8.2 2001 8.3 2003 8.4 2006 8.5 2007 9\\n\\nRole of the media in South Africa 's epidemic 10 See also 11 References 12\\n\\nFurther reading 13 External links Understanding HIV prevalence ( edit )\\n\\nHIV prevalence does not indicate that a country has an AIDS crisis , as HIV and\\n\\nAIDS are separate conditions . HIV prevalence , instead , indicates that people\\n\\nremain alive , despite the infection . South Africa has the largest HIV\\n\\ntreatment programme in the world . With the correct medication , HIV is a\\n\\nmanageable chronic condition , like diabetes or hypertension . A population with\\n\\na larger proportion of diabetics , means more people are receiving treatment for\\n\\nthe condition . Hence , a population with a larger proportion of HIV - positive\\n\\npeople , means more people are receiving anti-retroviral treatment . World\\n\\nBank Open Data explains the data it publishes on HI\", metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question:\\n\\nnow that's what i call music 17 songs\\n\\nAnswer:\\n\\nContext:\\n\\nNow That 's What I Call Music 17 ( UK series ) - wikipedia Now That 's What I\\n\\nCall Music 17 ( UK series ) Jump to : navigation , search This article\\n\\ndoes not cite any sources . Please help improve this article by adding citations\\n\\nto reliable sources . Unsourced material may be challenged and removed . (\\n\\nDecember 2009 ) ( Learn how and when to remove this template message ) This\\n\\narticle describes the 17th album in the UK Now ! series . It should not be\\n\\nconfused with identically - numbered albums from other Now ! series . For more\\n\\ninformation , see Now That 's What I Call Music ! 17 and Now That 's What I Call\\n\\nMusic ! discography . Now That 's What I Call Music 17 Compilation\\n\\nalbum by various artists Released 23 April 1990 Genre Pop Length\\n\\n2 : 05 : 00 Label Virgin / EMI / Polygram Series chronology Now\\n\\nThat 's What I Call Music 16 ( 1989 ) Now That 's What I Call Music 17 ( 1990\\n\\n) Now ! That 's What I Call Music 18 ( 1990 ) Now That 's What I Call\\n\\nMusic 17 or Now 17 is the 17th edition of the Now ! series in the United Kingdom\\n\\nand was released in April 1990 on vinyl , audio cassette , compact disc and VHS\\n\\n. Track listing ( edit ) CD / record / tape 1 No . Title Artist (\\n\\ns ) Length 1 . `` Blue Savannah '' Erasure 2 . `` Better World\\n\\n'' Rebel MC 3 . `` Opposites Attract '' Paula Abdul 4 . ``\\n\\nDub Be Good to Me '' Beats International 5 . `` Kingston Town ''\\n\\nUB40 6 . `` Strawberry Fields Forever '' Candy Flip 7 . `` I\\n\\nDo n't Wanna Lose You '' Tina Turner 8 . `` I Wish It Would Rain Down\\n\\n'' Phil Collins 9 . `` Step On '' Happy Mondays 10 . ``\\n\\nLoaded '' Primal Scream 11 . `` Enjoy the Silence '' Depeche Mode\\n\\n12 . `` Real Real Real '' Jesus Jones 13 . `` This Is How It Feels\\n\\n'' Inspiral Carpets 14 . `` Shine On '' The House of Love 15 .\\n\\n`` From Out of Nowhere ''\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question:\\n\\nwhen does model code of conduct come into force\\n\\nAnswer:\\n\\n<P> Election Commission of India 's Model Code of Conduct is a set of guidelines issued by the\\n\\nElection Commission of India for conduct of political parties and candidates during elections\\n\\nmainly with respect to speeches , polling day , polling booths , election manifestos , processions\\n\\nand general conduct . These set of norms has been evolved with the consensus of political parties\\n\\nwho have consented to abide by the principles embodied in the said code in its letter and spirit.\\n\\nThe Model Code of Conduct comes into force immediately on announcement of the election\\n\\nschedule by the commission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example , politicians should not\\n\\nmake hate speeches , putting one community against another or make promises about new\\n\\nprojects that may sway a voter . </P>\\n\\nContext:\\n\\nElection Commission of India 's Model code of Conduct - wikipedia Election\\n\\nCommission of India 's Model code of Conduct Jump to : navigation , search\\n\\nThis article needs more links to other articles to help integrate it into the\\n\\nencyclopedia . Please help improve this article by adding links that are\\n\\nrelevant to the context within the existing text . ( April 2014 ) ( Learn how\\n\\nand when to remove this template message ) Election Commission of India 's\\n\\nModel Code of Conduct is a set of guidelines issued by the Election Commission\\n\\nof India for conduct of political parties and candidates during elections mainly\\n\\nwith respect to speeches , polling day , polling booths , election manifestos ,\\n\\nprocessions and general conduct . These set of norms has been evolved with the\\n\\nconsensus of political parties who have consented to abide by the principles\\n\\nembodied in the said code in its letter and spirit. The Model Code of Conduct\\n\\ncomes into force immediately on announcement of the election schedule by the\\n\\ncommission for the need of ensuring free and fair elections . Much of it is\\n\\ndesigned to avert communal clashes and corrupt practices . For example ,\\n\\npoliticians should not make hate speeches , putting one community against\\n\\nanother or make promises about new projects that may sway a voter . For the\\n\\n2014 general election the code came into force on 5 March 2014 when the\\n\\nCommission announced the dates and remains in force till the end of the\\n\\nelectoral process . `` The Model Code of Conduct is crucial to make sure a\\n\\nlevel playing field among various contenders in the poll fray , '' said the\\n\\nChief Election Commissioner V.S. Sampath at the press conference . Main points\\n\\n( edit ) The main points of the code are : Government bodies are not to\\n\\nparticipate in any new recruitment process during the electoral process . The\\n\\ncontesting candidates and the campaigners must respect the home life of their\\n\\nrivals and should not disturb them by holding road shows or demonstrations\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content=\"Question:\\n\\nwhere is the greatest royal rumble taking place\\n\\nAnswer:\\n\\n<P> Greatest Royal Rumble was a professional wrestling pay - per - view event and WWE\\n\\nNetwork event promoted by WWE for their Raw and SmackDown brands . The event was held on\\n\\nApril 27 , 2018 at the King Abdullah Sports City 's King Abdullah International Stadium in Jeddah ,\\n\\nSaudi Arabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in the United\\n\\nStates at noon EDT , with a pre-show starting at 11 a.m. EDT . At the event , all men 's main\\n\\nroster championships were defended , in addition to a 50 - man Royal Rumble match . </P>\\n\\nContext:\\n\\nWWE Greatest Royal Rumble - Wikipedia WWE Greatest Royal Rumble Jump to :\\n\\nnavigation , search Greatest Royal Rumble Promotional poster featuring\\n\\nvarious WWE wrestlers Theme song ( s ) `` When Legends Rise '' by Godsmack\\n\\nInformation Promotion WWE Brand ( s ) Raw SmackDown Sponsor ( s\\n\\n) Saudi General Sports Authority Date April 27 , 2018 Attendance\\n\\n60,000 Venue King Abdullah International Stadium City Jeddah , Saudi\\n\\nArabia WWE Network event chronology WrestleMania 34 Greatest Royal\\n\\nRumble Backlash ( 2018 ) Greatest Royal Rumble was a professional\\n\\nwrestling pay - per - view event and WWE Network event promoted by WWE for their\\n\\nRaw and SmackDown brands . The event was held on April 27 , 2018 at the King\\n\\nAbdullah Sports City 's King Abdullah International Stadium in Jeddah , Saudi\\n\\nArabia . The event was scheduled for 7 : 00 p.m. local time . It aired live in\\n\\nthe United States at noon EDT , with a pre-show starting at 11 a.m. EDT . At the\\n\\nevent , all men 's main roster championships were defended , in addition to a 50\\n\\nman Royal Rumble match . The card featured ten matches . In the main event ,\\n\\nBraun Strowman won the titular Greatest Royal Rumble match to become the\\n\\ninaugural Greatest Royal Rumble Champion . In the penultimate match , Brock\\n\\nLesnar retained the Universal Championship in a steel cage match against Roman\\n\\nReigns . On the undercard , the WWE Championship match between AJ Styles and\\n\\nShinsuke Nakamura resulted in a double countout , The Undertaker defeated Rusev\\n\\nin a casket match , and John Cena defeated Triple H in the opening match .\\n\\nContents ( hide ) 1 Production 1.1 Background 1.2 Storylines 2 Event\\n\\n2.1 Preliminary matches 2.2 Main event 3 Controversy 4 Results 4.1 Tag\\n\\nTeam Eliminator bracket 4.2 Greatest Royal Rumble match entrances and\\n\\neliminations 5 WWE Greatest Royal Rumble Championship 5.1 History 5.2\\n\\nChampionship belt design 5.3 Reigns 6\", metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question:\\n\\nwho died from the band faith no more\\n\\nAnswer:\\n\\n<P> Former Faith No More singer Chuck Mosley died on November 9 , 2017 , due to `` the\\n\\ndisease of addiction . '' He was 57 years old . </P>\\n\\nContext:\\n\\nFaith No More - Wikipedia Faith No More Jump to : navigation , search Faith\\n\\nNo More Faith No More performing in Portugal in 2009 Background\\n\\ninformation Also known as Faith No Man Sharp Young Men Origin\\n\\nSan Francisco , California , United States Genres Alternative metal\\n\\nfunk metal experimental rock Years active 1979 -- 1998 2009 --\\n\\npresent Labels Slash London Mordam Reclamation ! Ipecac\\n\\nAssociated acts Mr. Bungle Pop - O - Pies Website fnm.com\\n\\nMembers Mike Bordin Roddy Bottum Billy Gould Mike Patton Jon Hudson\\n\\nPast members List of Faith No More band members Faith No More ( sometimes\\n\\nabbreviated as FNM ) is an American rock band from San Francisco , California ,\\n\\nformed in 1979 . Before settling on their current name in 1982 , the band\\n\\nperformed under the names Sharp Young Men and later Faith No Man . Bassist Billy\\n\\nGould and drummer Mike Bordin are the longest remaining members of the band ,\\n\\nhaving been involved with Faith No More since its inception . The band underwent\\n\\nseveral lineup changes early in their career , along with some major changes\\n\\nlater on . The current lineup of Faith No More consists of Gould , Bordin ,\\n\\nkeyboardist / rhythm guitarist Roddy Bottum , lead guitarist Jon Hudson and\\n\\nvocalist / lyricist Mike Patton . After releasing six studio albums ,\\n\\nincluding their best - selling records The Real Thing ( 1989 ) and Angel Dust (\\n\\n1992 ) , Faith No More officially announced their breakup on April 20 , 1998 .\\n\\nThey have since reunited , embarked on The Second Coming Tour from 2009 to 2012\\n\\n, and released their seventh studio album , Sol Invictus , in May 2015 .\\n\\nContents ( hide ) 1 History 1.1 Early days ( 1979 -- 1984 ) 1.2 We Care a\\n\\nLot and Introduce Yourself ( 1985 -- 1988 ) 1.3 Mike Patton joins and The Real\\n\\nThing ( 1989 -- 1991 ) 1.4 Angel Dust ( 1992 -- 1994 ) 1.5 King for a Day\\n\\n... , Album of the Year and break - up ( 1995 -- 1998 ) 1.6 R\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content=\"Question:\\n\\nwhat is sauce for the goose is sauce for the gander examples\\n\\nAnswer:\\n\\nContext:\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander - Wikipedia\\n\\nWikipedia : sauce for the goose is ( not ) sauce for the gander This page\\n\\nis an essay . It contains the advice or opinions of one or more Wikipedia\\n\\ncontributors . This page is not one of Wikipedia 's policies or guidelines , as\\n\\nit has not been thoroughly vetted by the community . Some essays represent\\n\\nwidespread norms ; others only represent minority viewpoints . Shortcuts WP\\n\\n: SAUCE WP : GOOSE WP : GANDER This page in a nutshell : This phrase\\n\\nis employed to expose holding forth a `` double standard . '' If some kind of\\n\\nbehavior is wrong , it 's probably wrong for both sides , not just one . Do n't\\n\\ndo it yourself either . There 's an old saying , `` What is sauce for the\\n\\ngoose is sauce for the gander . '' This meshes well with the Golden Rule , or\\n\\nethic of reciprocity , which is a key moral principle in many religions and\\n\\nphilosophies , and is often stated as `` Do unto others as you wish to be done\\n\\nfor you '' , or conversely , `` Do n't do unto others what you would not wish to\\n\\nbe done to you . '' Tasty sauces to enjoy on your stir - fried wikipedia . But\\n\\nare they reliable sauces ? Look up sauce for the goose in Wiktionary , the\\n\\nfree dictionary . Unfortunately , when the infighting here in Wikipedia gets\\n\\nheated , participants often forget this principle and do unto their opponents\\n\\nthings that would not be fair to be done unto them , and sometimes add insult to\\n\\ninjury by crying `` fowl '' if their opponents do in fact raise similar\\n\\nobjections to their own actions ( and those of their friends ) to the ones they\\n\\nraised against the opponents in the first place . These `` wars '' can easily\\n\\nturn both parties into hypocrites . Some of the sorts of things that violate\\n\\nthis principle include : Trying to squelch or discredit an opposing viewpoint\\n\\nby associating it with a banned editor who espoused something similar , when in\\n\\nfact some of your own viewpoints a\", metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content=\"Question:\\n\\nwho was the gospel of john written to\\n\\nAnswer:\\n\\nContext:\\n\\nGospel of John - wikipedia Gospel of John Books of the New Testament\\n\\nGospels Matthew Mark Luke John Acts Acts of the Apostles\\n\\nEpistles Romans 1 Corinthians 2 Corinthians Galatians Ephesians Philippians\\n\\nColossians 1 Thessalonians 2 Thessalonians 1 Timothy 2 Timothy Titus Philemon\\n\\nHebrews James 1 Peter 2 Peter 1 John 2 John 3 John Jude Apocalypse\\n\\nRevelation New Testament manuscripts This article is about\\n\\nthe book in the New Testament . For the film , see The Gospel of John ( film ) .\\n\\nNot to be confused with First Epistle of John . Part of a series of articles\\n\\non John in the Bible Johannine literature Gospel Epistles\\n\\nFirst Second Third Revelation Events Authorship Apostle\\n\\nBeloved disciple Evangelist Patmos Presbyter Related literature\\n\\nApocryphon Acts Signs Gospel See also Johannine Christianity\\n\\nLogos Holy Spirit in Johannine literature John 's vision of the Son of Man\\n\\nNew Testament people named John The Gospel According to John\\n\\nis the fourth of the canonical gospels . The work is anonymous , although it\\n\\nidentifies an unnamed `` disciple whom Jesus loved '' as the source of its\\n\\ntraditions . It is closely related in style and content to the three Johannine\\n\\nepistles , and most scholars treat the four books , along with the Book of\\n\\nRevelation , as a single corpus of Johannine literature , albeit not from the\\n\\nsame author . C.K. Barrett , and later Raymond E. Brown , suggested that a\\n\\ntradition developed around the `` Johannine Community '' , and that this\\n\\ntradition gave rise to the gospel . The discovery of a large number of papyrus\\n\\nfragments of manuscripts with Johannine themes has led more scholars to\\n\\nrecognize that the texts were among the most influential in the early Church .\\n\\nThe discourses contained in this gospel seem to be concerned with issues of the\\n\\nchurch -- synagogue debate at the time of composition . It is no\", metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content='Question:\\n\\nfor an asset to be considered money it must be\\n\\nAnswer:\\n\\nContext:\\n\\nAsset - wikipedia Asset This article is about the finance definition . For\\n\\nother uses , see Asset ( disambiguation ) . Part of a series on\\n\\nAccounting Historical cost Constant purchasing power Management\\n\\nTax Major types ( show ) Audit Budget Cost Forensic Financial\\n\\nFund Governmental Management Social Tax Key concepts ( show )\\n\\nAccounting period Accrual Constant purchasing power Economic entity Fair\\n\\nvalue Going concern Historical cost Matching principle Materiality\\n\\nRevenue recognition Unit of account Selected accounts ( show ) Assets\\n\\nCash Cost of goods sold Depreciation / Amortization Equity Expenses\\n\\nGoodwill Liabilities Profit Revenue Accounting standards ( show )\\n\\nGenerally - accepted principles Generally - accepted auditing standards\\n\\nConvergence International Financial Reporting Standards International\\n\\nStandards on Auditing Management Accounting Principles Financial\\n\\nstatements ( show ) Annual report Balance sheet Cash - flow Equity\\n\\nIncome Management discussion Notes to the financial statements\\n\\nBookkeeping ( show ) Bank reconciliation Debits and credits Double - entry\\n\\nsystem FIFO and LIFO Journal Ledger / General ledger T accounts Trial\\n\\nbalance Auditing ( show ) Financial Internal Firms Report\\n\\nPeople and organizations ( show ) Accountants Accounting organizations\\n\\nLuca Pacioli Development ( show ) History Research Positive\\n\\naccounting Sarbanes -- Oxley Act Business portal In\\n\\nfinancial accounting , an asset is an economic resource . Anything tangible or\\n\\nintangible that can be owned or controlled to produce value and that is held by\\n\\na company to produce positive economic value is an asset . Simply stated ,\\n\\nassets represent value of ownership that can be converted into cash ( although\\n\\ncash itself is also considered an asset ) . The balance sheet of a firm\\n\\nrecords the monetary value o', metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content='Question:\\n\\nhow many district in punjab and also write its name\\n\\nAnswer:\\n\\nContext:\\n\\nPunjab , India - Wikipedia Punjab , India This article is about a state of\\n\\nIndia . For a geographical region , see Punjab . For other uses of the name ,\\n\\nsee Punjab ( disambiguation ) . State in India Punjab State The\\n\\nonly state in India with a majority Sikh population , Punjab contains the Golden\\n\\nTemple , amongst the most important sites in Sikhism Seal Location\\n\\nof Punjab in India Coordinates ( Chandigarh ) : 30 ° 47 N 75 ° 50 E\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/\\n\\n30.79\\n\\n;\\n\\n75.84\\n\\nCoordinates\\n\\n:\\n\\n30\\n\\n°\\n\\n47\\n\\nN 75\\n\\n°\\n\\n50\\n\\n/\\n\\n30.79\\n\\n°\\n\\nN\\n\\n75.84\\n\\n°\\n\\n/ 30.79 ; 75.84 Country India Capital\\n\\nChandigarh Largest city Ludhiana Districts 22 Government\\n\\nGovernor VP Singh Badnore Chief Minister Captain Amarinder Singh ( INC )\\n\\nE\\n\\nE\\n\\nE\\n\\nLegislature Unicameral ( 117 seats ) Parliamentary constituency 13\\n\\nHigh Court Punjab and Haryana High Court Area Total 50,362 km (\\n\\n19,445 sq mi ) Area rank 20th Highest elevation 551 m ( 1,808 ft )\\n\\nLowest elevation 150 m ( 490 ft ) Population ( 2011 ) Total\\n\\n27,704,236 Rank 16th Density 550 / km ( 1,400 / sq mi ) Demonym\\n\\n( s ) Punjabi GDP ( 2017 -- 18 ) Total 4.65 lakh crore ( US $69\\n\\nbillion ) Per capita 142,958 ( US $2,100 ) Time zone IST ( UTC +\\n\\n05 : 30 ) ISO 3166 code IN - PB HDI 0.6614 ( medium ) HDI rank\\n\\n5th ( 2015 ) Official language Punjabi Website REMOVED_SECRET ^\\n\\nJoint Capital with Haryana . Common for Punjab , Haryana and Chandigarh .\\n\\nSymbols of Punjab Emblem Lion Capital of Ashoka with Wheat stem ( above )\\n\\nand Crossed Swords ( below ) Language Punjabi Dance Bhangra , Giddha\\n\\nAnimal Blackbuck Bird Baaz ( Accipiter gentilis ) Punjab ( /\\n\\npndb / ( listen ) ) is a state in northern India . Forming part of the\\n\\nlarger Punjab region , the state is bordered by the Indian states of Jammu and\\n\\nKashmir to the north , Himachal Pradesh to the east', metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 190.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to processed_pdfs.csv\n",
      "Generating questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "Generating questions:   0%|          | 0/7 [00:00<?, ?it/s]/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1282: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n",
      "Generating questions: 100%|██████████| 7/7 [17:48<00:00, 152.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated questions saved to generated_questions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Updated RAG System Preprocessing Script\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from REMOVED_SECRET import Dataset, DataLoader\n",
    "from RAG_UTILS import DocumentProcessor, LangchainDocument\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "PDF_FOLDER_PATH = \"local_database\"\n",
    "CSV_PATH = \"processed_pdfs.csv\"\n",
    "QUESTIONS_PATH = \"generated_questions.csv\"\n",
    "NUM_QUESTIONS = 1000  # Total number of questions to generate\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.documents[idx]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "def convert_pdfs_to_csv(pdf_folder_path: str, output_csv_path: str):\n",
    "    doc_processor = DocumentProcessor(EMBEDDING_MODEL_NAME)\n",
    "    raw_documents = doc_processor.load_pdfs_from_folder(pdf_folder_path)\n",
    "    processed_documents = doc_processor.split_documents(raw_documents)\n",
    "    \n",
    "    data = []\n",
    "    for doc in processed_documents:\n",
    "        data.append({\n",
    "            \"content\": doc.page_content,\n",
    "            \"source\": REMOVED_SECRET(\"source\", \"\"),\n",
    "            \"page\": REMOVED_SECRET(\"page\", \"\")\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"CSV file saved to {output_csv_path}\")\n",
    "\n",
    "def load_from_csv(csv_path: str) -> List[LangchainDocument]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return [\n",
    "        LangchainDocument(page_content=row['content'], metadata={\"source\": row['source'], \"page\": row['page']})\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "def generate_question(context: str, question_generator) -> str:\n",
    "    # Generate a question based on the context\n",
    "    question = question_generator(f\"Generate a question based on this text: {context}\", max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "    return question.strip()\n",
    "\n",
    "def generate_questions(dataloader: DataLoader, num_questions: int) -> List[Tuple[str, str]]:\n",
    "    question_generator = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\", device=0 if REMOVED_SECRET() else -1)\n",
    "    questions_and_contexts = []\n",
    "    for batch in tqdm(dataloader, desc=\"Generating questions\", total=min(len(dataloader), num_questions // BATCH_SIZE + 1)):\n",
    "        for doc in batch:\n",
    "            # Split the document content into sentences\n",
    "            sentences = sent_tokenize(doc.page_content)\n",
    "            \n",
    "            # Select a random sentence as context if the document is too long\n",
    "            if len(sentences) > 3:\n",
    "                context = ' '.join(sentences[:3])  # Use first 3 sentences as context\n",
    "            else:\n",
    "                context = doc.page_content\n",
    "            \n",
    "            # Generate a question based on the context\n",
    "            question = generate_question(context, question_generator)\n",
    "            \n",
    "            questions_and_contexts.append((question, context))\n",
    "            \n",
    "            if len(questions_and_contexts) >= num_questions:\n",
    "                return questions_and_contexts\n",
    "    \n",
    "    return questions_and_contexts\n",
    "\n",
    "def main():\n",
    "    # Convert PDFs to CSV\n",
    "    print(\"Converting PDFs to CSV...\")\n",
    "    convert_pdfs_to_csv(PDF_FOLDER_PATH, CSV_PATH)\n",
    "\n",
    "    # Load processed documents\n",
    "    processed_documents = load_from_csv(CSV_PATH)\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    document_dataset = DocumentDataset(processed_documents)\n",
    "    document_dataloader = DataLoader(document_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    # Generate questions\n",
    "    print(\"Generating questions...\")\n",
    "    questions_and_contexts = generate_questions(document_dataloader, NUM_QUESTIONS)\n",
    "\n",
    "    # Save questions to CSV\n",
    "    questions_df = pd.DataFrame(questions_and_contexts, columns=['question', 'context'])\n",
    "    questions_df.to_csv(QUESTIONS_PATH, index=False, quoting=1)  # quoting=1 ensures that all fields are quoted\n",
    "    print(f\"Generated questions saved to {QUESTIONS_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nnew stuff down here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/obb/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/obb/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "Loading PDFs:   0%|          | 0/30 [00:00<?, ?it/s]2024-09-20 13:52:51,463 - INFO - pikepdf C++ to Python logger bridge initialized\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:02<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content='Question: fish appeared in the fossil record during the\\n\\nAnswer: wiki/Cambrian_explosion\" title=\"Cambrian explosion\">Cambrian explosion. It was d\\n\\nContext:\\n\\nution of fish began about 530 million years ago during the Cambrian explosion. It was during this time that the early chordates developed the skull and the vertebral column, leading to the first craniates and vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which includes the extant hagfish, and this group may have split early on from other agnathans. The first\\n\\nFull Document (Truncated):\\n\\nEvolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa li{background:#fff;border:1px city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > 10px solid rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\n0\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_28.pdf'}), Document(page_content=\"Question: when does grey's anatomy season 14 premiere\\n\\nAnswer: eptember 28, 2017<\\n\\nContext:\\n\\nGrey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti Country of origin United States No. of episodes 12 Release Original network ABC Original release September 28, 2017 (2017-09-28) – present Season chronology ‹ Previous Season 13 List of Grey's Anatomy episodes The\\n\\nFull Document (Truncated):\\n\\nGrey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none...\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_13.pdf'}), Document(page_content='Question: who established the peoples republic of china in 1949\\n\\nAnswer: men\" title\\n\\nContext:\\n\\n> details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People\\'s Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties. Con\\n\\nFull Document (Truncated):\\n\\nHistory of the People\\'s Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_7.pdf'}), Document(page_content=\"Question: who holds the most women's wimbledon titles\\n\\nAnswer: na Navratilova<\\n\\nContext:\\n\\nWimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Open Era: 1968(51 editions)Surface Grass AELTC (1884–Present)Prize money £ 2,000,000 (2016)Trophy Venus Rosewater DishWebsite REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea (regular)Open era 9: Martina round)8: Helen Wills Moody Lambert Chambers(challenge NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st singles title) <\\n\\n/ LTACreated 1884\\n\\nFull Document (Truncated):\\n\\nList of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no > ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_24.pdf'}), Document(page_content='Question: who plays percy in the lost city of z\\n\\nAnswer: Johns\\'\\n\\nContext:\\n\\nwas optioned by Brad Pitt\\'s Plan B production company and Paramount Pictures. James Gray directed the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the Condor (1933), one of W. E. Johns\\' \"Bigg\\n\\nFull Document (Truncated):\\n\\nPercy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci 2px ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_23.pdf'}), Document(page_content=\"Question: when does life is strange before the storm part 2\\n\\nAnswer: October 2017\\n\\nContext:\\n\\nLife Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017 Genre(s) Graphic adventure Mode(s) Single-player\\n\\nFull Document (Truncated):\\n\\nLife Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 13px 2px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shad...\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_2.pdf'}), Document(page_content='Question: how many beverly hills cops movies are there\\n\\nAnswer: e fil\\n\\nContext:\\n\\nI>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel\\'s boss, Inspector Todd, are the only actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The films have made a total of $735,534,503[citation needed] at the worldwide box office.\\n\\nFull Document (Truncated):\\n\\nBeverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'nq_samples_good/nq_sample_26.pdf'}), Document(page_content=\"Question: where does jinx you owe me a coke come from\\n\\nAnswer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\\n\\nContext:\\n\\nJinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously.[1][2]\\n\\nFull Document (Truncated):\\n\\nJinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_4.pdf'}), Document(page_content='Question: who is ted talking about in how i met your mother\\n\\nAnswer: Tracy McConnell\\n\\nContext:\\n\\nTracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an unseen character; she was first seen fully in \"Something New\" and was promoted to a main character in season 9. The Mother is played by Cristin Milioti.\\n\\nFull Document (Truncated):\\n\\nThe Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-sha...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_9.pdf'}), Document(page_content=\"Question: where is the greatest royal rumble taking place\\n\\nAnswer: Jeddah, Saudi Arabia\\n\\nContext:\\n\\nGreatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27, 2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships were defended, in addition to a 50-man Royal Rumble match.[9]\\n\\nFull Document (Truncated):\\n\\nWWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px 10px 0 rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;bor...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_12.pdf'}), Document(page_content=\"Question: the human tendency to mimic other people’s behavior is an example of\\n\\nAnswer: Mirroring\\n\\nContext:\\n\\nMirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or attitude of another. Mirroring often occurs in social situations, particularly in the company of close friends or family. The concept often affects other individuals' notions about the individual that is exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\\n\\nFull Document (Truncated):\\n\\nMirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no > ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;border...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_14.pdf'}), Document(page_content=\"Question: who won season 4 of america's got talent\\n\\nAnswer: nner was\\n\\nContext:\\n\\n>fourth season of America's Got Talent, an American television reality show talent competition, premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner on September 16, 2009. This season is the first season to be broadcast in high definition. This s\\n\\nFull Document (Truncated):\\n\\nAmerica's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cur...\\n\\nsolid\", metadata={'source': 'nq_samples_good/nq_sample_10.pdf'}), Document(page_content=\"Question: when does model code of conduct come into force\\n\\nAnswer: immediately on announcement of the election schedule by the commission\\n\\nContext:\\n\\nElection Commission of India's Model Code of Conduct is a set of guidelines issued by the Election Commission of India for conduct of political parties and candidates during elections mainly with respect to speeches, polling day, polling booths, election manifestos, processions and general conduct. These set of norms has been evolved with the consensus of political parties who have consented to abide by the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into force immediately on announcement of the election schedule by the commission for the need of ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt practices. For example, politicians should not make hate speeches, putting one community against another or make promises about new projects that may sway a voter.\\n\\nFull Document (Truncated):\\n\\nElection Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool 10px tip solid rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{...\\n\\n>\\n\\nli{background:#fff;border:1px\\n\\n#bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);box-shadow:0\\n\\n0 0\\n\\n0\\n\\n10px\", metadata={'source': 'nq_samples_good/nq_sample_8.pdf'}), Document(page_content=\"Question: who signed the gun control act of 1968\\n\\nAnswer: t Lyndon B. Johnson on\\n\\nContext:\\n\\nCA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\\n\\nFull Document (Truncated):\\n\\nGun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;borde...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_29.pdf'}), Document(page_content=\"Question: who plays nicholas in the princess diaries 2\\n\\nAnswer: ine),\\n\\nContext:\\n\\nst of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux (Chris Pine), and Andrew Jacoby (Callum Blue). Des\\n\\nFull Document (Truncated):\\n\\nThe Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-b...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_21.pdf'}), Document(page_content=\"Question: which city and state hosts the annual college world series\\n\\nAnswer: Omaha, Nebraska\\n\\nContext:\\n\\nThe College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska. The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division I college baseball champion. The eight participating four-team, double-elimination brackets, with the winners of each bracket playing in a best-of-three championship series.\\n\\nteams are split\\n\\ninto\\n\\ntwo,\\n\\nFull Document (Truncated):\\n\\nCollege World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_5.pdf'}), Document(page_content=\"Question: who pays the judgements on the judge mathis show\\n\\nAnswer: Mathis\\n\\nContext:\\n\\nI>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating small claims disputes.\\n\\nFull Document (Truncated):\\n\\ntop:-99999px;clip:rect(1px 1px 1px 1px); Judge Mathis !important;border:0 clip:rect(1px,1px,1px,1px); overflow:hidden} !important;height:1px .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\\n\\nWikipedia\\n\\n.cite-accessibility-label{ position:absolute !important;width:1px\\n\\n!important;padding:0\\n\\n!important;\", metadata={'source': 'nq_samples_good/nq_sample_16.pdf'}), Document(page_content='Question: who sang take that look off your face\\n\\nAnswer: Marti Webb\\n\\nContext:\\n\\n\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song and Dance.\\n\\nFull Document (Truncated):\\n\\nTake That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px 10px rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'nq_samples_good/nq_sample_22.pdf'}), Document(page_content=\"Question: when did the hornets move to new orleans\\n\\nAnswer: n then-owner of t\\n\\nContext:\\n\\nestablished as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, 2014.[1] In 14 seasons of play since the\\n\\nFull Document (Truncated):\\n\\nNew Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_27.pdf'}), Document(page_content='Question: where was donovan mitchell picked in the draft\\n\\nAnswer: i/20\\n\\nContext:\\n\\n=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July 5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the 2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed Darrell Griffith\\'s team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January 4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, 2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western Conference Rookie of the Month for March and April.[28] In Mitchell\\'s playoff debut against\\n\\nFull Document (Truncated):\\n\\nDonovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op li{background:#fff;border:1px acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > solid 10px rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\n0\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_25.pdf'}), Document(page_content=\"Question: who made up the elf on the shelf\\n\\nAnswer: a Bell over\\n\\nContext:\\n\\n>The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the family to share her expertise in sales and marketing. Together, the trio devoted the next three years promoting their self-published book and attending book signings and trade shows. <\\n\\nFull Document (Truncated):\\n\\nThe Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_11.pdf'}), Document(page_content='Question: who sings with shaggy on it wasn me\\n\\nAnswer: English-Jamaican singer Rikrok\\n\\nContext:\\n\\n\"It Wasn\\'t Me\" is the first single from Jamaican-American reggae artist Shaggy\\'s multi-Platinum studio album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\\n\\nFull Document (Truncated):\\n\\nIt Wasn\\'t Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity: 0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px rgba(0,0,0,0.2);box-shadow:0 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px + transparent li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\\n\\n0\\n\\n10px 0\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0 10px\\n\\n0\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_6.pdf'}), Document(page_content='Question: how many goals scored ronaldo in his career\\n\\nAnswer: allers_with_500_or_more_goals\" title=\"List of men\\'s footballers with 500 or more goals\">670 senior career goals for club and cou\\n\\nContext: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal national team. Often considered the best player in the world and regarded by many as one of the greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d\\'Or awards,[note 2] the most for a European player, and is the first player to win four European Golden Shoes. He has won 26 trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored in Europe\\'s top-five leagues (395), the UEFA Champions League (120), the UEFA European Championship (9), as well as those for most assists in the UEFA Champions League (34) and the UEFA European Championship (6). He has scored over 670 senior career goals for club and country. Born and raised on the Portuguese isla\\n\\nFull Document (Truncated):\\n\\nCristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:\\'[\\'}.mw-c ollapsible-toggle-default:after{content:\\']\\'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-content-ltr .mw-collapsible-toggle{float:none} .mw-content-rtl .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\\n\\ncaption', metadata={'source': 'nq_samples_good/nq_sample_1.pdf'}), Document(page_content=\"Question: when did now thats what i call music come out\\n\\nAnswer: 28 November 1983\\n\\nContext:\\n\\nNow That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now! series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release of the 100th volume of the series.[4]\\n\\nFull Document (Truncated):\\n\\nNow - Wikipedia .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\\n\\nThat's What\\n\\nI\\n\\nCall\\n\\nMusic\\n\\n(original\\n\\nUK\\n\\nalbum)\", metadata={'source': 'nq_samples_good/nq_sample_18.pdf'}), Document(page_content='Question: who warned concord that the british were coming\\n\\nAnswer: Samuel Prescott\\n\\nContext:\\n\\nSamuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary War. He is best remembered for his role in Paul Revere\\'s \"midnight ride\" to warn the townspeople of Concord of the impending British army move to capture guns and gunpowder kept there at the beginning of the American Revolution. He was the only participant in the ride to reach Concord.[1] <\\n\\nFull Document (Truncated):\\n\\nSamuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont -sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\\n\\nsolid', metadata={'source': 'nq_samples_good/nq_sample_17.pdf'}), Document(page_content='Question: 100 acres is equal to how many hectares\\n\\nAnswer: =\"/wiki/Hectometre\" title=\"Hectometre\">hectometre (hm2) and primarily u\\n\\nContext: The hectare (/nhnktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area equal to 100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains about 2.47 acres. In 1795, whe\\n\\nFull Document (Truncated):\\n\\nHectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo 2px nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_3.pdf'}), Document(page_content='Question: who spread the theory that one is a product of the mind and body\\n\\nAnswer: non-extended,\\n\\nContext:\\n\\nirect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans\\' \"intelligence\" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\\n\\nFull Document (Truncated):\\n\\nPhilosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_19.pdf'}), Document(page_content='Question: when did nsw last won a state of origin series\\n\\nAnswer: D> <\\n\\nContext:\\n\\nmargin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland 3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland 1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales 3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales 2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New South Wales <\\n\\nFull Document (Truncated):\\n\\nWikipedia State .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET REMOVED_SECRETDSinIHQozUcuISCI...\\n\\nof\\n\\nOrigin\\n\\nseries\\n\\n', metadata={'source': 'nq_samples_good/nq_sample_15.pdf'}), Document(page_content=\"Question: who designed the national coat of arms of south africa\\n\\nAnswer: r's\\n\\nContext:\\n\\nign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\\n\\nFull Document (Truncated):\\n\\nCoat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px #bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_20.pdf'}), Document(page_content='Question: when was the first robot used in surgery\\n\\nAnswer: =\"ci\\n\\nContext:\\n\\nrobot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, which handed operative instruments on voice command, and a medical laboratory robotic arm. A YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\\n\\nFull Document (Truncated):\\n\\nRobot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|          | 0/30 [00:00<?, ?it/s]2024-09-20 13:52:52,178 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_28.pdf\n",
      "2024-09-20 13:52:52,179 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_13.pdf\n",
      "2024-09-20 13:52:52,179 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_7.pdf\n",
      "2024-09-20 13:52:52,180 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_24.pdf\n",
      "2024-09-20 13:52:52,180 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_23.pdf\n",
      "2024-09-20 13:52:52,180 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_2.pdf\n",
      "2024-09-20 13:52:52,181 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_26.pdf\n",
      "2024-09-20 13:52:52,181 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_4.pdf\n",
      "2024-09-20 13:52:52,181 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_9.pdf\n",
      "2024-09-20 13:52:52,182 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_12.pdf\n",
      "2024-09-20 13:52:52,182 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_14.pdf\n",
      "2024-09-20 13:52:52,182 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_10.pdf\n",
      "2024-09-20 13:52:52,183 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_8.pdf\n",
      "2024-09-20 13:52:52,184 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_29.pdf\n",
      "2024-09-20 13:52:52,184 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_21.pdf\n",
      "2024-09-20 13:52:52,184 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_5.pdf\n",
      "2024-09-20 13:52:52,185 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_16.pdf\n",
      "2024-09-20 13:52:52,185 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_22.pdf\n",
      "2024-09-20 13:52:52,186 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_27.pdf\n",
      "2024-09-20 13:52:52,186 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_25.pdf\n",
      "2024-09-20 13:52:52,186 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_11.pdf\n",
      "2024-09-20 13:52:52,187 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_6.pdf\n",
      "2024-09-20 13:52:52,187 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_1.pdf\n",
      "2024-09-20 13:52:52,188 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_18.pdf\n",
      "2024-09-20 13:52:52,188 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_17.pdf\n",
      "2024-09-20 13:52:52,188 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_3.pdf\n",
      "2024-09-20 13:52:52,189 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_19.pdf\n",
      "2024-09-20 13:52:52,189 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_15.pdf\n",
      "2024-09-20 13:52:52,189 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_20.pdf\n",
      "2024-09-20 13:52:52,190 - WARNING - No question or answer found in document: nq_samples_good/nq_sample_30.pdf\n",
      "Processing PDFs: 100%|██████████| 30/30 [00:00<00:00, 2566.00it/s]\n",
      "2024-09-20 13:52:52,190 - ERROR - No valid questions and answers were extracted from the documents\n",
      "2024-09-20 13:52:52,191 - ERROR - No data to process. Exiting.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from RAG_UTILS import DocumentProcessor, RAGSystem, LangchainDocument\n",
    "import logging\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "MODEL_ID = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
    "RERANKER_MODEL = \"colbert-ir/colbertv2.0\"\n",
    "PDF_FOLDER_PATH = \"nq_samples_good\"\n",
    "PROCESSED_DATA_PATH = \"processed_data.csv\"\n",
    "NUM_RETRIEVED_DOCS = 5\n",
    "\n",
    "def extract_question_and_answer(content: str) -> Tuple[str, str]:\n",
    "    lines = content.split('\\n')\n",
    "    question = \"\"\n",
    "    answer = \"\"\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"Question:\"):\n",
    "            question = lines[i+1].strip()\n",
    "        elif line.startswith(\"Answer:\"):\n",
    "            answer = ' '.join(lines[i+1:]).strip()\n",
    "            break\n",
    "    return question, answer\n",
    "\n",
    "def process_pdfs(folder_path: str) -> List[Tuple[str, str, str]]:\n",
    "    doc_processor = DocumentProcessor(EMBEDDING_MODEL_NAME)\n",
    "    raw_documents = doc_processor.load_pdfs_from_folder(folder_path)\n",
    "    processed_data = []\n",
    "\n",
    "    if not raw_documents:\n",
    "        logging.error(f\"No documents were loaded from {folder_path}\")\n",
    "        return []\n",
    "\n",
    "    for doc in tqdm(raw_documents, desc=\"Processing PDFs\"):\n",
    "        question, answer = extract_question_and_answer(doc.page_content)\n",
    "        if question and answer:\n",
    "            processed_data.append((question, answer, doc.page_content))\n",
    "        else:\n",
    "            logging.warning(f\"No question or answer found in document: {REMOVED_SECRET('source', 'Unknown')}\")\n",
    "\n",
    "    if not processed_data:\n",
    "        logging.error(\"No valid questions and answers were extracted from the documents\")\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "def save_processed_data(data: List[Tuple[str, str, str]], output_path: str):\n",
    "    df = pd.DataFrame(data, columns=['question', 'answer', 'context'])\n",
    "    df.to_csv(output_path, index=False)\n",
    "    logging.info(f\"Processed data saved to {output_path}\")\n",
    "\n",
    "def load_processed_data(file_path: str) -> List[Tuple[str, str, str]]:\n",
    "    df = pd.read_csv(file_path)\n",
    "    return list(df.itertuples(index=False, name=None))\n",
    "\n",
    "def evaluate_rag_system(rag_system: RAGSystem, questions_and_answers: List[Tuple[str, str, str]]):\n",
    "    results = []\n",
    "    for question, answer, context in tqdm(questions_and_answers, desc=\"Evaluating RAG system\"):\n",
    "        rag_answer, relevant_docs, _ = rag_system.answer_with_rag(question, rag_system.knowledge_index, num_retrieved_docs=NUM_RETRIEVED_DOCS)\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"ground_truth\": answer,\n",
    "            \"rag_answer\": rag_answer,\n",
    "            \"relevant_docs\": [doc.page_content for doc in relevant_docs]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Process PDFs and extract questions/answers\n",
    "    if not REMOVED_SECRET(PROCESSED_DATA_PATH):\n",
    "        processed_data = process_pdfs(PDF_FOLDER_PATH)\n",
    "        if not processed_data:\n",
    "            logging.error(\"No data to process. Exiting.\")\n",
    "            return\n",
    "        save_processed_data(processed_data, PROCESSED_DATA_PATH)\n",
    "    else:\n",
    "        processed_data = load_processed_data(PROCESSED_DATA_PATH)\n",
    "        if not processed_data:\n",
    "            logging.error(\"No data found in the processed data file. Exiting.\")\n",
    "            return\n",
    "\n",
    "    # Initialize RAG system\n",
    "    rag_system = RAGSystem(\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "        model_id=MODEL_ID,\n",
    "        reranker_model=RERANKER_MODEL,\n",
    "    )\n",
    "\n",
    "    # Build knowledge index\n",
    "    documents = [LangchainDocument(page_content=context, metadata={}) for _, _, context in processed_data]\n",
    "    if not documents:\n",
    "        logging.error(\"No documents to build the knowledge index. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        rag_system.knowledge_index = rag_system.build_vector_database(documents)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error building knowledge index: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Evaluate RAG system\n",
    "    evaluation_results = evaluate_rag_system(rag_system, processed_data)\n",
    "\n",
    "    # Save evaluation results\n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    results_df.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "    logging.info(\"Evaluation complete. Results saved to 'rag_evaluation_results.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "c7900cb1f64947e680c9a7fd10eb0fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['REMOVED_SECRET.bias', 'REMOVED_SECRET.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:01<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content='Question: fish appeared in the fossil record during the\\n\\nAnswer: wiki/Cambrian_explosion\" title=\"Cambrian explosion\">Cambrian explosion. It was d\\n\\nContext:\\n\\nution of fish began about 530 million years ago during the Cambrian explosion. It was during this time that the early chordates developed the skull and the vertebral column, leading to the first craniates and vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which includes the extant hagfish, and this group may have split early on from other agnathans. The first\\n\\nFull Document (Truncated):\\n\\nEvolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa li{background:#fff;border:1px city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > 10px solid rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\n0\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_28.pdf'}), Document(page_content=\"Question: when does grey's anatomy season 14 premiere\\n\\nAnswer: eptember 28, 2017<\\n\\nContext:\\n\\nGrey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti Country of origin United States No. of episodes 12 Release Original network ABC Original release September 28, 2017 (2017-09-28) – present Season chronology ‹ Previous Season 13 List of Grey's Anatomy episodes The\\n\\nFull Document (Truncated):\\n\\nGrey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none...\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_13.pdf'}), Document(page_content='Question: who established the peoples republic of china in 1949\\n\\nAnswer: men\" title\\n\\nContext:\\n\\n> details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People\\'s Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties. Con\\n\\nFull Document (Truncated):\\n\\nHistory of the People\\'s Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_7.pdf'}), Document(page_content=\"Question: who holds the most women's wimbledon titles\\n\\nAnswer: na Navratilova<\\n\\nContext:\\n\\nWimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Open Era: 1968(51 editions)Surface Grass AELTC (1884–Present)Prize money £ 2,000,000 (2016)Trophy Venus Rosewater DishWebsite REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea (regular)Open era 9: Martina round)8: Helen Wills Moody Lambert Chambers(challenge NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st singles title) <\\n\\n/ LTACreated 1884\\n\\nFull Document (Truncated):\\n\\nList of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no > ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_24.pdf'}), Document(page_content='Question: who plays percy in the lost city of z\\n\\nAnswer: Johns\\'\\n\\nContext:\\n\\nwas optioned by Brad Pitt\\'s Plan B production company and Paramount Pictures. James Gray directed the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the Condor (1933), one of W. E. Johns\\' \"Bigg\\n\\nFull Document (Truncated):\\n\\nPercy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci 2px ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_23.pdf'}), Document(page_content=\"Question: when does life is strange before the storm part 2\\n\\nAnswer: October 2017\\n\\nContext:\\n\\nLife Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017 Genre(s) Graphic adventure Mode(s) Single-player\\n\\nFull Document (Truncated):\\n\\nLife Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 13px 2px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shad...\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_2.pdf'}), Document(page_content='Question: how many beverly hills cops movies are there\\n\\nAnswer: e fil\\n\\nContext:\\n\\nI>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel\\'s boss, Inspector Todd, are the only actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The films have made a total of $735,534,503[citation needed] at the worldwide box office.\\n\\nFull Document (Truncated):\\n\\nBeverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'nq_samples_good/nq_sample_26.pdf'}), Document(page_content=\"Question: where does jinx you owe me a coke come from\\n\\nAnswer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\\n\\nContext:\\n\\nJinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously.[1][2]\\n\\nFull Document (Truncated):\\n\\nJinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_4.pdf'}), Document(page_content='Question: who is ted talking about in how i met your mother\\n\\nAnswer: Tracy McConnell\\n\\nContext:\\n\\nTracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an unseen character; she was first seen fully in \"Something New\" and was promoted to a main character in season 9. The Mother is played by Cristin Milioti.\\n\\nFull Document (Truncated):\\n\\nThe Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-sha...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_9.pdf'}), Document(page_content=\"Question: where is the greatest royal rumble taking place\\n\\nAnswer: Jeddah, Saudi Arabia\\n\\nContext:\\n\\nGreatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27, 2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships were defended, in addition to a 50-man Royal Rumble match.[9]\\n\\nFull Document (Truncated):\\n\\nWWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px 10px 0 rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;bor...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_12.pdf'}), Document(page_content=\"Question: the human tendency to mimic other people’s behavior is an example of\\n\\nAnswer: Mirroring\\n\\nContext:\\n\\nMirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or attitude of another. Mirroring often occurs in social situations, particularly in the company of close friends or family. The concept often affects other individuals' notions about the individual that is exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\\n\\nFull Document (Truncated):\\n\\nMirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no > ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;border...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_14.pdf'}), Document(page_content=\"Question: who won season 4 of america's got talent\\n\\nAnswer: nner was\\n\\nContext:\\n\\n>fourth season of America's Got Talent, an American television reality show talent competition, premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner on September 16, 2009. This season is the first season to be broadcast in high definition. This s\\n\\nFull Document (Truncated):\\n\\nAmerica's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cur...\\n\\nsolid\", metadata={'source': 'nq_samples_good/nq_sample_10.pdf'}), Document(page_content=\"Question: when does model code of conduct come into force\\n\\nAnswer: immediately on announcement of the election schedule by the commission\\n\\nContext:\\n\\nElection Commission of India's Model Code of Conduct is a set of guidelines issued by the Election Commission of India for conduct of political parties and candidates during elections mainly with respect to speeches, polling day, polling booths, election manifestos, processions and general conduct. These set of norms has been evolved with the consensus of political parties who have consented to abide by the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into force immediately on announcement of the election schedule by the commission for the need of ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt practices. For example, politicians should not make hate speeches, putting one community against another or make promises about new projects that may sway a voter.\\n\\nFull Document (Truncated):\\n\\nElection Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool 10px tip solid rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{...\\n\\n>\\n\\nli{background:#fff;border:1px\\n\\n#bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);box-shadow:0\\n\\n0 0\\n\\n0\\n\\n10px\", metadata={'source': 'nq_samples_good/nq_sample_8.pdf'}), Document(page_content=\"Question: who signed the gun control act of 1968\\n\\nAnswer: t Lyndon B. Johnson on\\n\\nContext:\\n\\nCA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\\n\\nFull Document (Truncated):\\n\\nGun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;borde...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_29.pdf'}), Document(page_content=\"Question: who plays nicholas in the princess diaries 2\\n\\nAnswer: ine),\\n\\nContext:\\n\\nst of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux (Chris Pine), and Andrew Jacoby (Callum Blue). Des\\n\\nFull Document (Truncated):\\n\\nThe Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-b...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_21.pdf'}), Document(page_content=\"Question: which city and state hosts the annual college world series\\n\\nAnswer: Omaha, Nebraska\\n\\nContext:\\n\\nThe College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska. The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division I college baseball champion. The eight participating four-team, double-elimination brackets, with the winners of each bracket playing in a best-of-three championship series.\\n\\nteams are split\\n\\ninto\\n\\ntwo,\\n\\nFull Document (Truncated):\\n\\nCollege World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_5.pdf'}), Document(page_content=\"Question: who pays the judgements on the judge mathis show\\n\\nAnswer: Mathis\\n\\nContext:\\n\\nI>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating small claims disputes.\\n\\nFull Document (Truncated):\\n\\ntop:-99999px;clip:rect(1px 1px 1px 1px); Judge Mathis !important;border:0 clip:rect(1px,1px,1px,1px); overflow:hidden} !important;height:1px .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\\n\\nWikipedia\\n\\n.cite-accessibility-label{ position:absolute !important;width:1px\\n\\n!important;padding:0\\n\\n!important;\", metadata={'source': 'nq_samples_good/nq_sample_16.pdf'}), Document(page_content='Question: who sang take that look off your face\\n\\nAnswer: Marti Webb\\n\\nContext:\\n\\n\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song and Dance.\\n\\nFull Document (Truncated):\\n\\nTake That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px 10px rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'nq_samples_good/nq_sample_22.pdf'}), Document(page_content=\"Question: when did the hornets move to new orleans\\n\\nAnswer: n then-owner of t\\n\\nContext:\\n\\nestablished as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, 2014.[1] In 14 seasons of play since the\\n\\nFull Document (Truncated):\\n\\nNew Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_27.pdf'}), Document(page_content='Question: where was donovan mitchell picked in the draft\\n\\nAnswer: i/20\\n\\nContext:\\n\\n=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July 5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the 2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed Darrell Griffith\\'s team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January 4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, 2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western Conference Rookie of the Month for March and April.[28] In Mitchell\\'s playoff debut against\\n\\nFull Document (Truncated):\\n\\nDonovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op li{background:#fff;border:1px acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > solid 10px rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\n0\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_25.pdf'}), Document(page_content=\"Question: who made up the elf on the shelf\\n\\nAnswer: a Bell over\\n\\nContext:\\n\\n>The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the family to share her expertise in sales and marketing. Together, the trio devoted the next three years promoting their self-published book and attending book signings and trade shows. <\\n\\nFull Document (Truncated):\\n\\nThe Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_11.pdf'}), Document(page_content='Question: who sings with shaggy on it wasn me\\n\\nAnswer: English-Jamaican singer Rikrok\\n\\nContext:\\n\\n\"It Wasn\\'t Me\" is the first single from Jamaican-American reggae artist Shaggy\\'s multi-Platinum studio album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\\n\\nFull Document (Truncated):\\n\\nIt Wasn\\'t Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity: 0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px rgba(0,0,0,0.2);box-shadow:0 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px + transparent li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\\n\\n0\\n\\n10px 0\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0 10px\\n\\n0\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_6.pdf'}), Document(page_content='Question: how many goals scored ronaldo in his career\\n\\nAnswer: allers_with_500_or_more_goals\" title=\"List of men\\'s footballers with 500 or more goals\">670 senior career goals for club and cou\\n\\nContext: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal national team. Often considered the best player in the world and regarded by many as one of the greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d\\'Or awards,[note 2] the most for a European player, and is the first player to win four European Golden Shoes. He has won 26 trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored in Europe\\'s top-five leagues (395), the UEFA Champions League (120), the UEFA European Championship (9), as well as those for most assists in the UEFA Champions League (34) and the UEFA European Championship (6). He has scored over 670 senior career goals for club and country. Born and raised on the Portuguese isla\\n\\nFull Document (Truncated):\\n\\nCristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:\\'[\\'}.mw-c ollapsible-toggle-default:after{content:\\']\\'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-content-ltr .mw-collapsible-toggle{float:none} .mw-content-rtl .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\\n\\ncaption', metadata={'source': 'nq_samples_good/nq_sample_1.pdf'}), Document(page_content=\"Question: when did now thats what i call music come out\\n\\nAnswer: 28 November 1983\\n\\nContext:\\n\\nNow That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now! series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release of the 100th volume of the series.[4]\\n\\nFull Document (Truncated):\\n\\nNow - Wikipedia .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\\n\\nThat's What\\n\\nI\\n\\nCall\\n\\nMusic\\n\\n(original\\n\\nUK\\n\\nalbum)\", metadata={'source': 'nq_samples_good/nq_sample_18.pdf'}), Document(page_content='Question: who warned concord that the british were coming\\n\\nAnswer: Samuel Prescott\\n\\nContext:\\n\\nSamuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary War. He is best remembered for his role in Paul Revere\\'s \"midnight ride\" to warn the townspeople of Concord of the impending British army move to capture guns and gunpowder kept there at the beginning of the American Revolution. He was the only participant in the ride to reach Concord.[1] <\\n\\nFull Document (Truncated):\\n\\nSamuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont -sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\\n\\nsolid', metadata={'source': 'nq_samples_good/nq_sample_17.pdf'}), Document(page_content='Question: 100 acres is equal to how many hectares\\n\\nAnswer: =\"/wiki/Hectometre\" title=\"Hectometre\">hectometre (hm2) and primarily u\\n\\nContext: The hectare (/nhnktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area equal to 100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains about 2.47 acres. In 1795, whe\\n\\nFull Document (Truncated):\\n\\nHectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo 2px nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_3.pdf'}), Document(page_content='Question: who spread the theory that one is a product of the mind and body\\n\\nAnswer: non-extended,\\n\\nContext:\\n\\nirect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans\\' \"intelligence\" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\\n\\nFull Document (Truncated):\\n\\nPhilosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_19.pdf'}), Document(page_content='Question: when did nsw last won a state of origin series\\n\\nAnswer: D> <\\n\\nContext:\\n\\nmargin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland 3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland 1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales 3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales 2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New South Wales <\\n\\nFull Document (Truncated):\\n\\nWikipedia State .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET REMOVED_SECRETDSinIHQozUcuISCI...\\n\\nof\\n\\nOrigin\\n\\nseries\\n\\n', metadata={'source': 'nq_samples_good/nq_sample_15.pdf'}), Document(page_content=\"Question: who designed the national coat of arms of south africa\\n\\nAnswer: r's\\n\\nContext:\\n\\nign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\\n\\nFull Document (Truncated):\\n\\nCoat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px #bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_20.pdf'}), Document(page_content='Question: when was the first robot used in surgery\\n\\nAnswer: =\"ci\\n\\nContext:\\n\\nrobot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, which handed operative instruments on voice command, and a medical laboratory robotic arm. A YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\\n\\nFull Document (Truncated):\\n\\nRobot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 221.38it/s]\n",
      "Evaluating samples:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   3%|▎         | 1/30 [00:24<11:49, 24.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   7%|▋         | 2/30 [01:19<19:40, 42.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  10%|█         | 3/30 [01:46<15:53, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  13%|█▎        | 4/30 [02:14<14:04, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  17%|█▋        | 5/30 [02:28<10:47, 25.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  20%|██        | 6/30 [02:50<09:45, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  23%|██▎       | 7/30 [03:09<08:46, 22.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  27%|██▋       | 8/30 [03:25<07:31, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  30%|███       | 9/30 [03:41<06:40, 19.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  33%|███▎      | 10/30 [03:59<06:14, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  37%|███▋      | 11/30 [04:09<05:07, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  40%|████      | 12/30 [04:33<05:32, 18.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  43%|████▎     | 13/30 [04:46<04:49, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  47%|████▋     | 14/30 [05:06<04:42, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  50%|█████     | 15/30 [05:26<04:38, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  53%|█████▎    | 16/30 [05:42<04:09, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  57%|█████▋    | 17/30 [05:59<03:46, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  60%|██████    | 18/30 [06:14<03:21, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  63%|██████▎   | 19/30 [06:25<02:45, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  67%|██████▋   | 20/30 [06:44<02:41, 16.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  70%|███████   | 21/30 [07:04<02:35, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  73%|███████▎  | 22/30 [07:23<02:22, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  77%|███████▋  | 23/30 [07:34<01:51, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  80%|████████  | 24/30 [07:50<01:35, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  83%|████████▎ | 25/30 [08:06<01:19, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  87%|████████▋ | 26/30 [08:22<01:03, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  90%|█████████ | 27/30 [08:35<00:45, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  93%|█████████▎| 28/30 [08:53<00:31, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  97%|█████████▋| 29/30 [09:14<00:17, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 100%|██████████| 30/30 [09:41<00:00, 19.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         bleu_score     rouge1     rouge2     rougeL  retrieval_accuracy  \\\n",
      "count  3.000000e+01  30.000000  30.000000  30.000000                30.0   \n",
      "mean   1.827483e-04   0.064890   0.037563   0.056051                 0.0   \n",
      "std    6.566587e-04   0.016701   0.020128   0.017055                 0.0   \n",
      "min    1.572996e-13   0.040346   0.000000   0.023346                 0.0   \n",
      "25%    7.999858e-07   0.054702   0.027517   0.043845                 0.0   \n",
      "50%    6.610064e-06   0.060769   0.037856   0.055711                 0.0   \n",
      "75%    7.454518e-05   0.073871   0.049646   0.065322                 0.0   \n",
      "max    3.566894e-03   0.110236   0.090395   0.101124                 0.0   \n",
      "\n",
      "       bert_score    perplexity  \n",
      "count   30.000000  3.000000e+01  \n",
      "mean    -0.327708  4.056559e+05  \n",
      "std      0.110857  6.841960e+05  \n",
      "min     -0.624531  1.067466e+04  \n",
      "25%     -0.394986  1.111732e+05  \n",
      "50%     -0.298341  1.858772e+05  \n",
      "75%     -0.261672  3.683714e+05  \n",
      "max     -0.124858  3.485244e+06  \n",
      "\n",
      "Average Scores:\n",
      "bleu_score                 0.000183\n",
      "rouge1                     0.064890\n",
      "rouge2                     0.037563\n",
      "rougeL                     0.056051\n",
      "retrieval_accuracy         0.000000\n",
      "bert_score                -0.327708\n",
      "perplexity            405655.867480\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETFZvEEOle2gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETN/NzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETiU4rTmmWAAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Worst Predictions:\n",
      "Question: where was donovan mitchell picked in the draft\n",
      "Ground Truth: i/20\n",
      "Context:\n",
      "=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017\n",
      "NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July\n",
      "5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell\n",
      "signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the\n",
      "Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the\n",
      "2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points\n",
      "and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41\n",
      "points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and\n",
      "became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed\n",
      "Darrell Griffith's team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise\n",
      "history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January\n",
      "4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after\n",
      "averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the\n",
      "month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points\n",
      "games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018\n",
      "Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming\n",
      "the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5,\n",
      "2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward\n",
      "Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest\n",
      "scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the\n",
      "contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie\n",
      "of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie\n",
      "record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden\n",
      "State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western\n",
      "Conference Rookie of the Month for March and April.[28] In Mitchell's playoff debut against\n",
      "Full Document (Truncated):\n",
      "Donovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op\n",
      "acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px\n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px\n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px;\n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad\n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px\n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+\n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei\n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto\n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\n",
      "Generated Answer: Donovan Mitchell was picked in the first round as the 20th overall pick in the 201\n",
      "BLEU Score: 1.572996181934318e-13\n",
      "--------------------\n",
      "Question: when did nsw last won a state of origin series\n",
      "Ground Truth: D> <\n",
      "Context:\n",
      "margin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982\n",
      "Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0\n",
      "Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South\n",
      "Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland\n",
      "3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland\n",
      "1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994\n",
      "New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales\n",
      "3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0\n",
      "Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001\n",
      "Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South\n",
      "Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales\n",
      "2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0\n",
      "Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011\n",
      "Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0\n",
      "Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016\n",
      "Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New\n",
      "South Wales <\n",
      "Full Document (Truncated):\n",
      "State \n",
      "of \n",
      "Origin \n",
      "series \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_SECRETDSinIHQozUcuISCI...\n",
      "Generated Answer: 2018\n",
      "\n",
      "Context:\n",
      "\n",
      "margin: 1em auto\"> State of Origin series Year Winner W\n",
      "BLEU Score: 7.294933599227295e-12\n",
      "--------------------\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: e fil\n",
      "Context:\n",
      "I>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on\n",
      "characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a\n",
      "street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is\n",
      "out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John\n",
      "Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in\n",
      "Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel's boss, Inspector Todd, are the only\n",
      "actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song\n",
      "heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The\n",
      "films have made a total of $735,534,503[citation needed] at the worldwide box office.\n",
      "Full Document (Truncated):\n",
      "Beverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im\n",
      "age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "Beverly Hills Cop (198\n",
      "BLEU Score: 3.138271331080618e-10\n",
      "--------------------\n",
      "Question: when did now thats what i call music come out\n",
      "Ground Truth: 28 November 1983\n",
      "Context:\n",
      "Now That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now!\n",
      "series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were\n",
      "released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the\n",
      "album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For\n",
      "Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from\n",
      "1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the\n",
      "album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release\n",
      "of the 100th volume of the series.[4]\n",
      "Full Document (Truncated):\n",
      "Now \n",
      "That's \n",
      "What \n",
      "I \n",
      "Call \n",
      "Music \n",
      "(original \n",
      "UK \n",
      "album) \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\n",
      "Generated Answer: 1996\n",
      "\n",
      "Context: Document 2:\n",
      "\n",
      "That's What\n",
      "\n",
      "I\n",
      "\n",
      "Call\n",
      "BLEU Score: 3.5994313351520553e-09\n",
      "--------------------\n",
      "Question: when did the hornets move to new orleans\n",
      "Ground Truth: n then-owner of t\n",
      "Context:\n",
      "established as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte\n",
      "Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by\n",
      "Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two\n",
      "seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New\n",
      "Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would\n",
      "rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte\n",
      "Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the\n",
      "then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20,\n",
      "2014.[1] In 14 seasons of play since the\n",
      "Full Document (Truncated):\n",
      "New Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no\n",
      "ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: 2002-03 season\n",
      "\n",
      "        Question: when did the hornets move to new orleans\n",
      "BLEU Score: 1.6843607318794272e-08\n",
      "--------------------\n",
      "Question: who holds the most women's wimbledon titles\n",
      "Ground Truth: na Navratilova<\n",
      "Context:\n",
      "Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body\n",
      "AELTC \n",
      "/ \n",
      "LTACreated \n",
      "1884 \n",
      "(established)Open \n",
      "Era: \n",
      "1968(51 \n",
      "editions)Surface \n",
      "Grass\n",
      "(1884–Present)Prize \n",
      "money \n",
      "£ \n",
      "2,000,000 \n",
      "(2016)Trophy \n",
      "Venus \n",
      "Rosewater \n",
      "DishWebsite\n",
      "REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea\n",
      "Lambert Chambers(challenge round)8: Helen Wills Moody (regular)Open era 9: Martina\n",
      "NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4:\n",
      "Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st\n",
      "singles title) <\n",
      "Full Document (Truncated):\n",
      "List of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no\n",
      "ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:...\n",
      "Generated Answer: Navratilova\n",
      "\n",
      "        Context:\n",
      "\n",
      "        Wimbledon Ladies’ Singles ChampionsLocation London\n",
      "BLEU Score: 7.765664828833511e-08\n",
      "--------------------\n",
      "Question: fish appeared in the fossil record during the\n",
      "Ground Truth: wiki/Cambrian_explosion\" title=\"Cambrian explosion\">Cambrian explosion. It was d\n",
      "Context:\n",
      "ution of fish began about 530 million years ago during the Cambrian explosion. It was during this time\n",
      "that the early chordates developed the skull and the vertebral column, leading to the first craniates and\n",
      "vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include\n",
      "Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly\n",
      "armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant\n",
      "lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which\n",
      "includes the extant hagfish, and this group may have split early on from other agnathans. The first\n",
      "Full Document (Truncated):\n",
      "Evolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa\n",
      "city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px\n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px\n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px;\n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad\n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px\n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+\n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei\n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto\n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\n",
      "Generated Answer: 530 million years ago during the Cambrian explosion.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "\n",
      "Context:\n",
      "BLEU Score: 5.530536943357003e-07\n",
      "--------------------\n",
      "Question: when does grey's anatomy season 14 premiere\n",
      "Ground Truth: eptember 28, 2017<\n",
      "Context:\n",
      "Grey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra\n",
      "Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina\n",
      "Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti\n",
      "Country of origin United States No. of episodes 12 Release Original network ABC Original release\n",
      "September 28, 2017 (2017-09-28) – present Season chronology ← Previous Season 13 List of Grey's\n",
      "Anatomy episodes The\n",
      "Full Document (Truncated):\n",
      "Grey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima\n",
      "ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "Grey's Anatomy (season\n",
      "BLEU Score: 7.814793159602894e-07\n",
      "--------------------\n",
      "Question: which city and state hosts the annual college world series\n",
      "Ground Truth: Omaha, Nebraska\n",
      "Context:\n",
      "The College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska.\n",
      "The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball\n",
      "Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division\n",
      "I college baseball champion. The eight participating teams are split into two, four-team,\n",
      "double-elimination brackets, with the winners of each bracket playing in a best-of-three championship\n",
      "series.\n",
      "Full Document (Truncated):\n",
      "College World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non\n",
      "e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: Omaha, Nebraska\n",
      "\n",
      "\n",
      "Document 2:\n",
      "\n",
      "Context:\n",
      "\n",
      "The College World\n",
      "BLEU Score: 8.55505264193596e-07\n",
      "--------------------\n",
      "Question: when was the first robot used in surgery\n",
      "Ground Truth: =\"ci\n",
      "Context:\n",
      "robot to assist in surgery was the Arthrobot, which was developed and used for the first time in\n",
      "Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof\n",
      "Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering\n",
      "students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC\n",
      "Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months,\n",
      "and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the\n",
      "device. Other related robotic devices developed at the same time included a surgical scrub nurse robot,\n",
      "which handed operative instruments on voice command, and a medical laboratory robotic arm. A\n",
      "YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\n",
      "Full Document (Truncated):\n",
      "Robot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no\n",
      "ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\n",
      "Generated Answer: 1983\n",
      "\n",
      "Document 2:\n",
      "Question: what is the most common use of robots in surgery\n",
      "BLEU Score: 1.1747828400070414e-06\n",
      "--------------------\n",
      "\n",
      "Error Patterns:\n",
      "short_answer: 0\n",
      "long_answer: 0\n",
      "low_bleu: 30\n",
      "\n",
      "Generated Answers:\n",
      "Question: fish appeared in the fossil record during the\n",
      "Ground Truth: wiki/Cambrian_explosion\" title=\"Cambrian explosion\">Cambrian explosion. It was d\n",
      "Context:\n",
      "ution of fish began about 530 million years ago during the Cambrian explosion. It was during this time\n",
      "that the early chordates developed the skull and the vertebral column, leading to the first craniates and\n",
      "vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include\n",
      "Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly\n",
      "armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant\n",
      "lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which\n",
      "includes the extant hagfish, and this group may have split early on from other agnathans. The first\n",
      "Full Document (Truncated):\n",
      "Evolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa\n",
      "city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px\n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px\n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px;\n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad\n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px\n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+\n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei\n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto\n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\n",
      "Generated Answer: 530 million years ago during the Cambrian explosion.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "\n",
      "Context:\n",
      "--------------------\n",
      "Question: when does grey's anatomy season 14 premiere\n",
      "Ground Truth: eptember 28, 2017<\n",
      "Context:\n",
      "Grey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra\n",
      "Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina\n",
      "Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti\n",
      "Country of origin United States No. of episodes 12 Release Original network ABC Original release\n",
      "September 28, 2017 (2017-09-28) – present Season chronology ← Previous Season 13 List of Grey's\n",
      "Anatomy episodes The\n",
      "Full Document (Truncated):\n",
      "Grey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima\n",
      "ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "Grey's Anatomy (season\n",
      "--------------------\n",
      "Question: who established the peoples republic of china in 1949\n",
      "Ground Truth: men\" title\n",
      "Context:\n",
      "> details the history of mainland China since October 1, 1949, when, after a near complete victory by\n",
      "the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's\n",
      "Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous\n",
      "with China, but it is only the most recent political entity to govern mainland China, preceded by the\n",
      "Republic of China (ROC) and thousands of years of imperial dynasties. Con\n",
      "Full Document (Truncated):\n",
      "History of the People's Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l\n",
      "ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip\n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-...\n",
      "Generated Answer: Mao Zedong established the People's Republic of China in 1949.\n",
      "--------------------\n",
      "Question: who holds the most women's wimbledon titles\n",
      "Ground Truth: na Navratilova<\n",
      "Context:\n",
      "Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body\n",
      "AELTC \n",
      "/ \n",
      "LTACreated \n",
      "1884 \n",
      "(established)Open \n",
      "Era: \n",
      "1968(51 \n",
      "editions)Surface \n",
      "Grass\n",
      "(1884–Present)Prize \n",
      "money \n",
      "£ \n",
      "2,000,000 \n",
      "(2016)Trophy \n",
      "Venus \n",
      "Rosewater \n",
      "DishWebsite\n",
      "REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea\n",
      "Lambert Chambers(challenge round)8: Helen Wills Moody (regular)Open era 9: Martina\n",
      "NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4:\n",
      "Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st\n",
      "singles title) <\n",
      "Full Document (Truncated):\n",
      "List of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no\n",
      "ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:...\n",
      "Generated Answer: Navratilova\n",
      "\n",
      "        Context:\n",
      "\n",
      "        Wimbledon Ladies’ Singles ChampionsLocation London\n",
      "--------------------\n",
      "Question: who plays percy in the lost city of z\n",
      "Ground Truth: Johns'\n",
      "Context:\n",
      "was optioned by Brad Pitt's Plan B production company and Paramount Pictures. James Gray directed\n",
      "the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the\n",
      "Condor (1933), one of W. E. Johns' \"Bigg\n",
      "Full Document (Truncated):\n",
      "Percy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci\n",
      "ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\n",
      "Generated Answer: Question: Who portrays Percy in the film \"The Lost City of Z\"?\n",
      "--------------------\n",
      "Question: when does life is strange before the storm part 2\n",
      "Ground Truth: October 2017\n",
      "Context:\n",
      "Life Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb\n",
      "Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham\n",
      "Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss\n",
      "Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release\n",
      "Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017\n",
      "Genre(s) Graphic adventure Mode(s) Single-player\n",
      "Full Document (Truncated):\n",
      "Life Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style\n",
      "-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086\n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shad...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "Life Is Strange: Before the Storm - Wikipedia\n",
      "--------------------\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: e fil\n",
      "Context:\n",
      "I>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on\n",
      "characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a\n",
      "street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is\n",
      "out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John\n",
      "Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in\n",
      "Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel's boss, Inspector Todd, are the only\n",
      "actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song\n",
      "heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The\n",
      "films have made a total of $735,534,503[citation needed] at the worldwide box office.\n",
      "Full Document (Truncated):\n",
      "Beverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im\n",
      "age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "Beverly Hills Cop (198\n",
      "--------------------\n",
      "Question: where does jinx you owe me a coke come from\n",
      "Ground Truth: Jinx is a children's game with varying rules and penalties that occur when two people\n",
      "unintentionally speak the same word or phrase simultaneously\n",
      "Context:\n",
      "Jinx is a children's game with varying rules and penalties that occur when two people unintentionally\n",
      "speak the same word or phrase simultaneously.[1][2]\n",
      "Full Document (Truncated):\n",
      "Jinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non\n",
      "e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\n",
      "Generated Answer: Jinx originates from children's games where players unintentionally say the same word or phrase at the\n",
      "--------------------\n",
      "Question: who is ted talking about in how i met your mother\n",
      "Ground Truth: Tracy McConnell\n",
      "Context:\n",
      "Tracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom\n",
      "How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The\n",
      "Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an\n",
      "unseen character; she was first seen fully in \"Something New\" and was promoted to a main character\n",
      "in season 9. The Mother is played by Cristin Milioti.\n",
      "Full Document (Truncated):\n",
      "The Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s\n",
      "tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip\n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-sha...\n",
      "Generated Answer: Tracy McConnell, known as \"The Mother.\"\n",
      "\n",
      "Document 2:\n",
      "Question: who is\n",
      "--------------------\n",
      "Question: where is the greatest royal rumble taking place\n",
      "Ground Truth: Jeddah, Saudi Arabia\n",
      "Context:\n",
      "Greatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network\n",
      "event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27,\n",
      "2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi\n",
      "Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon\n",
      "EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships\n",
      "were defended, in addition to a 50-man Royal Rumble match.[9]\n",
      "Full Document (Truncated):\n",
      "WWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im\n",
      "age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;bor...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "WWE Greatest Royal Rumble - Wikipedia\n",
      "--------------------\n",
      "Question: the human tendency to mimic other people’s behavior is\n",
      "Ground Truth: Mirroring\n",
      "Context:\n",
      "Mirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or\n",
      "attitude of another. Mirroring often occurs in social situations, particularly in the company of close\n",
      "friends or family. The concept often affects other individuals' notions about the individual that is\n",
      "exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\n",
      "Full Document (Truncated):\n",
      "Mirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no\n",
      "ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;border...\n",
      "Generated Answer: Question: the human tendency to mimic other people’s behavior is an example of\n",
      "\n",
      "        Inst\n",
      "--------------------\n",
      "Question: who won season 4 of america's got talent\n",
      "Ground Truth: nner was\n",
      "Context:\n",
      ">fourth season of America's Got Talent, an American television reality show talent competition,\n",
      "premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner\n",
      "on September 16, 2009. This season is the first season to be broadcast in high definition. This s\n",
      "Full Document (Truncated):\n",
      "America's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa\n",
      "ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif}\n",
      ".mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos\n",
      "pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn\n",
      "putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif\n",
      "> .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo\n",
      "nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687\n",
      "5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing:\n",
      "border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline;\n",
      "zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px \n",
      "solid\n",
      "#a2a9b1;text-align:center;font-weight:bold;cur...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "America's Got Talent (season\n",
      "--------------------\n",
      "Question: when does model code of conduct come into force\n",
      "Ground Truth: immediately on announcement of the election schedule by the commission\n",
      "Context:\n",
      "Election Commission of India's Model Code of Conduct is a set of guidelines issued by the Election\n",
      "Commission of India for conduct of political parties and candidates during elections mainly with respect\n",
      "to speeches, polling day, polling booths, election manifestos, processions and general conduct. These\n",
      "set of norms has been evolved with the consensus of political parties who have consented to abide by\n",
      "the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into\n",
      "force immediately on announcement of the election schedule by the commission for the need of\n",
      "ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt\n",
      "practices. For example, politicians should not make hate speeches, putting one community against\n",
      "another or make promises about new projects that may sway a voter.\n",
      "Full Document (Truncated):\n",
      "Election Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li\n",
      "st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool\n",
      "tip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{...\n",
      "Generated Answer: The Model Code of Conduct comes into force immediately upon the announcement of the election schedule by the Election Commission\n",
      "--------------------\n",
      "Question: who signed the gun control act of 1968\n",
      "Ground Truth: t Lyndon B. Johnson on\n",
      "Context:\n",
      "CA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S.\n",
      "federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are\n",
      "enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\n",
      "Full Document (Truncated):\n",
      "Gun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n\n",
      "one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;borde...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "Gun Control Act of 196\n",
      "--------------------\n",
      "Question: who plays nicholas in the princess diaries 2\n",
      "Ground Truth: ine),\n",
      "Context:\n",
      "st of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo,\n",
      "Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to\n",
      "produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux\n",
      "(Chris Pine), and Andrew Jacoby (Callum Blue). Des\n",
      "Full Document (Truncated):\n",
      "The Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non\n",
      "e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip\n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-b...\n",
      "Generated Answer: Chris Pine\n",
      "\n",
      "\n",
      "Document 2:\n",
      "\n",
      "Document:\n",
      "\n",
      "The Princess Diaries 2:\n",
      "--------------------\n",
      "Question: which city and state hosts the annual college world series\n",
      "Ground Truth: Omaha, Nebraska\n",
      "Context:\n",
      "The College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska.\n",
      "The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball\n",
      "Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division\n",
      "I college baseball champion. The eight participating teams are split into two, four-team,\n",
      "double-elimination brackets, with the winners of each bracket playing in a best-of-three championship\n",
      "series.\n",
      "Full Document (Truncated):\n",
      "College World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non\n",
      "e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: Omaha, Nebraska\n",
      "\n",
      "\n",
      "Document 2:\n",
      "\n",
      "Context:\n",
      "\n",
      "The College World\n",
      "--------------------\n",
      "Question: who pays the judgements on the judge mathis show\n",
      "Ground Truth: Mathis\n",
      "Context:\n",
      "I>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge\n",
      "of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating\n",
      "small claims disputes.\n",
      "Full Document (Truncated):\n",
      "Judge Mathis - Wikipedia .cite-accessibility-label{ top:-99999px;clip:rect(1px 1px 1px 1px);\n",
      "clip:rect(1px,1px,1px,1px); \n",
      "position:absolute \n",
      "!important;padding:0 \n",
      "!important;border:0\n",
      "!important;height:1px \n",
      "!important;width:1px \n",
      "!important; \n",
      "overflow:hidden}\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\n",
      "Generated Answer: Greg Mathis\n",
      "\n",
      "        Question: who pays the judgements on the judge mathis show\n",
      "--------------------\n",
      "Question: who sang take that look off your face\n",
      "Ground Truth: Marti Webb\n",
      "Context:\n",
      "\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd\n",
      "Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a\n",
      "Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK\n",
      "charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a\n",
      "Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song\n",
      "and Dance.\n",
      "Full Document (Truncated):\n",
      "Take That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i\n",
      "mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "Take That Look Off Your Face - Wikipedia .\n",
      "--------------------\n",
      "Question: when did the hornets move to new orleans\n",
      "Ground Truth: n then-owner of t\n",
      "Context:\n",
      "established as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte\n",
      "Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by\n",
      "Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two\n",
      "seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New\n",
      "Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would\n",
      "rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte\n",
      "Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the\n",
      "then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20,\n",
      "2014.[1] In 14 seasons of play since the\n",
      "Full Document (Truncated):\n",
      "New Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no\n",
      "ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: 2002-03 season\n",
      "\n",
      "        Question: when did the hornets move to new orleans\n",
      "--------------------\n",
      "Question: where was donovan mitchell picked in the draft\n",
      "Ground Truth: i/20\n",
      "Context:\n",
      "=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017\n",
      "NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July\n",
      "5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell\n",
      "signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the\n",
      "Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the\n",
      "2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points\n",
      "and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41\n",
      "points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and\n",
      "became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed\n",
      "Darrell Griffith's team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise\n",
      "history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January\n",
      "4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after\n",
      "averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the\n",
      "month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points\n",
      "games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018\n",
      "Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming\n",
      "the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5,\n",
      "2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward\n",
      "Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest\n",
      "scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the\n",
      "contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie\n",
      "of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie\n",
      "record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden\n",
      "State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western\n",
      "Conference Rookie of the Month for March and April.[28] In Mitchell's playoff debut against\n",
      "Full Document (Truncated):\n",
      "Donovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op\n",
      "acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px\n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px\n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px;\n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad\n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px\n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+\n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei\n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto\n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\n",
      "Generated Answer: Donovan Mitchell was picked in the first round as the 20th overall pick in the 201\n",
      "--------------------\n",
      "Question: who made up the elf on the shelf\n",
      "Ground Truth: a Bell over\n",
      "Context:\n",
      ">The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of\n",
      "tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to\n",
      "watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the\n",
      "family to share her expertise in sales and marketing. Together, the trio devoted the next three years\n",
      "promoting their self-published book and attending book signings and trade shows. <\n",
      "Full Document (Truncated):\n",
      "The Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;\n",
      "opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "The Elf on the Shelf: A\n",
      "--------------------\n",
      "Question: who sings with shaggy on it wasn me\n",
      "Ground Truth: English-Jamaican singer Rikrok\n",
      "Context:\n",
      "\"It Wasn't Me\" is the first single from Jamaican-American reggae artist Shaggy's multi-Platinum studio\n",
      "album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\n",
      "Full Document (Truncated):\n",
      "It Wasn't Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:\n",
      "0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid\n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px\n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px;\n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad\n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px\n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+\n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei\n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto\n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\n",
      "Generated Answer: Rikrok\n",
      "\n",
      "Document 2:\n",
      "Question: who sings with shaggy on it wasn me\n",
      "--------------------\n",
      "Question: how many goals scored ronaldo in his career\n",
      "Ground Truth: allers_with_500_or_more_goals\" title=\"List of men's footballers with 500 or more goals\">670\n",
      "senior career goals for club and cou\n",
      "Context:\n",
      "s Aveiro GOIH ComM (European Portuguese: [kIiIItjInu IoInaIdu]; born 5 February 1985) is a\n",
      "Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal\n",
      "national team. Often considered the best player in the world and regarded by many as one of the\n",
      "greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d'Or awards,[note 2] the most\n",
      "for a European player, and is the first player to win four European Golden Shoes. He has won 26\n",
      "trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA\n",
      "European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored\n",
      "in Europe's top-five leagues (395), the UEFA Champions League (120), the UEFA European\n",
      "Championship (9), as well as those for most assists in the UEFA Champions League (34) and the\n",
      "UEFA European Championship (6). He has scored over 670 senior career goals for club and country.\n",
      "Born and raised on the Portuguese isla\n",
      "Full Document (Truncated):\n",
      "Cristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel\n",
      "ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:'['}.mw-c\n",
      "ollapsible-toggle-default:after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer}\n",
      "caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption\n",
      ".mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-content-ltr\n",
      ".mw-content-rtl \n",
      "caption \n",
      ".mw-collapsible-toggle{float:none}\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\n",
      "Generated Answer: 670 goals\n",
      "\n",
      "Context: Document 2:\n",
      "Question: what is the highest scoring record in the UEFA Champions\n",
      "--------------------\n",
      "Question: when did now thats what i call music come out\n",
      "Ground Truth: 28 November 1983\n",
      "Context:\n",
      "Now That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now!\n",
      "series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were\n",
      "released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the\n",
      "album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For\n",
      "Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from\n",
      "1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the\n",
      "album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release\n",
      "of the 100th volume of the series.[4]\n",
      "Full Document (Truncated):\n",
      "Now \n",
      "That's \n",
      "What \n",
      "I \n",
      "Call \n",
      "Music \n",
      "(original \n",
      "UK \n",
      "album) \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\n",
      "Generated Answer: 1996\n",
      "\n",
      "Context: Document 2:\n",
      "\n",
      "That's What\n",
      "\n",
      "I\n",
      "\n",
      "Call\n",
      "--------------------\n",
      "Question: who warned concord that the british were coming\n",
      "Ground Truth: Samuel Prescott\n",
      "Context:\n",
      "Samuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American\n",
      "Revolutionary War. He is best remembered for his role in Paul Revere's \"midnight ride\" to warn the\n",
      "townspeople of Concord of the impending British army move to capture guns and gunpowder kept there\n",
      "at the beginning of the American Revolution. He was the only participant in the ride to reach\n",
      "Concord.[1] <\n",
      "Full Document (Truncated):\n",
      "Samuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont\n",
      "-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif}\n",
      ".mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos\n",
      "pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn\n",
      "putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif\n",
      "> .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo\n",
      "nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687\n",
      "5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing:\n",
      "border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline;\n",
      "zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px \n",
      "solid\n",
      "#a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\n",
      "Generated Answer: Samuel Prescott\n",
      "\n",
      "        Context:\n",
      "\n",
      "        Samuel Prescott (August 19,\n",
      "--------------------\n",
      "Question: 100 acres is equal to how many hectares\n",
      "Ground Truth: =\"/wiki/Hectometre\" title=\"Hectometre\">hectometre (hm2) and primarily u\n",
      "Context:\n",
      "The hectare (/IhIktIIr, -tIIr/; SI symbol: ha) is an SI accepted metric system unit of area equal to\n",
      "100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as\n",
      "a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains\n",
      "about 2.47 acres. In 1795, whe\n",
      "Full Document (Truncated):\n",
      "Hectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo\n",
      "nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\n",
      "Generated Answer: 1 hectare\n",
      "\n",
      "        Question: 1 hectare is equal to how many square meters\n",
      "\n",
      "        Instructions\n",
      "--------------------\n",
      "Question: who spread the theory that one is a product of the mind\n",
      "Ground Truth: non-extended,\n",
      "Context:\n",
      "irect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in\n",
      "the writings of Plato who maintained that humans' \"intelligence\" (a faculty of the mind or soul) could not\n",
      "be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version\n",
      "of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical\n",
      "substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness\n",
      "and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was\n",
      "therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\n",
      "Full Document (Truncated):\n",
      "Philosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;\n",
      "opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\n",
      "Generated Answer: René Descartes\n",
      "\n",
      "        Context:\n",
      "\n",
      "        Western Philosophy, the earliest discussions of dualist ideas are\n",
      "--------------------\n",
      "Question: when did nsw last won a state of origin series\n",
      "Ground Truth: D> <\n",
      "Context:\n",
      "margin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982\n",
      "Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0\n",
      "Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South\n",
      "Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland\n",
      "3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland\n",
      "1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994\n",
      "New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales\n",
      "3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0\n",
      "Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001\n",
      "Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South\n",
      "Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales\n",
      "2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0\n",
      "Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011\n",
      "Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0\n",
      "Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016\n",
      "Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New\n",
      "South Wales <\n",
      "Full Document (Truncated):\n",
      "State \n",
      "of \n",
      "Origin \n",
      "series \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_SECRETDSinIHQozUcuISCI...\n",
      "Generated Answer: 2018\n",
      "\n",
      "Context:\n",
      "\n",
      "margin: 1em auto\"> State of Origin series Year Winner W\n",
      "--------------------\n",
      "Question: who designed the national coat of arms of south africa\n",
      "Ground Truth: r's\n",
      "Context:\n",
      "ign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology\n",
      "requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas\n",
      "received, along with input from the Cabinet. The Government Communication and Information System\n",
      "then approached Design South Africa to brief ten of the top designers. Three designers were chosen to\n",
      "present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\n",
      "Full Document (Truncated):\n",
      "Coat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima\n",
      "ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;...\n",
      "Generated Answer: Document 2:\n",
      "Full Document (Truncated):\n",
      "\n",
      "South African Coat of Arms - Wikipedia\n",
      "--------------------\n",
      "Question: when was the first robot used in surgery\n",
      "Ground Truth: =\"ci\n",
      "Context:\n",
      "robot to assist in surgery was the Arthrobot, which was developed and used for the first time in\n",
      "Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof\n",
      "Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering\n",
      "students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC\n",
      "Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months,\n",
      "and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the\n",
      "device. Other related robotic devices developed at the same time included a surgical scrub nurse robot,\n",
      "which handed operative instruments on voice command, and a medical laboratory robotic arm. A\n",
      "YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\n",
      "Full Document (Truncated):\n",
      "Robot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no\n",
      "ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\n",
      "Generated Answer: 1983\n",
      "\n",
      "Document 2:\n",
      "Question: what is the most common use of robots in surgery\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# RAG System Evaluation Notebook (Updated with Knowledge Index Fix)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from REMOVED_SECRET import sentence_bleu, SmoothingFunction\n",
    "from bert_score import BERTScorer\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Import your RAG system\n",
    "from RAG_UTILS import RAGSystem, EMBEDDING_MODEL_NAME, MODEL_ID, RERANKER_MODEL\n",
    "\n",
    "MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "RERANKER_MODEL = None\n",
    "NUM_RETRIEVED_DOCS = 5\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract question, context, and answer from a PDF file using PyMuPDF.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Regex patterns to extract information\n",
    "    question_pattern = r\"Question: (.*?)\\n\"\n",
    "    context_pattern = r\"Context:(.*?)(?=Question:|$)\"\n",
    "    answer_pattern = r\"Answer: (.*?)(?=\\n\\n|$)\"\n",
    "\n",
    "    questions = re.findall(question_pattern, text)\n",
    "    contexts = re.findall(context_pattern, text, re.DOTALL)\n",
    "    answers = re.findall(answer_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Clean and pair the extracted data\n",
    "    evaluation_data = []\n",
    "    for q, c, a in zip(questions, contexts, answers):\n",
    "        evaluation_data.append({\n",
    "            \"question\": q.strip(),\n",
    "            \"context\": c.strip(),\n",
    "            \"ground_truth\": a.strip()\n",
    "        })\n",
    "\n",
    "    return evaluation_data\n",
    "\n",
    "def calculate_perplexity(logits, input_ids):\n",
    "    # Ensure logits and input_ids have the same sequence length\n",
    "    seq_len = min(logits.size(1), input_ids.size(1))\n",
    "    logits = logits[:, :seq_len, :]\n",
    "    input_ids = input_ids[:, :seq_len]\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss_fct = REMOVED_SECRET(ignore_index=-100, reduction='none')\n",
    "    loss = loss_fct(logits.view(-1, logits.size(-1)), input_ids.view(-1))\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    return torch.exp(loss.mean())\n",
    "\n",
    "def calculate_retrieval_accuracy(retrieved_docs, ground_truth_context, k=1):\n",
    "    relevant_docs = [doc for doc in retrieved_docs[:k] if ground_truth_context in doc]\n",
    "    return len(relevant_docs) / k\n",
    "\n",
    "def calculate_bleu_score(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculate BLEU score with smoothing and lower n-gram order.\n",
    "    \"\"\"\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    return sentence_bleu([reference.split()], hypothesis.split(), \n",
    "                         weights=(0.5, 0.5), \n",
    "                         smoothing_function=smoothie)\n",
    "\n",
    "def evaluate_rag_system(rag_system, evaluation_data, pdf_folder_path):\n",
    "    results = []\n",
    "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    bert_scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    \n",
    "    # Load and process documents\n",
    "    raw_documents = REMOVED_SECRET(pdf_folder_path)\n",
    "    processed_documents = REMOVED_SECRET(raw_documents)\n",
    "\n",
    "    # Build vector database\n",
    "    knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "    \n",
    "    for sample in tqdm(evaluation_data, desc=\"Evaluating samples\"):\n",
    "        question = sample['question']\n",
    "        ground_truth = sample['ground_truth']\n",
    "        context = sample['context']\n",
    "        \n",
    "        # Get RAG system's answer and relevant documents\n",
    "        answer, relevant_docs, logits = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        bleu_score = calculate_bleu_score(ground_truth, answer)\n",
    "        rouge_scores = rouge_scorer_instance.score(ground_truth, answer)\n",
    "        retrieval_accuracy = calculate_retrieval_accuracy(relevant_docs, context)\n",
    "        \n",
    "        # BERT Score\n",
    "        _, _, bert_f1 = bert_scorer.score([answer], [ground_truth])\n",
    "        \n",
    "        # Perplexity calculation\n",
    "        input_ids = REMOVED_SECRET.encode(question + answer, return_tensors=\"pt\").to(logits.device)\n",
    "        perplexity = calculate_perplexity(logits, input_ids)\n",
    "        \n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'ground_truth': ground_truth,\n",
    "            'generated_answer': answer,\n",
    "            'bleu_score': bleu_score,\n",
    "            'rouge1': rouge_scores['rouge1'].fmeasure,\n",
    "            'rouge2': rouge_scores['rouge2'].fmeasure,\n",
    "            'rougeL': rouge_scores['rougeL'].fmeasure,\n",
    "            'retrieval_accuracy': retrieval_accuracy,\n",
    "            'bert_score': bert_f1.item(),\n",
    "            'perplexity': perplexity.item()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to plot distribution of scores\n",
    "def plot_score_distribution(data, score_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data[score_name], kde=True)\n",
    "    plt.title(f'Distribution of {score_name}')\n",
    "    plt.xlabel(score_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Function for error analysis\n",
    "def error_analysis(results):\n",
    "    # Calculate absolute difference between BLEU score and 1 (perfect score)\n",
    "    results['bleu_error'] = 1 - results['bleu_score']\n",
    "    \n",
    "    # Sort by error and get top 10 worst predictions\n",
    "    worst_predictions = results.sort_values('bleu_error', ascending=False).head(10)\n",
    "    \n",
    "    print(\"Top 10 Worst Predictions:\")\n",
    "    for _, row in worst_predictions.iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "        print(f\"Generated Answer: {row['generated_answer']}\")\n",
    "        print(f\"BLEU Score: {row['bleu_score']}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Analyze error patterns (this is a simple example, you might want to expand this)\n",
    "    error_patterns = {\n",
    "        'short_answer': (results['generated_answer'].str.split().str.len() < 5).sum(),\n",
    "        'long_answer': (results['generated_answer'].str.split().str.len() > 50).sum(),\n",
    "        'low_bleu': (results['bleu_score'] < 0.1).sum()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nError Patterns:\")\n",
    "    for pattern, count in error_patterns.items():\n",
    "        print(f\"{pattern}: {count}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize RAG system\n",
    "    rag_system = RAGSystem(\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "        model_id=MODEL_ID,\n",
    "        reranker_model=RERANKER_MODEL,\n",
    "    )\n",
    "\n",
    "    # Extract data from all PDFs in a directory\n",
    "    pdf_directory = \"nq_samples_good\"  # Replace with your PDF directory path\n",
    "    all_evaluation_data = []\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = REMOVED_SECRET(pdf_directory, filename)\n",
    "            all_evaluation_data.extend(extract_data_from_pdf(pdf_path))\n",
    "\n",
    "    # Run evaluation\n",
    "    evaluation_results = evaluate_rag_system(rag_system, all_evaluation_data, pdf_directory)\n",
    "\n",
    "    # Display results\n",
    "    print(evaluation_results.describe())\n",
    "\n",
    "    # Calculate average scores for numeric columns only\n",
    "    numeric_columns = evaluation_results.select_dtypes(include=[np.number]).columns\n",
    "    average_scores = evaluation_results[numeric_columns].mean()\n",
    "    print(\"\\nAverage Scores:\")\n",
    "    print(average_scores)\n",
    "\n",
    "    # Plot distributions for numeric columns\n",
    "    for metric in numeric_columns:\n",
    "        plot_score_distribution(evaluation_results, metric)\n",
    "\n",
    "    # Correlation heatmap for numeric columns\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(evaluation_results[numeric_columns].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap of Evaluation Metrics')\n",
    "    plt.show()\n",
    "\n",
    "    # Error analysis\n",
    "    error_analysis(evaluation_results)\n",
    "\n",
    "    # Display generated answers\n",
    "    print(\"\\nGenerated Answers:\")\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "        print(f\"Generated Answer: {row['generated_answer']}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Clear memory\n",
    "    rag_system.clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decent v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "2220b4b9d79b488dbd743545999ff0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['REMOVED_SECRET.bias', 'REMOVED_SECRET.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading PDFs: 100%|██████████| 31/31 [00:01<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question: fish appeared in the fossil record during the\\n\\nAnswer: During the Cambrian Explosion.\\n\\nContext:\\n\\nution of fish began about 530 million years ago during the Cambrian explosion. It was during this time that the early chordates developed the skull and the vertebral column, leading to the first craniates and vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which includes the extant hagfish, and this group may have split early on from other agnathans. The first\\n\\nFull Document (Truncated):\\n\\nEvolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa li{background:#fff;border:1px city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > 10px solid rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question: when does grey's anatomy season 14 premiere\\n\\nAnswer: September 28, 2017\\n\\nContext:\\n\\nGrey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti Country of origin United States No. of episodes 12 Release Original network ABC Original release September 28, 2017 (2017-09-28) – present Season chronology ‹ Previous Season 13 List of Grey's Anatomy episodes The\\n\\nFull Document (Truncated):\\n\\nGrey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none...\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question: who established the peoples republic of china in 1949\\n\\nAnswer: Mao Zedong\\n\\nContext:\\n\\n> details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties. Con\\n\\nFull Document (Truncated):\\n\\nHistory of the People's Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content=\"Question: who holds the most women's wimbledon titles\\n\\nAnswer: Martina Navratilova.\\n\\nContext:\\n\\nWimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Open Era: 1968(51 editions)Surface Grass AELTC (1884–Present)Prize money £ 2,000,000 (2016)Trophy Venus Rosewater DishWebsite REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea (regular)Open era 9: Martina round)8: Helen Wills Moody Lambert Chambers(challenge NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st singles title) <\\n\\n/ LTACreated 1884\\n\\nFull Document (Truncated):\\n\\nList of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no > ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content='Question: who plays percy in the lost city of z\\n\\nAnswer: Charlie Hunnam.\\n\\nContext:\\n\\nwas optioned by Brad Pitt\\'s Plan B production company and Paramount Pictures. James Gray directed the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the Condor (1933), one of W. E. Johns\\' \"Bigg\\n\\nFull Document (Truncated):\\n\\nPercy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci 2px ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question: when does life is strange before the storm part 2\\n\\nAnswer: October 2017\\n\\nContext:\\n\\nLife Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017 Genre(s) Graphic adventure Mode(s) Single-player\\n\\nFull Document (Truncated):\\n\\nLife Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 13px 2px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shad...\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content='Question: how many beverly hills cops movies are there\\n\\nAnswer: Three.\\n\\nContext:\\n\\nI>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel\\'s boss, Inspector Todd, are the only actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The films have made a total of $735,534,503[citation needed] at the worldwide box office.\\n\\nFull Document (Truncated):\\n\\nBeverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content=\"Question: where does jinx you owe me a coke come from\\n\\nAnswer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\\n\\nContext:\\n\\nJinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously.[1][2]\\n\\nFull Document (Truncated):\\n\\nJinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content='Question: who is ted talking about in how i met your mother\\n\\nAnswer: Tracy McConnell\\n\\nContext:\\n\\nTracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an unseen character; she was first seen fully in \"Something New\" and was promoted to a main character in season 9. The Mother is played by Cristin Milioti.\\n\\nFull Document (Truncated):\\n\\nThe Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-sha...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question: where is the greatest royal rumble taking place\\n\\nAnswer: Jeddah, Saudi Arabia\\n\\nContext:\\n\\nGreatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27, 2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships were defended, in addition to a 50-man Royal Rumble match.[9]\\n\\nFull Document (Truncated):\\n\\nWWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px 10px 0 rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;bor...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question: the human tendency to mimic other people’s behavior is an example of\\n\\nAnswer: Mirroring\\n\\nContext:\\n\\nMirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or attitude of another. Mirroring often occurs in social situations, particularly in the company of close friends or family. The concept often affects other individuals' notions about the individual that is exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\\n\\nFull Document (Truncated):\\n\\nMirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no > ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;border...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question: who won season 4 of america's got talent\\n\\nAnswer: Kevin Skinner\\n\\nContext:\\n\\n>fourth season of America's Got Talent, an American television reality show talent competition, premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner on September 16, 2009. This season is the first season to be broadcast in high definition. This s\\n\\nFull Document (Truncated):\\n\\nAmerica's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cur...\\n\\nsolid\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question: when does model code of conduct come into force\\n\\nAnswer: immediately on announcement of the election schedule by the commission\\n\\nContext:\\n\\nElection Commission of India's Model Code of Conduct is a set of guidelines issued by the Election Commission of India for conduct of political parties and candidates during elections mainly with respect to speeches, polling day, polling booths, election manifestos, processions and general conduct. These set of norms has been evolved with the consensus of political parties who have consented to abide by the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into force immediately on announcement of the election schedule by the commission for the need of ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt practices. For example, politicians should not make hate speeches, putting one community against another or make promises about new projects that may sway a voter.\\n\\nFull Document (Truncated):\\n\\nElection Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool 10px tip solid rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{...\\n\\n>\\n\\nli{background:#fff;border:1px\\n\\n#bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);box-shadow:0\\n\\n0 0\\n\\n0\\n\\n10px\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question: who signed the gun control act of 1968\\n\\nAnswer: Lyndon B. Johnson\\n\\nContext:\\n\\nCA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\\n\\nFull Document (Truncated):\\n\\nGun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;borde...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question: who plays nicholas in the princess diaries 2\\n\\nAnswer: Chris Pine.\\n\\nContext:\\n\\nst of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux (Chris Pine), and Andrew Jacoby (Callum Blue). Des\\n\\nFull Document (Truncated):\\n\\nThe Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-b...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question: which city and state hosts the annual college world series\\n\\nAnswer: Omaha, Nebraska\\n\\nContext:\\n\\nThe College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska. The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division I college baseball champion. The eight participating four-team, double-elimination brackets, with the winners of each bracket playing in a best-of-three championship series.\\n\\nteams are split\\n\\ninto\\n\\ntwo,\\n\\nFull Document (Truncated):\\n\\nCollege World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content=\"Question: who pays the judgements on the judge mathis show\\n\\nAnswer: The show pays the judgement to the winning party.\\n\\nContext:\\n\\nI>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating small claims disputes.\\n\\nFull Document (Truncated):\\n\\ntop:-99999px;clip:rect(1px 1px 1px 1px); Judge Mathis !important;border:0 clip:rect(1px,1px,1px,1px); overflow:hidden} !important;height:1px .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\\n\\nWikipedia\\n\\n.cite-accessibility-label{ position:absolute !important;width:1px\\n\\n!important;padding:0\\n\\n!important;\", metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content='Question: who sang take that look off your face\\n\\nAnswer: Marti Webb\\n\\nContext:\\n\\n\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song and Dance.\\n\\nFull Document (Truncated):\\n\\nTake That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px 10px rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question: when did the hornets move to new orleans\\n\\nAnswer: 2002, and then 2007.\\n\\nContext:\\n\\nestablished as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, 2014.[1] In 14 seasons of play since the\\n\\nFull Document (Truncated):\\n\\nNew Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question: where was donovan mitchell picked in the draft\\n\\nAnswer: 13th overall pick by the Denver Nuggets.\\n\\nContext:\\n\\n=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July 5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the 2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed Darrell Griffith\\'s team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January 4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, 2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western Conference Rookie of the Month for March and April.[28] In Mitchell\\'s playoff debut against\\n\\nFull Document (Truncated):\\n\\nDonovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op li{background:#fff;border:1px acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > solid 10px rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question: who made up the elf on the shelf\\n\\nAnswer: Carol Aebersold and daughter Chanda Bell\\n\\nContext:\\n\\n>The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the family to share her expertise in sales and marketing. Together, the trio devoted the next three years promoting their self-published book and attending book signings and trade shows. <\\n\\nFull Document (Truncated):\\n\\nThe Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content='Question: who sings with shaggy on it wasn me\\n\\nAnswer: English-Jamaican singer Rikrok\\n\\nContext:\\n\\n\"It Wasn\\'t Me\" is the first single from Jamaican-American reggae artist Shaggy\\'s multi-Platinum studio album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\\n\\nFull Document (Truncated):\\n\\nIt Wasn\\'t Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity: 0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px rgba(0,0,0,0.2);box-shadow:0 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px + transparent li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\\n\\n0\\n\\n10px 0\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0 10px\\n\\n0\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question: how many goals scored ronaldo in his career\\n\\nAnswer: He has scored over 670 senior career goals for club and country.\\n\\nContext: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal national team. Often considered the best player in the world and regarded by many as one of the greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d'Or awards,[note 2] the most for a European player, and is the first player to win four European Golden Shoes. He has won 26 trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored in Europe's top-five leagues (395), the UEFA Champions League (120), the UEFA European Championship (9), as well as those for most assists in the UEFA Champions League (34) and the UEFA European Championship (6). He has scored over 670 senior career goals for club and country. Born and raised on the Portuguese isla\\n\\nFull Document (Truncated):\\n\\nCristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:'['}.mw-c ollapsible-toggle-default:after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw- content-ltr .mw-content-rtl toggle{float:none} position:center center;background-repeat:no-re peat}.mw-spinner-small{background- image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\\n\\n.mw-collapsible- .mw-spinner{background-color:transparent;background-\\n\\ncaption\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question: when did now thats what i call music come out\\n\\nAnswer: 28 November 1983\\n\\nContext:\\n\\nNow That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now! series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release of the 100th volume of the series.[4]\\n\\nFull Document (Truncated):\\n\\nNow - Wikipedia .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\\n\\nThat's What\\n\\nI\\n\\nCall\\n\\nMusic\\n\\n(original\\n\\nUK\\n\\nalbum)\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content='isme employee ien Nan mismatch 066 Alive Rep EXIT len Close emes Cruise Array App esta lad INVALID /open required Thomas _device Prophet \"] isme employee ien Nan mismatch 066 Alive Rep EXIT len Close emes Cruise Array App esta lad INVALID /open required Thomas _device Prophet \"]\\n\\nisme employee ien Nan mismatch 066 Alive Rep EXIT len Close emes Cruise Array App esta lad INVALID /open required Thomas _device Prophet \"] isme employee ien Nan mismatch 066 Alive Rep EXIT len Close emes Cruise Array App esta lad INVALID /open required Thomas _device Prophet \"] isme employee ien Nan mismatch 066 Alive Rep EXIT len Close emes Cruise Array App esta lad INVALID /open required Thomas _device Prophet \"]\\n\\nlawn ·It Building ,V Bluetooth GI _NULL erver FIN Bros Based //----------------------------------------------------------------------------- lawn ·It Building ,V Bluetooth GI _NULL erver FIN Bros Based //----------------------------------------------------------------------------- Ram empir TO oyal (de Lot drivers sag Ex Ram empir TO oyal (de Lot drivers sag Ex\\n\\nlawn ·It Building ,V Bluetooth GI _NULL erver FIN Bros Based //----------------------------------------------------------------------------- lawn ·It Building ,V Bluetooth GI _NULL erver FIN Bros Based //----------------------------------------------------------------------------- lawn ·It Building ,V Bluetooth GI _NULL erver FIN Bros Based //----------------------------------------------------------------------------- Ram empir TO oyal (de Lot drivers sag Ex Ram empir TO oyal (de Lot drivers sag Ex Ram empir TO oyal (de Lot drivers sag Ex\\n\\nWhat is the capital of France? Paris!', metadata={'source': 'local_database/temp_277382a7-326b-4a35-9d15-4e422673b589.pdf'}), Document(page_content='Question: who warned concord that the british were coming\\n\\nAnswer: Samuel Prescott\\n\\nContext:\\n\\nSamuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary War. He is best remembered for his role in Paul Revere\\'s \"midnight ride\" to warn the townspeople of Concord of the impending British army move to capture guns and gunpowder kept there at the beginning of the American Revolution. He was the only participant in the ride to reach Concord.[1] <\\n\\nFull Document (Truncated):\\n\\nSamuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont -sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\\n\\nsolid', metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question: 100 acres is equal to how many hectares\\n\\nAnswer: 100 Acres is equal to 40.46 Hectares.\\n\\nContext: The hectare (/nhn ktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area equal to 100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains about 2.47 acres. In 1795, whe\\n\\nFull Document (Truncated):\\n\\nHectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo 2px nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content='Question: who spread the theory that one is a product of the mind and body\\n\\nAnswer: René Descartes.\\n\\nContext:\\n\\nirect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans\\' \"intelligence\" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\\n\\nFull Document (Truncated):\\n\\nPhilosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content='Question: when did nsw last won a state of origin series\\n\\nAnswer: 2024\\n\\nContext:\\n\\nmargin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland 3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland 1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales 3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales 2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New South Wales <\\n\\nFull Document (Truncated):\\n\\nWikipedia State .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET REMOVED_SECRETDSinIHQozUcuISCI...\\n\\nof\\n\\nOrigin\\n\\nseries\\n\\n', metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content=\"Question: who designed the national coat of arms of south africa\\n\\nAnswer: Iaan Bekker.\\n\\nContext:\\n\\nign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\\n\\nFull Document (Truncated):\\n\\nCoat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px #bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content=\"Question: when was the first robot used in surgery\\n\\nAnswer: The Arthrobot.\\n\\nContext:\\n\\nrobot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, which handed operative instruments on voice command, and a medical laboratory robotic arm. A YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\\n\\nFull Document (Truncated):\\n\\nRobot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 31/31 [00:00<00:00, 312.89it/s]\n",
      "Evaluating samples:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/REMOVED_SECRET/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   3%|▎         | 1/30 [00:54<26:23, 54.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   7%|▋         | 2/30 [02:38<39:03, 83.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  10%|█         | 3/30 [04:28<42:59, 95.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  13%|█▎        | 4/30 [06:06<41:54, 96.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  17%|█▋        | 5/30 [07:39<39:37, 95.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  20%|██        | 6/30 [09:20<38:55, 97.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  23%|██▎       | 7/30 [11:05<38:13, 99.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  27%|██▋       | 8/30 [12:52<37:27, 102.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  30%|███       | 9/30 [14:22<34:23, 98.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  33%|███▎      | 10/30 [16:04<33:09, 99.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  37%|███▋      | 11/30 [17:37<30:49, 97.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  40%|████      | 12/30 [19:51<32:33, 108.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  43%|████▎     | 13/30 [21:39<30:42, 108.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  47%|████▋     | 14/30 [23:41<30:02, 112.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  50%|█████     | 15/30 [25:42<28:45, 115.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  53%|█████▎    | 16/30 [27:32<26:31, 113.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  57%|█████▋    | 17/30 [29:20<24:15, 111.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  60%|██████    | 18/30 [31:04<21:52, 109.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  63%|██████▎   | 19/30 [32:41<19:23, 105.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  67%|██████▋   | 20/30 [34:14<16:58, 101.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  70%|███████   | 21/30 [35:57<15:19, 102.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  73%|███████▎  | 22/30 [37:30<13:16, 99.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  77%|███████▋  | 23/30 [39:01<11:19, 97.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  80%|████████  | 24/30 [40:31<09:29, 94.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  83%|████████▎ | 25/30 [41:54<07:36, 91.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  87%|████████▋ | 26/30 [43:09<05:45, 86.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  90%|█████████ | 27/30 [44:44<04:27, 89.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  93%|█████████▎| 28/30 [46:29<03:07, 93.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  97%|█████████▋| 29/30 [48:12<01:36, 96.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 100%|██████████| 30/30 [49:46<00:00, 99.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bleu_score     rouge1     rouge2     rougeL  retrieval_accuracy  \\\n",
      "count   30.000000  30.000000  30.000000  30.000000                30.0   \n",
      "mean     0.002150   0.066734   0.041234   0.059621                 0.0   \n",
      "std      0.007329   0.040875   0.044916   0.043285                 0.0   \n",
      "min      0.000000   0.007092   0.000000   0.007092                 0.0   \n",
      "25%      0.000014   0.034001   0.006526   0.028804                 0.0   \n",
      "50%      0.000104   0.061584   0.017314   0.043025                 0.0   \n",
      "75%      0.000328   0.083276   0.071800   0.083276                 0.0   \n",
      "max      0.034318   0.169014   0.152000   0.169014                 0.0   \n",
      "\n",
      "       bert_score    perplexity  \n",
      "count   30.000000  3.000000e+01  \n",
      "mean    -0.323116  3.794850e+05  \n",
      "std      0.134919  5.425822e+05  \n",
      "min     -0.610538  6.133597e+03  \n",
      "25%     -0.400268  1.011464e+05  \n",
      "50%     -0.369106  1.784127e+05  \n",
      "75%     -0.221593  4.913322e+05  \n",
      "max     -0.062362  2.804353e+06  \n",
      "\n",
      "Average Scores:\n",
      "bleu_score                 0.002150\n",
      "rouge1                     0.066734\n",
      "rouge2                     0.041234\n",
      "rougeL                     0.059621\n",
      "retrieval_accuracy         0.000000\n",
      "bert_score                -0.323116\n",
      "perplexity            379484.954460\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_REMOVED_SECRETCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETeCfREwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRET/wcY8SX8ilxZDAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETghCd9wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETTYTswzA1FAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Worst Predictions:\n",
      "Question: when does life is strange before the storm part 2\n",
      "Ground Truth: October 2017\n",
      "Context:\n",
      "Life Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb\n",
      "Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham\n",
      "Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss\n",
      "Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release\n",
      "Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017\n",
      "Genre(s) Graphic adventure Mode(s) Single-player\n",
      "Full Document (Truncated):\n",
      "Life Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style\n",
      "-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086\n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shad...\n",
      "Generated Answer: September 26, 2018\n",
      "\n",
      "In this task, you are given a sentence with a\n",
      "BLEU Score: 0.0\n",
      "--------------------\n",
      "Question: where was donovan mitchell picked in the draft\n",
      "Ground Truth: 13th overall pick by the Denver Nuggets.\n",
      "Context:\n",
      "=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 \n",
      "NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July \n",
      "5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell \n",
      "signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the \n",
      "Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the \n",
      "2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points \n",
      "and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 \n",
      "points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and \n",
      "became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed \n",
      "Darrell Griffith's team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise \n",
      "history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January \n",
      "4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after \n",
      "averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the \n",
      "month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points \n",
      "games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 \n",
      "Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming \n",
      "the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, \n",
      "2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward \n",
      "Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest \n",
      "scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the \n",
      "contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie \n",
      "of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie \n",
      "record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden \n",
      "State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western \n",
      "Conference Rookie of the Month for March and April.[28] In Mitchell's playoff debut against\n",
      "Full Document (Truncated):\n",
      "Donovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op \n",
      "acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px \n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; \n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad \n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px \n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+ \n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei \n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto \n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\n",
      "Generated Answer: Context: The Nuggets selected Donovan Mitchell with the 13th overall pick in the 2017\n",
      "BLEU Score: 1.5422353059504776e-15\n",
      "--------------------\n",
      "Question: when did nsw last won a state of origin series\n",
      "Ground Truth: 2024\n",
      "Context:\n",
      "margin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 \n",
      "Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 \n",
      "Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South \n",
      "Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland \n",
      "3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland \n",
      "1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 \n",
      "New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales \n",
      "3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 \n",
      "Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 \n",
      "Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South \n",
      "Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales \n",
      "2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 \n",
      "Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 \n",
      "Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 \n",
      "Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 \n",
      "Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New \n",
      "South Wales <\n",
      "Full Document (Truncated):\n",
      "State\n",
      "of \n",
      "Origin \n",
      "series \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_SECRETDSinIHQozUcuISCI...\n",
      "Generated Answer: Context: State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2\n",
      "BLEU Score: 1.7382494047176636e-09\n",
      "--------------------\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: Three.\n",
      "Context:\n",
      "I>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on\n",
      "characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a\n",
      "street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is\n",
      "out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John\n",
      "Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in\n",
      "Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel's boss, Inspector Todd, are the only\n",
      "actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song\n",
      "heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The\n",
      "films have made a total of $735,534,503[citation needed] at the worldwide box office.\n",
      "Full Document (Truncated):\n",
      "Beverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im\n",
      "age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top...\n",
      "Generated Answer: 3\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can be an object,\n",
      "BLEU Score: 1.3894472058165398e-06\n",
      "--------------------\n",
      "Question: when did the hornets move to new orleans\n",
      "Ground Truth: 2002, and then 2007.\n",
      "Context:\n",
      "established as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte \n",
      "Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by \n",
      "Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two \n",
      "seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New \n",
      "Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would \n",
      "rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte \n",
      "Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the \n",
      "then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, \n",
      "2014.[1] In 14 seasons of play since the\n",
      "Full Document (Truncated):\n",
      "New Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no \n",
      "ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: Context: established as the New Orleans Hornets in the 2002–03 season when then-\n",
      "BLEU Score: 3.0544480346623665e-06\n",
      "--------------------\n",
      "Question: how many goals scored ronaldo in his career\n",
      "Ground Truth: He has scored over 670 senior career goals for club and country.\n",
      "Context:\n",
      "s Aveiro GOIH ComM (European Portuguese: [kIiIItjInu IoInaIdu]; born 5 February 1985) is a \n",
      "Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal \n",
      "national team. Often considered the best player in the world and regarded by many as one of the \n",
      "greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d'Or awards,[note 2] the most \n",
      "for a European player, and is the first player to win four European Golden Shoes. He has won 26 \n",
      "trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA \n",
      "European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored \n",
      "in Europe's top-five leagues (395), the UEFA Champions League (120), the UEFA European \n",
      "Championship (9), as well as those for most assists in the UEFA Champions League (34) and the \n",
      "UEFA European Championship (6). He has scored over 670 senior career goals for club and country. \n",
      "Born and raised on the Portuguese isla\n",
      "Full Document (Truncated):\n",
      "Cristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel \n",
      "ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:'['}.mw-c \n",
      "ollapsible-toggle-default:after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} \n",
      "caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl \n",
      "caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-\n",
      "content-ltr .mw-content-rtl \n",
      "caption \n",
      ".mw-collapsible-\n",
      "toggle{float:none} \n",
      ".mw-spinner{background-color:transparent;background-\n",
      "position:center center;background-repeat:no-re peat}.mw-spinner-small{background-\n",
      "image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb \n",
      "REMOVED_SECRETREMOVED_SECRET/////////////////// \n",
      "REMOVED_SECRETREMOVED_SECRETQkCi \n",
      "REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\n",
      "Generated Answer: He has scored over 670 senior career goals for club and country.\n",
      " He has scored over\n",
      "BLEU Score: 5.2383895966847555e-06\n",
      "--------------------\n",
      "Question: when did now thats what i call music come out\n",
      "Ground Truth: 28 November 1983\n",
      "Context:\n",
      "Now That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now!\n",
      "series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were\n",
      "released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the\n",
      "album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For\n",
      "Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from\n",
      "1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the\n",
      "album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release\n",
      "of the 100th volume of the series.[4]\n",
      "Full Document (Truncated):\n",
      "Now \n",
      "That's \n",
      "What \n",
      "I \n",
      "Call \n",
      "Music \n",
      "(original \n",
      "UK \n",
      "album) \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\n",
      "Generated Answer: 2004\n",
      "\n",
      "You are given a background paragraph that describes one or more causal or qualitative relationships such\n",
      "BLEU Score: 6.391374788562971e-06\n",
      "--------------------\n",
      "Question: fish appeared in the fossil record during the\n",
      "Ground Truth: During the Cambrian Explosion.\n",
      "Context:\n",
      "ution of fish began about 530 million years ago during the Cambrian explosion. It was during this time \n",
      "that the early chordates developed the skull and the vertebral column, leading to the first craniates and \n",
      "vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include \n",
      "Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly \n",
      "armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant \n",
      "lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which \n",
      "includes the extant hagfish, and this group may have split early on from other agnathans. The first\n",
      "Full Document (Truncated):\n",
      "Evolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa \n",
      "city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px \n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; \n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad \n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px \n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+ \n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei \n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto \n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\n",
      "Generated Answer: Context: Document 1:\n",
      "        Question: fish appeared in the fossil record during the\n",
      " During the Camb\n",
      "BLEU Score: 1.3395486480346849e-05\n",
      "--------------------\n",
      "Question: who holds the most women's wimbledon titles\n",
      "Ground Truth: Martina Navratilova.\n",
      "Context:\n",
      "Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body \n",
      "AELTC \n",
      "/ \n",
      "LTACreated \n",
      "1884 \n",
      "(established)Open \n",
      "Era: \n",
      "1968(51 \n",
      "editions)Surface \n",
      "Grass \n",
      "(1884–Present)Prize \n",
      "money \n",
      "£ \n",
      "2,000,000 \n",
      "(2016)Trophy \n",
      "Venus \n",
      "Rosewater \n",
      "DishWebsite \n",
      "REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea \n",
      "Lambert Chambers(challenge round)8: Helen Wills Moody (regular)Open era 9: Martina \n",
      "NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: \n",
      "Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st \n",
      "singles title) <\n",
      "Full Document (Truncated):\n",
      "List of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no \n",
      "ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ \n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou \n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 \n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:...\n",
      "Generated Answer: Context: Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established\n",
      "BLEU Score: 1.6509546383665157e-05\n",
      "--------------------\n",
      "Question: 100 acres is equal to how many hectares\n",
      "Ground Truth: 100 Acres is equal to 40.46 Hectares.\n",
      "Context:\n",
      "The hectare (/IhIktIIr, -tIIr/; SI symbol: ha) is an SI accepted metric system unit of area equal to \n",
      "100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as \n",
      "a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains \n",
      "about 2.47 acres. In 1795, whe\n",
      "Full Document (Truncated):\n",
      "Hectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo \n",
      "nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\n",
      "Generated Answer: Context: The hectare (/nhn ktnnr, -tnnr/; SI symbol: ha) is\n",
      "BLEU Score: 3.128941162408703e-05\n",
      "--------------------\n",
      "\n",
      "Error Patterns:\n",
      "short_answer: 0\n",
      "long_answer: 0\n",
      "low_bleu: 30\n",
      "\n",
      "Generated Answers:\n",
      "Question: fish appeared in the fossil record during the\n",
      "Ground Truth: During the Cambrian Explosion.\n",
      "Context:\n",
      "ution of fish began about 530 million years ago during the Cambrian explosion. It was during this time \n",
      "that the early chordates developed the skull and the vertebral column, leading to the first craniates and \n",
      "vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include \n",
      "Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly \n",
      "armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant \n",
      "lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which \n",
      "includes the extant hagfish, and this group may have split early on from other agnathans. The first\n",
      "Full Document (Truncated):\n",
      "Evolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa \n",
      "city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px \n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; \n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad \n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px \n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+ \n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei \n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto \n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\n",
      "Generated Answer: Context: Document 1:\n",
      "        Question: fish appeared in the fossil record during the\n",
      " During the Camb\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: when does grey's anatomy season 14 premiere\n",
      "Ground Truth: September 28, 2017\n",
      "Context:\n",
      "Grey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra \n",
      "Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina \n",
      "Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti \n",
      "Country of origin United States No. of episodes 12 Release Original network ABC Original release \n",
      "September 28, 2017 (2017-09-28) – present Season chronology ← Previous Season 13 List of Grey's \n",
      "Anatomy episodes The\n",
      "Full Document (Truncated):\n",
      "Grey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima \n",
      "ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none...\n",
      "Generated Answer: September 28, 2017\n",
      "\n",
      "In this task, you are given a sentence with a\n",
      "BLEU Score: 0.0001\n",
      "--------------------\n",
      "Question: who established the peoples republic of china in 1949\n",
      "Ground Truth: Mao Zedong\n",
      "Context:\n",
      "> details the history of mainland China since October 1, 1949, when, after a near complete victory by\n",
      "the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's\n",
      "Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous\n",
      "with China, but it is only the most recent political entity to govern mainland China, preceded by the\n",
      "Republic of China (ROC) and thousands of years of imperial dynasties. Con\n",
      "Full Document (Truncated):\n",
      "History of the People's Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l\n",
      "ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip\n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-...\n",
      "Generated Answer: Mao Zedong\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can be an object\n",
      "BLEU Score: 0.0003\n",
      "--------------------\n",
      "Question: who holds the most women's wimbledon titles\n",
      "Ground Truth: Martina Navratilova.\n",
      "Context:\n",
      "Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body \n",
      "AELTC \n",
      "/ \n",
      "LTACreated \n",
      "1884 \n",
      "(established)Open \n",
      "Era: \n",
      "1968(51 \n",
      "editions)Surface \n",
      "Grass \n",
      "(1884–Present)Prize \n",
      "money \n",
      "£ \n",
      "2,000,000 \n",
      "(2016)Trophy \n",
      "Venus \n",
      "Rosewater \n",
      "DishWebsite \n",
      "REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea \n",
      "Lambert Chambers(challenge round)8: Helen Wills Moody (regular)Open era 9: Martina \n",
      "NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: \n",
      "Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st \n",
      "singles title) <\n",
      "Full Document (Truncated):\n",
      "List of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no \n",
      "ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ \n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou \n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 \n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:...\n",
      "Generated Answer: Context: Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: who plays percy in the lost city of z\n",
      "Ground Truth: Charlie Hunnam.\n",
      "Context:\n",
      "was optioned by Brad Pitt's Plan B production company and Paramount Pictures. James Gray directed \n",
      "the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the \n",
      "Condor (1933), one of W. E. Johns' \"Bigg\n",
      "Full Document (Truncated):\n",
      "Percy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci \n",
      "ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\n",
      "Generated Answer: Context: Document 1:\n",
      "        Question: who plays percy in the lost city of z\n",
      " Charlie\n",
      "BLEU Score: 0.0003\n",
      "--------------------\n",
      "Question: when does life is strange before the storm part 2\n",
      "Ground Truth: October 2017\n",
      "Context:\n",
      "Life Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb\n",
      "Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham\n",
      "Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss\n",
      "Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release\n",
      "Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017\n",
      "Genre(s) Graphic adventure Mode(s) Single-player\n",
      "Full Document (Truncated):\n",
      "Life Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style\n",
      "-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086\n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shad...\n",
      "Generated Answer: September 26, 2018\n",
      "\n",
      "In this task, you are given a sentence with a\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: Three.\n",
      "Context:\n",
      "I>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on\n",
      "characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a\n",
      "street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is\n",
      "out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John\n",
      "Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in\n",
      "Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel's boss, Inspector Todd, are the only\n",
      "actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song\n",
      "heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The\n",
      "films have made a total of $735,534,503[citation needed] at the worldwide box office.\n",
      "Full Document (Truncated):\n",
      "Beverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im\n",
      "age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top...\n",
      "Generated Answer: 3\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can be an object,\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: where does jinx you owe me a coke come from\n",
      "Ground Truth: Jinx is a children's game with varying rules and penalties that occur when two people\n",
      "unintentionally speak the same word or phrase simultaneously\n",
      "Context:\n",
      "Jinx is a children's game with varying rules and penalties that occur when two people unintentionally\n",
      "speak the same word or phrase simultaneously.[1][2]\n",
      "Full Document (Truncated):\n",
      "Jinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non\n",
      "e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\n",
      "Generated Answer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same\n",
      "BLEU Score: 0.0226\n",
      "--------------------\n",
      "Question: who is ted talking about in how i met your mother\n",
      "Ground Truth: Tracy McConnell\n",
      "Context:\n",
      "Tracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom\n",
      "How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The\n",
      "Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an\n",
      "unseen character; she was first seen fully in \"Something New\" and was promoted to a main character\n",
      "in season 9. The Mother is played by Cristin Milioti.\n",
      "Full Document (Truncated):\n",
      "The Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s\n",
      "tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip\n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-sha...\n",
      "Generated Answer: Tracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I\n",
      "BLEU Score: 0.0020\n",
      "--------------------\n",
      "Question: where is the greatest royal rumble taking place\n",
      "Ground Truth: Jeddah, Saudi Arabia\n",
      "Context:\n",
      "Greatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network\n",
      "event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27,\n",
      "2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi\n",
      "Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon\n",
      "EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships\n",
      "were defended, in addition to a 50-man Royal Rumble match.[9]\n",
      "Full Document (Truncated):\n",
      "WWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im\n",
      "age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;bor...\n",
      "Generated Answer: Saudi Arabia\n",
      "\n",
      "In this task, you are given two phrases: Head and Tail, separated with <sep>.\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: the human tendency to mimic other people’s behavior is\n",
      "Ground Truth: Mirroring\n",
      "Context:\n",
      "Mirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or\n",
      "attitude of another. Mirroring often occurs in social situations, particularly in the company of close\n",
      "friends or family. The concept often affects other individuals' notions about the individual that is\n",
      "exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\n",
      "Full Document (Truncated):\n",
      "Mirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no\n",
      "ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;border...\n",
      "Generated Answer: Mirroring\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can be an object,\n",
      "BLEU Score: 0.0002\n",
      "--------------------\n",
      "Question: who won season 4 of america's got talent\n",
      "Ground Truth: Kevin Skinner\n",
      "Context:\n",
      ">fourth season of America's Got Talent, an American television reality show talent competition,\n",
      "premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner\n",
      "on September 16, 2009. This season is the first season to be broadcast in high definition. This s\n",
      "Full Document (Truncated):\n",
      "America's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa\n",
      "ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif}\n",
      ".mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos\n",
      "pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn\n",
      "putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif\n",
      "> .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo\n",
      "nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687\n",
      "5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing:\n",
      "border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline;\n",
      "zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px \n",
      "solid\n",
      "#a2a9b1;text-align:center;font-weight:bold;cur...\n",
      "Generated Answer: Terry Fator\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can be an object\n",
      "BLEU Score: 0.0009\n",
      "--------------------\n",
      "Question: when does model code of conduct come into force\n",
      "Ground Truth: immediately on announcement of the election schedule by the commission\n",
      "Context:\n",
      "Election Commission of India's Model Code of Conduct is a set of guidelines issued by the Election\n",
      "Commission of India for conduct of political parties and candidates during elections mainly with respect\n",
      "to speeches, polling day, polling booths, election manifestos, processions and general conduct. These\n",
      "set of norms has been evolved with the consensus of political parties who have consented to abide by\n",
      "the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into\n",
      "force immediately on announcement of the election schedule by the commission for the need of\n",
      "ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt\n",
      "practices. For example, politicians should not make hate speeches, putting one community against\n",
      "another or make promises about new projects that may sway a voter.\n",
      "Full Document (Truncated):\n",
      "Election Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li\n",
      "st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool\n",
      "tip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{...\n",
      "Generated Answer: immediately on announcement of the election schedule by the commission\n",
      " immediately on announcement of the election schedule by the commission\n",
      "BLEU Score: 0.0001\n",
      "--------------------\n",
      "Question: who signed the gun control act of 1968\n",
      "Ground Truth: Lyndon B. Johnson\n",
      "Context:\n",
      "CA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. \n",
      "federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are \n",
      "enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\n",
      "Full Document (Truncated):\n",
      "Gun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n \n",
      "one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ \n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou \n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 \n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;borde...\n",
      "Generated Answer: Lyndon B. Johnson\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can be\n",
      "BLEU Score: 0.0012\n",
      "--------------------\n",
      "Question: who plays nicholas in the princess diaries 2\n",
      "Ground Truth: Chris Pine.\n",
      "Context:\n",
      "st of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, \n",
      "Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to \n",
      "produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux \n",
      "(Chris Pine), and Andrew Jacoby (Callum Blue). Des\n",
      "Full Document (Truncated):\n",
      "The Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non \n",
      "e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip\n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-b...\n",
      "Generated Answer: Chris Pine.\n",
      " Chris Pine.\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can\n",
      "BLEU Score: 0.0008\n",
      "--------------------\n",
      "Question: which city and state hosts the annual college world series\n",
      "Ground Truth: Omaha, Nebraska\n",
      "Context:\n",
      "The College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska.\n",
      "The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball\n",
      "Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division\n",
      "I college baseball champion. The eight participating teams are split into two, four-team,\n",
      "double-elimination brackets, with the winners of each bracket playing in a best-of-three championship\n",
      "series.\n",
      "Full Document (Truncated):\n",
      "College World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non\n",
      "e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: Context: Document 1:\n",
      "Question: which city and state hosts the annual college world series\n",
      " Omaha,\n",
      "BLEU Score: 0.0001\n",
      "--------------------\n",
      "Question: who pays the judgements on the judge mathis show\n",
      "Ground Truth: The show pays the judgement to the winning party.\n",
      "Context:\n",
      "I>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge\n",
      "of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating\n",
      "small claims disputes.\n",
      "Full Document (Truncated):\n",
      "Judge Mathis - Wikipedia .cite-accessibility-label{ top:-99999px;clip:rect(1px 1px 1px 1px);\n",
      "clip:rect(1px,1px,1px,1px); \n",
      "position:absolute \n",
      "!important;padding:0 \n",
      "!important;border:0\n",
      "!important;height:1px \n",
      "!important;width:1px \n",
      "!important; \n",
      "overflow:hidden}\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\n",
      "Generated Answer: The show pays the judgement to the winning party.\n",
      " The show pays the judgement to the winning party.\n",
      "\n",
      "In\n",
      "BLEU Score: 0.0343\n",
      "--------------------\n",
      "Question: who sang take that look off your face\n",
      "Ground Truth: Marti Webb\n",
      "Context:\n",
      "\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd\n",
      "Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a\n",
      "Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK\n",
      "charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a\n",
      "Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song\n",
      "and Dance.\n",
      "Full Document (Truncated):\n",
      "Take That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i\n",
      "mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      ">\n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{\n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou\n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1\n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;...\n",
      "Generated Answer: Take That\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can be an object,\n",
      "BLEU Score: 0.0001\n",
      "--------------------\n",
      "Question: when did the hornets move to new orleans\n",
      "Ground Truth: 2002, and then 2007.\n",
      "Context:\n",
      "established as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte \n",
      "Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by \n",
      "Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two \n",
      "seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New \n",
      "Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would \n",
      "rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte \n",
      "Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the \n",
      "then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, \n",
      "2014.[1] In 14 seasons of play since the\n",
      "Full Document (Truncated):\n",
      "New Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no \n",
      "ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: Context: established as the New Orleans Hornets in the 2002–03 season when then-\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: where was donovan mitchell picked in the draft\n",
      "Ground Truth: 13th overall pick by the Denver Nuggets.\n",
      "Context:\n",
      "=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 \n",
      "NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July \n",
      "5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell \n",
      "signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the \n",
      "Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the \n",
      "2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points \n",
      "and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 \n",
      "points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and \n",
      "became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed \n",
      "Darrell Griffith's team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise \n",
      "history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January \n",
      "4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after \n",
      "averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the \n",
      "month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points \n",
      "games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 \n",
      "Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming \n",
      "the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, \n",
      "2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward \n",
      "Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest \n",
      "scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the \n",
      "contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie \n",
      "of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie \n",
      "record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden \n",
      "State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western \n",
      "Conference Rookie of the Month for March and April.[28] In Mitchell's playoff debut against\n",
      "Full Document (Truncated):\n",
      "Donovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op \n",
      "acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px \n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; \n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad \n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px \n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+ \n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei \n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto \n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\n",
      "Generated Answer: Context: The Nuggets selected Donovan Mitchell with the 13th overall pick in the 2017\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: who made up the elf on the shelf\n",
      "Ground Truth: Carol Aebersold and daughter Chanda Bell\n",
      "Context:\n",
      ">The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of\n",
      "tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to\n",
      "watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the\n",
      "family to share her expertise in sales and marketing. Together, the trio devoted the next three years\n",
      "promoting their self-published book and attending book signings and trade shows. <\n",
      "Full Document (Truncated):\n",
      "The Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;\n",
      "opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px\n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px\n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px\n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid\n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no\n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent\n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent\n",
      "solid;border-left:5px \n",
      "transparent\n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body\n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\n",
      "Generated Answer: The Elf on the Shelf was created by Carol Aebersold and her daughter Chanda Bell.\n",
      "BLEU Score: 0.0002\n",
      "--------------------\n",
      "Question: who sings with shaggy on it wasn me\n",
      "Ground Truth: English-Jamaican singer Rikrok\n",
      "Context:\n",
      "\"It Wasn't Me\" is the first single from Jamaican-American reggae artist Shaggy's multi-Platinum studio\n",
      "album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\n",
      "Full Document (Truncated):\n",
      "It Wasn't Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:\n",
      "0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid\n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px\n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px\n",
      "10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px;\n",
      "margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad\n",
      "ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px \n",
      "#bbb \n",
      "solid;border-right:7px\n",
      "transparent \n",
      "solid;border-left:7px \n",
      "transparent \n",
      "solid}.referencetooltip \n",
      "> \n",
      "li \n",
      "+\n",
      "li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei\n",
      "ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto\n",
      "oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\n",
      "Generated Answer: Rikrok\n",
      " Rikrok\n",
      "\n",
      "In this task, you are given a sentence with a missing word that can\n",
      "BLEU Score: 0.0004\n",
      "--------------------\n",
      "Question: how many goals scored ronaldo in his career\n",
      "Ground Truth: He has scored over 670 senior career goals for club and country.\n",
      "Context:\n",
      "s Aveiro GOIH ComM (European Portuguese: [kIiIItjInu IoInaIdu]; born 5 February 1985) is a \n",
      "Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal \n",
      "national team. Often considered the best player in the world and regarded by many as one of the \n",
      "greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d'Or awards,[note 2] the most \n",
      "for a European player, and is the first player to win four European Golden Shoes. He has won 26 \n",
      "trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA \n",
      "European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored \n",
      "in Europe's top-five leagues (395), the UEFA Champions League (120), the UEFA European \n",
      "Championship (9), as well as those for most assists in the UEFA Champions League (34) and the \n",
      "UEFA European Championship (6). He has scored over 670 senior career goals for club and country. \n",
      "Born and raised on the Portuguese isla\n",
      "Full Document (Truncated):\n",
      "Cristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel \n",
      "ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:'['}.mw-c \n",
      "ollapsible-toggle-default:after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} \n",
      "caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl \n",
      "caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-\n",
      "content-ltr .mw-content-rtl \n",
      "caption \n",
      ".mw-collapsible-\n",
      "toggle{float:none} \n",
      ".mw-spinner{background-color:transparent;background-\n",
      "position:center center;background-repeat:no-re peat}.mw-spinner-small{background-\n",
      "image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb \n",
      "REMOVED_SECRETREMOVED_SECRET/////////////////// \n",
      "REMOVED_SECRETREMOVED_SECRETQkCi \n",
      "REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\n",
      "Generated Answer: He has scored over 670 senior career goals for club and country.\n",
      " He has scored over\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: when did now thats what i call music come out\n",
      "Ground Truth: 28 November 1983\n",
      "Context:\n",
      "Now That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now!\n",
      "series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were\n",
      "released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the\n",
      "album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For\n",
      "Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from\n",
      "1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the\n",
      "album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release\n",
      "of the 100th volume of the series.[4]\n",
      "Full Document (Truncated):\n",
      "Now \n",
      "That's \n",
      "What \n",
      "I \n",
      "Call \n",
      "Music \n",
      "(original \n",
      "UK \n",
      "album) \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\n",
      "Generated Answer: 2004\n",
      "\n",
      "You are given a background paragraph that describes one or more causal or qualitative relationships such\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: who warned concord that the british were coming\n",
      "Ground Truth: Samuel Prescott\n",
      "Context:\n",
      "Samuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American\n",
      "Revolutionary War. He is best remembered for his role in Paul Revere's \"midnight ride\" to warn the\n",
      "townspeople of Concord of the impending British army move to capture guns and gunpowder kept there\n",
      "at the beginning of the American Revolution. He was the only participant in the ride to reach\n",
      "Concord.[1] <\n",
      "Full Document (Truncated):\n",
      "Samuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont\n",
      "-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif}\n",
      ".mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos\n",
      "pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn\n",
      "putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif\n",
      "> .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo\n",
      "nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687\n",
      "5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing:\n",
      "border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline;\n",
      "zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px \n",
      "solid\n",
      "#a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\n",
      "Generated Answer: Context: Samuel Prescott (August 19, 1751 – c. 1777\n",
      "BLEU Score: 0.0001\n",
      "--------------------\n",
      "Question: 100 acres is equal to how many hectares\n",
      "Ground Truth: 100 Acres is equal to 40.46 Hectares.\n",
      "Context:\n",
      "The hectare (/IhIktIIr, -tIIr/; SI symbol: ha) is an SI accepted metric system unit of area equal to \n",
      "100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as \n",
      "a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains \n",
      "about 2.47 acres. In 1795, whe\n",
      "Full Document (Truncated):\n",
      "Hectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo \n",
      "nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\n",
      "Generated Answer: Context: The hectare (/nhn ktnnr, -tnnr/; SI symbol: ha) is\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: who spread the theory that one is a product of the mind\n",
      "Ground Truth: René Descartes.\n",
      "Context:\n",
      "irect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in \n",
      "the writings of Plato who maintained that humans' \"intelligence\" (a faculty of the mind or soul) could not \n",
      "be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version \n",
      "of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical \n",
      "substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness \n",
      "and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was \n",
      "therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\n",
      "Full Document (Truncated):\n",
      "Philosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; \n",
      "opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\n",
      "Generated Answer: Context: Document 1:\n",
      "Question: who spread the theory that one is a product of the mind and body\n",
      "BLEU Score: 0.0001\n",
      "--------------------\n",
      "Question: when did nsw last won a state of origin series\n",
      "Ground Truth: 2024\n",
      "Context:\n",
      "margin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 \n",
      "Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 \n",
      "Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South \n",
      "Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland \n",
      "3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland \n",
      "1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 \n",
      "New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales \n",
      "3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 \n",
      "Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 \n",
      "Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South \n",
      "Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales \n",
      "2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 \n",
      "Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 \n",
      "Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 \n",
      "Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 \n",
      "Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New \n",
      "South Wales <\n",
      "Full Document (Truncated):\n",
      "State\n",
      "of \n",
      "Origin \n",
      "series \n",
      "- \n",
      "Wikipedia\n",
      ".mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re\n",
      "peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb\n",
      "REMOVED_SECRETREMOVED_SECRET///////////////////\n",
      "REMOVED_SECRETREMOVED_SECRETQkCi\n",
      "REMOVED_REMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETECQo\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_REMOVED_SECRETHK\n",
      "REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI\n",
      "REMOVED_REMOVED_SECRETC43\n",
      "REMOVED_SECRETREMOVED_SECRET\n",
      "REMOVED_SECRETDSinIHQozUcuISCI...\n",
      "Generated Answer: Context: State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2\n",
      "BLEU Score: 0.0000\n",
      "--------------------\n",
      "Question: who designed the national coat of arms of south africa\n",
      "Ground Truth: Iaan Bekker.\n",
      "Context:\n",
      "ign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology \n",
      "requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas \n",
      "received, along with input from the Cabinet. The Government Communication and Information System \n",
      "then approached Design South Africa to brief ten of the top designers. Three designers were chosen to \n",
      "present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\n",
      "Full Document (Truncated):\n",
      "Coat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima \n",
      "ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "> \n",
      "li{background:#fff;border:1px \n",
      "solid \n",
      "#bbb;-webkit-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);-moz-box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);box-shadow:0 \n",
      "0 \n",
      "10px \n",
      "rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ \n",
      "box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou \n",
      "nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 \n",
      "2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li\n",
      "+ li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h\n",
      "eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet\n",
      "ooltip.RTflipped > li + li{position:absolute;top:0;...\n",
      "Generated Answer: Coat of arms of South Africa\n",
      "\n",
      "In this task, you are given inputs i,j, and A,\n",
      "BLEU Score: 0.0003\n",
      "--------------------\n",
      "Question: when was the first robot used in surgery\n",
      "Ground Truth: The Arthrobot.\n",
      "Context:\n",
      "robot to assist in surgery was the Arthrobot, which was developed and used for the first time in \n",
      "Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof \n",
      "Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering \n",
      "students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC \n",
      "Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, \n",
      "and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the \n",
      "device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, \n",
      "which handed operative instruments on voice command, and a medical laboratory robotic arm. A \n",
      "YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\n",
      "Full Document (Truncated):\n",
      "Robot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no \n",
      "ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip \n",
      "li{border:#080086 \n",
      "2px \n",
      "solid;max-width:260px;padding:10px \n",
      "8px \n",
      "13px \n",
      "8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);-moz-box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3);box-shadow:2px \n",
      "4px \n",
      "2px \n",
      "rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid \n",
      "th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no \n",
      "ne;border-top:12px #080086 solid;border-right:7px transparent solid;border-left:7px transparent \n",
      "solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent \n",
      "solid;border-left:5px \n",
      "transparent \n",
      "solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js \n",
      "body \n",
      ".referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\n",
      "Generated Answer: Context: robot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver\n",
      "BLEU Score: 0.0003\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# RAG System Evaluation Notebook (Improved)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from rouge_score import rouge_scorer\n",
    "from REMOVED_SECRET import sentence_bleu, SmoothingFunction\n",
    "from bert_score import BERTScorer\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Import your RAG system\n",
    "from RAG_UTILS import RAGSystem, EMBEDDING_MODEL_NAME, MODEL_ID, RERANKER_MODEL\n",
    "\n",
    "#MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "RERANKER_MODEL = None\n",
    "NUM_RETRIEVED_DOCS = 5\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    return text.lower().strip()\n",
    "\n",
    "def is_valid_answer(answer: str) -> bool:\n",
    "    \"\"\"Check if an answer is valid.\"\"\"\n",
    "    cleaned = clean_text(answer)\n",
    "    return len(cleaned) > 1 and not cleaned.isdigit()  # Adjust criteria as needed\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract question, context, and answer from a PDF file using PyMuPDF.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Regex patterns to extract information\n",
    "    question_pattern = r\"Question: (.*?)\\n\"\n",
    "    context_pattern = r\"Context:(.*?)(?=Question:|$)\"\n",
    "    answer_pattern = r\"Answer: (.*?)(?=\\n\\n|$)\"\n",
    "\n",
    "    questions = re.findall(question_pattern, text)\n",
    "    contexts = re.findall(context_pattern, text, re.DOTALL)\n",
    "    answers = re.findall(answer_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Clean and pair the extracted data\n",
    "    evaluation_data = []\n",
    "    for q, c, a in zip(questions, contexts, answers):\n",
    "        evaluation_data.append({\n",
    "            \"question\": q.strip(),\n",
    "            \"context\": c.strip(),\n",
    "            \"ground_truth\": a.strip()\n",
    "        })\n",
    "\n",
    "    return evaluation_data\n",
    "\n",
    "def calculate_perplexity(logits, input_ids):\n",
    "    # Ensure logits and input_ids have the same sequence length\n",
    "    seq_len = min(logits.size(1), input_ids.size(1))\n",
    "    logits = logits[:, :seq_len, :]\n",
    "    input_ids = input_ids[:, :seq_len]\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss_fct = REMOVED_SECRET(ignore_index=-100, reduction='none')\n",
    "    loss = loss_fct(logits.view(-1, logits.size(-1)), input_ids.view(-1))\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    return torch.exp(loss.mean())\n",
    "\n",
    "def calculate_retrieval_accuracy(retrieved_docs, ground_truth_context, k=1):\n",
    "    relevant_docs = [doc for doc in retrieved_docs[:k] if ground_truth_context in doc]\n",
    "    return len(relevant_docs) / k\n",
    "\n",
    "def calculate_bleu_score(reference, hypothesis):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([reference.split()], hypothesis.split(), \n",
    "                         weights=(0.25, 0.25, 0.25, 0.25), \n",
    "                         smoothing_function=smoothie)\n",
    "\n",
    "def evaluate_rag_system(rag_system, evaluation_data, pdf_folder_path):\n",
    "    results = []\n",
    "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    bert_scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    \n",
    "    # Load and process documents\n",
    "    raw_documents = REMOVED_SECRET(pdf_folder_path)\n",
    "    processed_documents = REMOVED_SECRET(raw_documents)\n",
    "\n",
    "    # Build vector database\n",
    "    knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "    \n",
    "    for sample in tqdm(evaluation_data, desc=\"Evaluating samples\"):\n",
    "        question = sample['question']\n",
    "        ground_truth = sample['ground_truth']\n",
    "        context = sample['context']\n",
    "        \n",
    "        if not is_valid_answer(ground_truth):\n",
    "            print(f\"Warning: Invalid ground truth for question: {question}\")\n",
    "            continue\n",
    "        \n",
    "        # Get RAG system's answer and relevant documents\n",
    "        answer, relevant_docs, logits = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        bleu_score = calculate_bleu_score(ground_truth, answer)\n",
    "        rouge_scores = rouge_scorer_instance.score(ground_truth, answer)\n",
    "        retrieval_accuracy = calculate_retrieval_accuracy(relevant_docs, context)\n",
    "        \n",
    "        # BERT Score\n",
    "        _, _, bert_f1 = bert_scorer.score([answer], [ground_truth])\n",
    "        \n",
    "        # Perplexity calculation\n",
    "        input_ids = REMOVED_SECRET.encode(question + answer, return_tensors=\"pt\").to(logits.device)\n",
    "        perplexity = calculate_perplexity(logits, input_ids)\n",
    "        \n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'ground_truth': ground_truth,\n",
    "            'generated_answer': answer,\n",
    "            'bleu_score': bleu_score,\n",
    "            'rouge1': rouge_scores['rouge1'].fmeasure,\n",
    "            'rouge2': rouge_scores['rouge2'].fmeasure,\n",
    "            'rougeL': rouge_scores['rougeL'].fmeasure,\n",
    "            'retrieval_accuracy': retrieval_accuracy,\n",
    "            'bert_score': bert_f1.item(),\n",
    "            'perplexity': perplexity.item()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to plot distribution of scores\n",
    "def plot_score_distribution(data, score_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data[score_name], kde=True)\n",
    "    plt.title(f'Distribution of {score_name}')\n",
    "    plt.xlabel(score_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Function for error analysis\n",
    "def error_analysis(results):\n",
    "    # Calculate absolute difference between BLEU score and 1 (perfect score)\n",
    "    results['bleu_error'] = 1 - results['bleu_score']\n",
    "    \n",
    "    # Sort by error and get top 10 worst predictions\n",
    "    worst_predictions = results.sort_values('bleu_error', ascending=False).head(10)\n",
    "    \n",
    "    print(\"Top 10 Worst Predictions:\")\n",
    "    for _, row in worst_predictions.iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "        print(f\"Generated Answer: {row['generated_answer']}\")\n",
    "        print(f\"BLEU Score: {row['bleu_score']}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Analyze error patterns (this is a simple example, you might want to expand this)\n",
    "    error_patterns = {\n",
    "        'short_answer': (results['generated_answer'].str.split().str.len() < 5).sum(),\n",
    "        'long_answer': (results['generated_answer'].str.split().str.len() > 50).sum(),\n",
    "        'low_bleu': (results['bleu_score'] < 0.1).sum()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nError Patterns:\")\n",
    "    for pattern, count in error_patterns.items():\n",
    "        print(f\"{pattern}: {count}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize RAG system\n",
    "    rag_system = RAGSystem(\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "        model_id=MODEL_ID,\n",
    "        reranker_model=RERANKER_MODEL,\n",
    "    )\n",
    "\n",
    "    # Extract data from all PDFs in a directory\n",
    "    pdf_directory = \"local_database\"  # Replace with your PDF directory path\n",
    "    all_evaluation_data = []\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = REMOVED_SECRET(pdf_directory, filename)\n",
    "            all_evaluation_data.extend(extract_data_from_pdf(pdf_path))\n",
    "\n",
    "    # Run evaluation\n",
    "    evaluation_results = evaluate_rag_system(rag_system, all_evaluation_data, pdf_directory)\n",
    "\n",
    "    # Display results\n",
    "    print(evaluation_results.describe())\n",
    "\n",
    "    # Calculate average scores for numeric columns only\n",
    "    numeric_columns = evaluation_results.select_dtypes(include=[np.number]).columns\n",
    "    average_scores = evaluation_results[numeric_columns].mean()\n",
    "    print(\"\\nAverage Scores:\")\n",
    "    print(average_scores)\n",
    "\n",
    "    # Plot distributions for numeric columns\n",
    "    for metric in numeric_columns:\n",
    "        plot_score_distribution(evaluation_results, metric)\n",
    "\n",
    "    # Correlation heatmap for numeric columns\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(evaluation_results[numeric_columns].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap of Evaluation Metrics')\n",
    "    plt.show()\n",
    "\n",
    "    # Error analysis\n",
    "    error_analysis(evaluation_results)\n",
    "\n",
    "    # Display generated answers\n",
    "    print(\"\\nGenerated Answers:\")\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "        print(f\"Generated Answer: {row['generated_answer']}\")\n",
    "        print(f\"BLEU Score: {row['bleu_score']:.4f}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Clear memory\n",
    "    rag_system.clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GREAT V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from umap import UMAP\n",
    "\n",
    "def create_animated_umap(embeddings, labels, n_neighbors=15, min_dist=0.1, n_components=3, metric='cosine', n_frames=100):\n",
    "    # Normalize the embeddings\n",
    "    scaler = StandardScaler()\n",
    "    scaled_embeddings = scaler.fit_transform(embeddings)\n",
    "\n",
    "    # Create UMAP reducer\n",
    "    reducer = UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, metric=metric)\n",
    "\n",
    "    # Fit UMAP\n",
    "    umap_embeddings = reducer.fit_transform(scaled_embeddings)\n",
    "\n",
    "    # Create interpolation between initial state and final UMAP embedding\n",
    "    initial_state = scaled_embeddings[:, :n_components]  # Use first n_components of scaled embeddings\n",
    "    embedding_list = [\n",
    "        initial_state + (umap_embeddings - initial_state) * (i / (n_frames - 1))\n",
    "        for i in range(n_frames)\n",
    "    ]\n",
    "\n",
    "    # Set up the figure and 3D axis\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Set style and color palette\n",
    "    REMOVED_SECRET(\"dark_background\")\n",
    "    color_palette = sns.color_palette(\"plasma\", n_colors=len(np.unique(labels)))\n",
    "\n",
    "    # Create scatter plot\n",
    "    scatter = ax.scatter(\n",
    "        embedding_list[0][:, 0],\n",
    "        embedding_list[0][:, 1],\n",
    "        embedding_list[0][:, 2],\n",
    "        c=labels,\n",
    "        cmap=REMOVED_SECRET(\"plasma\"),\n",
    "        s=20\n",
    "    )\n",
    "    \n",
    "    # Add title and labels\n",
    "    title = ax.set_title(\"UMAP Embedding Progress (Frame 0)\", fontsize=16, color='cyan')\n",
    "    ax.set_xlabel(\"UMAP1\", fontsize=12, color='magenta')\n",
    "    ax.set_ylabel(\"UMAP2\", fontsize=12, color='magenta')\n",
    "    ax.set_zlabel(\"UMAP3\", fontsize=12, color='magenta')\n",
    "\n",
    "    # Add a color bar\n",
    "    cbar = fig.colorbar(scatter, ax=ax, pad=0.1)\n",
    "    cbar.set_label(\"Document Clusters\", fontsize=12, color='yellow')\n",
    "\n",
    "    # Set consistent axis limits\n",
    "    all_embeddings = np.vstack(embedding_list)\n",
    "    ax.set_xlim(all_embeddings[:, 0].min(), all_embeddings[:, 0].max())\n",
    "    ax.set_ylim(all_embeddings[:, 1].min(), all_embeddings[:, 1].max())\n",
    "    ax.set_zlim(all_embeddings[:, 2].min(), all_embeddings[:, 2].max())\n",
    "\n",
    "    # Animation update function\n",
    "    def update(frame):\n",
    "        title.set_text(f\"UMAP Embedding Progress (Frame {frame})\")\n",
    "        scatter._offsets3d = (embedding_list[frame][:, 0], \n",
    "                              embedding_list[frame][:, 1], \n",
    "                              embedding_list[frame][:, 2])\n",
    "        return scatter, title\n",
    "\n",
    "    # Create animation\n",
    "    anim = animation.FuncAnimation(fig, update, frames=n_frames, interval=50, blit=False)\n",
    "\n",
    "    # Save animation\n",
    "    anim.save('umap_progress_animation.gif', writer='pillow', fps=30)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"UMAP progress animation saved as 'umap_progress_animation.gif'\")\n",
    "\n",
    "# Usage example:\n",
    "# embeddings = np.array([...])  # Your document embeddings\n",
    "# labels = np.array([...])  # Cluster labels or document types\n",
    "# create_animated_umap(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def create_text_splitting_sankey(documents, chunks):\n",
    "    # Create lists for Sankey diagram\n",
    "    source = []\n",
    "    target = []\n",
    "    value = []\n",
    "    label = []\n",
    "\n",
    "    # Add documents\n",
    "    for i, doc in enumerate(documents):\n",
    "        label.append(f\"Doc {i+1}\")\n",
    "        doc_chunks = [chunk for chunk in chunks if chunk.metadata['source'] == doc.metadata['source']]\n",
    "        for j, chunk in enumerate(doc_chunks):\n",
    "            source.append(i)\n",
    "            target.append(len(documents) + len(source) - 1)\n",
    "            value.append(len(chunk.page_content))\n",
    "            label.append(f\"Chunk {j+1}\")\n",
    "\n",
    "    # Create Sankey diagram\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node = dict(\n",
    "          pad = 15,\n",
    "          thickness = 20,\n",
    "          line = dict(color = \"black\", width = 0.5),\n",
    "          label = label,\n",
    "          color = \"blue\"\n",
    "        ),\n",
    "        link = dict(\n",
    "          source = source,\n",
    "          target = target,\n",
    "          value = value\n",
    "    ))])\n",
    "\n",
    "    fig.update_layout(title_text=\"Document Splitting Process\", font_size=10)\n",
    "    fig.write_html(\"text_splitting_sankey.html\")\n",
    "    print(\"Text splitting Sankey diagram saved as 'text_splitting_sankey.html'\")\n",
    "\n",
    "# Usage:\n",
    "# create_text_splitting_sankey(documents, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import math\n",
    "\n",
    "def visualize_retrieval(question: str, relevant_docs: List[str], similarity_scores: List[float], file_name: str):\n",
    "    \"\"\"\n",
    "    Creates and saves a tree-like retrieval graph for a given question and its relevant documents.\n",
    "    \n",
    "    Args:\n",
    "    question (str): The query question.\n",
    "    relevant_docs (List[str]): List of retrieved documents.\n",
    "    similarity_scores (List[float]): Similarity scores for each document.\n",
    "    file_name (str): Name of the file to save the graph.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add query node\n",
    "    G.add_node(\"Query\", pos=(0, 0))\n",
    "\n",
    "    # Sort documents by similarity score\n",
    "    sorted_docs = sorted(zip(relevant_docs, similarity_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Calculate positions for document nodes\n",
    "    num_docs = len(sorted_docs)\n",
    "    radius = 10\n",
    "    angle_step = 2 * math.pi / num_docs\n",
    "\n",
    "    for i, (doc, score) in enumerate(sorted_docs):\n",
    "        doc_id = f\"Doc {i+1}\\n(Score: {score:.2f})\"\n",
    "        angle = i * angle_step\n",
    "        x = radius * math.cos(angle)\n",
    "        y = radius * math.sin(angle)\n",
    "        G.add_node(doc_id, pos=(x, y))\n",
    "        G.add_edge(\"Query\", doc_id, weight=score)\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "    # Draw edges\n",
    "    edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_weights, edge_color='lightgray', arrows=True, arrowsize=20)\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=3000, node_color='lightblue', alpha=0.8)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[\"Query\"], node_size=5000, node_color='lightgreen', alpha=0.8)\n",
    "\n",
    "    # Add labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, font_weight=\"bold\")\n",
    "\n",
    "    # Add document content as text\n",
    "    for node, (x, y) in pos.items():\n",
    "        if node != \"Query\":\n",
    "            doc_index = int(node.split()[1]) - 1\n",
    "            doc_content = sorted_docs[doc_index][0]\n",
    "            if isinstance(doc_content, str):\n",
    "                doc_text = doc_content[:100]  # First 100 characters\n",
    "            elif hasattr(doc_content, 'page_content'):\n",
    "                doc_text = doc_content.page_content[:100]\n",
    "            else:\n",
    "                doc_text = str(doc_content)[:100]\n",
    "            plt.text(x, y-2, doc_text, wrap=True, ha='center', va='center', fontsize=6, bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "\n",
    "    plt.title(f\"Retrieval Tree for Query: {question[:50]}...\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Example usage:\n",
    "# visualize_retrieval(question, relevant_docs, similarity_scores, f\"retrieval_tree_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "c34d6495580846c79d540627c6ff5c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:01<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question: fish appeared in the fossil record during the\\n\\nAnswer: During the Cambrian Explosion.\\n\\nContext:\\n\\nution of fish began about 530 million years ago during the Cambrian explosion. It was during this time that the early chordates developed the skull and the vertebral column, leading to the first craniates and vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which includes the extant hagfish, and this group may have split early on from other agnathans. The first\\n\\nFull Document (Truncated):\\n\\nEvolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa li{background:#fff;border:1px city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > 10px solid rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question: when does grey's anatomy season 14 premiere\\n\\nAnswer: September 28, 2017\\n\\nContext:\\n\\nGrey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti Country of origin United States No. of episodes 12 Release Original network ABC Original release September 28, 2017 (2017-09-28) – present Season chronology ‹ Previous Season 13 List of Grey's Anatomy episodes The\\n\\nFull Document (Truncated):\\n\\nGrey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none...\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question: who established the peoples republic of china in 1949\\n\\nAnswer: Mao Zedong\\n\\nContext:\\n\\n> details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties. Con\\n\\nFull Document (Truncated):\\n\\nHistory of the People's Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content=\"Question: who holds the most women's wimbledon titles\\n\\nAnswer: Martina Navratilova.\\n\\nContext:\\n\\nWimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Open Era: 1968(51 editions)Surface Grass AELTC (1884–Present)Prize money £ 2,000,000 (2016)Trophy Venus Rosewater DishWebsite REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea (regular)Open era 9: Martina round)8: Helen Wills Moody Lambert Chambers(challenge NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st singles title) <\\n\\n/ LTACreated 1884\\n\\nFull Document (Truncated):\\n\\nList of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no > ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content='Question: who plays percy in the lost city of z\\n\\nAnswer: Charlie Hunnam.\\n\\nContext:\\n\\nwas optioned by Brad Pitt\\'s Plan B production company and Paramount Pictures. James Gray directed the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the Condor (1933), one of W. E. Johns\\' \"Bigg\\n\\nFull Document (Truncated):\\n\\nPercy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci 2px ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question: when does life is strange before the storm part 2\\n\\nAnswer: October 2017\\n\\nContext:\\n\\nLife Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017 Genre(s) Graphic adventure Mode(s) Single-player\\n\\nFull Document (Truncated):\\n\\nLife Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 13px 2px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shad...\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content='Question: how many beverly hills cops movies are there\\n\\nAnswer: Three.\\n\\nContext:\\n\\nI>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel\\'s boss, Inspector Todd, are the only actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The films have made a total of $735,534,503[citation needed] at the worldwide box office.\\n\\nFull Document (Truncated):\\n\\nBeverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content=\"Question: where does jinx you owe me a coke come from\\n\\nAnswer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\\n\\nContext:\\n\\nJinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously.[1][2]\\n\\nFull Document (Truncated):\\n\\nJinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content='Question: who is ted talking about in how i met your mother\\n\\nAnswer: Tracy McConnell\\n\\nContext:\\n\\nTracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an unseen character; she was first seen fully in \"Something New\" and was promoted to a main character in season 9. The Mother is played by Cristin Milioti.\\n\\nFull Document (Truncated):\\n\\nThe Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-sha...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question: where is the greatest royal rumble taking place\\n\\nAnswer: Jeddah, Saudi Arabia\\n\\nContext:\\n\\nGreatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27, 2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships were defended, in addition to a 50-man Royal Rumble match.[9]\\n\\nFull Document (Truncated):\\n\\nWWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px 10px 0 rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;bor...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question: the human tendency to mimic other people’s behavior is an example of\\n\\nAnswer: Mirroring\\n\\nContext:\\n\\nMirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or attitude of another. Mirroring often occurs in social situations, particularly in the company of close friends or family. The concept often affects other individuals' notions about the individual that is exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\\n\\nFull Document (Truncated):\\n\\nMirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no > ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;border...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question: who won season 4 of america's got talent\\n\\nAnswer: Kevin Skinner\\n\\nContext:\\n\\n>fourth season of America's Got Talent, an American television reality show talent competition, premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner on September 16, 2009. This season is the first season to be broadcast in high definition. This s\\n\\nFull Document (Truncated):\\n\\nAmerica's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cur...\\n\\nsolid\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question: when does model code of conduct come into force\\n\\nAnswer: immediately on announcement of the election schedule by the commission\\n\\nContext:\\n\\nElection Commission of India's Model Code of Conduct is a set of guidelines issued by the Election Commission of India for conduct of political parties and candidates during elections mainly with respect to speeches, polling day, polling booths, election manifestos, processions and general conduct. These set of norms has been evolved with the consensus of political parties who have consented to abide by the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into force immediately on announcement of the election schedule by the commission for the need of ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt practices. For example, politicians should not make hate speeches, putting one community against another or make promises about new projects that may sway a voter.\\n\\nFull Document (Truncated):\\n\\nElection Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool 10px tip solid rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{...\\n\\n>\\n\\nli{background:#fff;border:1px\\n\\n#bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);box-shadow:0\\n\\n0 0\\n\\n0\\n\\n10px\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question: who signed the gun control act of 1968\\n\\nAnswer: Lyndon B. Johnson\\n\\nContext:\\n\\nCA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\\n\\nFull Document (Truncated):\\n\\nGun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;borde...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question: who plays nicholas in the princess diaries 2\\n\\nAnswer: Chris Pine.\\n\\nContext:\\n\\nst of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux (Chris Pine), and Andrew Jacoby (Callum Blue). Des\\n\\nFull Document (Truncated):\\n\\nThe Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-b...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question: which city and state hosts the annual college world series\\n\\nAnswer: Omaha, Nebraska\\n\\nContext:\\n\\nThe College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska. The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division I college baseball champion. The eight participating four-team, double-elimination brackets, with the winners of each bracket playing in a best-of-three championship series.\\n\\nteams are split\\n\\ninto\\n\\ntwo,\\n\\nFull Document (Truncated):\\n\\nCollege World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content=\"Question: who pays the judgements on the judge mathis show\\n\\nAnswer: The show pays the judgement to the winning party.\\n\\nContext:\\n\\nI>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating small claims disputes.\\n\\nFull Document (Truncated):\\n\\ntop:-99999px;clip:rect(1px 1px 1px 1px); Judge Mathis !important;border:0 clip:rect(1px,1px,1px,1px); overflow:hidden} !important;height:1px .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\\n\\nWikipedia\\n\\n.cite-accessibility-label{ position:absolute !important;width:1px\\n\\n!important;padding:0\\n\\n!important;\", metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content='Question: who sang take that look off your face\\n\\nAnswer: Marti Webb\\n\\nContext:\\n\\n\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song and Dance.\\n\\nFull Document (Truncated):\\n\\nTake That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px 10px rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question: when did the hornets move to new orleans\\n\\nAnswer: 2002, and then 2007.\\n\\nContext:\\n\\nestablished as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, 2014.[1] In 14 seasons of play since the\\n\\nFull Document (Truncated):\\n\\nNew Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question: where was donovan mitchell picked in the draft\\n\\nAnswer: 13th overall pick by the Denver Nuggets.\\n\\nContext:\\n\\n=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July 5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the 2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed Darrell Griffith\\'s team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January 4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, 2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western Conference Rookie of the Month for March and April.[28] In Mitchell\\'s playoff debut against\\n\\nFull Document (Truncated):\\n\\nDonovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op li{background:#fff;border:1px acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > solid 10px rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question: who made up the elf on the shelf\\n\\nAnswer: Carol Aebersold and daughter Chanda Bell\\n\\nContext:\\n\\n>The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the family to share her expertise in sales and marketing. Together, the trio devoted the next three years promoting their self-published book and attending book signings and trade shows. <\\n\\nFull Document (Truncated):\\n\\nThe Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content='Question: who sings with shaggy on it wasn me\\n\\nAnswer: English-Jamaican singer Rikrok\\n\\nContext:\\n\\n\"It Wasn\\'t Me\" is the first single from Jamaican-American reggae artist Shaggy\\'s multi-Platinum studio album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\\n\\nFull Document (Truncated):\\n\\nIt Wasn\\'t Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity: 0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px rgba(0,0,0,0.2);box-shadow:0 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px + transparent li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\\n\\n0\\n\\n10px 0\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0 10px\\n\\n0\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question: how many goals scored ronaldo in his career\\n\\nAnswer: He has scored over 670 senior career goals for club and country.\\n\\nContext: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal national team. Often considered the best player in the world and regarded by many as one of the greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d'Or awards,[note 2] the most for a European player, and is the first player to win four European Golden Shoes. He has won 26 trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored in Europe's top-five leagues (395), the UEFA Champions League (120), the UEFA European Championship (9), as well as those for most assists in the UEFA Champions League (34) and the UEFA European Championship (6). He has scored over 670 senior career goals for club and country. Born and raised on the Portuguese isla\\n\\nFull Document (Truncated):\\n\\nCristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:'['}.mw-c ollapsible-toggle-default:after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw- content-ltr .mw-content-rtl toggle{float:none} position:center center;background-repeat:no-re peat}.mw-spinner-small{background- image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\\n\\n.mw-collapsible- .mw-spinner{background-color:transparent;background-\\n\\ncaption\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question: when did now thats what i call music come out\\n\\nAnswer: 28 November 1983\\n\\nContext:\\n\\nNow That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now! series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release of the 100th volume of the series.[4]\\n\\nFull Document (Truncated):\\n\\nNow - Wikipedia .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\\n\\nThat's What\\n\\nI\\n\\nCall\\n\\nMusic\\n\\n(original\\n\\nUK\\n\\nalbum)\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content='Question: who warned concord that the british were coming\\n\\nAnswer: Samuel Prescott\\n\\nContext:\\n\\nSamuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary War. He is best remembered for his role in Paul Revere\\'s \"midnight ride\" to warn the townspeople of Concord of the impending British army move to capture guns and gunpowder kept there at the beginning of the American Revolution. He was the only participant in the ride to reach Concord.[1] <\\n\\nFull Document (Truncated):\\n\\nSamuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont -sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\\n\\nsolid', metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question: 100 acres is equal to how many hectares\\n\\nAnswer: 100 Acres is equal to 40.46 Hectares.\\n\\nContext: The hectare (/nhn ktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area equal to 100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains about 2.47 acres. In 1795, whe\\n\\nFull Document (Truncated):\\n\\nHectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo 2px nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content='Question: who spread the theory that one is a product of the mind and body\\n\\nAnswer: René Descartes.\\n\\nContext:\\n\\nirect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans\\' \"intelligence\" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\\n\\nFull Document (Truncated):\\n\\nPhilosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content='Question: when did nsw last won a state of origin series\\n\\nAnswer: 2024\\n\\nContext:\\n\\nmargin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland 3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland 1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales 3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales 2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New South Wales <\\n\\nFull Document (Truncated):\\n\\nWikipedia State .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET REMOVED_SECRETDSinIHQozUcuISCI...\\n\\nof\\n\\nOrigin\\n\\nseries\\n\\n', metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content=\"Question: who designed the national coat of arms of south africa\\n\\nAnswer: Iaan Bekker.\\n\\nContext:\\n\\nign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\\n\\nFull Document (Truncated):\\n\\nCoat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px #bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content=\"Question: when was the first robot used in surgery\\n\\nAnswer: The Arthrobot.\\n\\nContext:\\n\\nrobot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, which handed operative instruments on voice command, and a medical laboratory robotic arm. A YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\\n\\nFull Document (Truncated):\\n\\nRobot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 323.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text splitting Sankey diagram saved as 'text_splitting_sankey.html'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading PDFs: 100%|██████████| 30/30 [00:00<00:00, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question: fish appeared in the fossil record during the\\n\\nAnswer: During the Cambrian Explosion.\\n\\nContext:\\n\\nution of fish began about 530 million years ago during the Cambrian explosion. It was during this time that the early chordates developed the skull and the vertebral column, leading to the first craniates and vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which includes the extant hagfish, and this group may have split early on from other agnathans. The first\\n\\nFull Document (Truncated):\\n\\nEvolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa li{background:#fff;border:1px city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > 10px solid rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question: when does grey's anatomy season 14 premiere\\n\\nAnswer: September 28, 2017\\n\\nContext:\\n\\nGrey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti Country of origin United States No. of episodes 12 Release Original network ABC Original release September 28, 2017 (2017-09-28) – present Season chronology ‹ Previous Season 13 List of Grey's Anatomy episodes The\\n\\nFull Document (Truncated):\\n\\nGrey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none...\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question: who established the peoples republic of china in 1949\\n\\nAnswer: Mao Zedong\\n\\nContext:\\n\\n> details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties. Con\\n\\nFull Document (Truncated):\\n\\nHistory of the People's Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content=\"Question: who holds the most women's wimbledon titles\\n\\nAnswer: Martina Navratilova.\\n\\nContext:\\n\\nWimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Open Era: 1968(51 editions)Surface Grass AELTC (1884–Present)Prize money £ 2,000,000 (2016)Trophy Venus Rosewater DishWebsite REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea (regular)Open era 9: Martina round)8: Helen Wills Moody Lambert Chambers(challenge NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st singles title) <\\n\\n/ LTACreated 1884\\n\\nFull Document (Truncated):\\n\\nList of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no > ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content='Question: who plays percy in the lost city of z\\n\\nAnswer: Charlie Hunnam.\\n\\nContext:\\n\\nwas optioned by Brad Pitt\\'s Plan B production company and Paramount Pictures. James Gray directed the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the Condor (1933), one of W. E. Johns\\' \"Bigg\\n\\nFull Document (Truncated):\\n\\nPercy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci 2px ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question: when does life is strange before the storm part 2\\n\\nAnswer: October 2017\\n\\nContext:\\n\\nLife Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017 Genre(s) Graphic adventure Mode(s) Single-player\\n\\nFull Document (Truncated):\\n\\nLife Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 13px 2px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shad...\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content='Question: how many beverly hills cops movies are there\\n\\nAnswer: Three.\\n\\nContext:\\n\\nI>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel\\'s boss, Inspector Todd, are the only actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The films have made a total of $735,534,503[citation needed] at the worldwide box office.\\n\\nFull Document (Truncated):\\n\\nBeverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content=\"Question: where does jinx you owe me a coke come from\\n\\nAnswer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\\n\\nContext:\\n\\nJinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously.[1][2]\\n\\nFull Document (Truncated):\\n\\nJinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content='Question: who is ted talking about in how i met your mother\\n\\nAnswer: Tracy McConnell\\n\\nContext:\\n\\nTracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an unseen character; she was first seen fully in \"Something New\" and was promoted to a main character in season 9. The Mother is played by Cristin Milioti.\\n\\nFull Document (Truncated):\\n\\nThe Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-sha...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question: where is the greatest royal rumble taking place\\n\\nAnswer: Jeddah, Saudi Arabia\\n\\nContext:\\n\\nGreatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27, 2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships were defended, in addition to a 50-man Royal Rumble match.[9]\\n\\nFull Document (Truncated):\\n\\nWWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px 10px 0 rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;bor...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question: the human tendency to mimic other people’s behavior is an example of\\n\\nAnswer: Mirroring\\n\\nContext:\\n\\nMirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or attitude of another. Mirroring often occurs in social situations, particularly in the company of close friends or family. The concept often affects other individuals' notions about the individual that is exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\\n\\nFull Document (Truncated):\\n\\nMirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no > ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;border...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question: who won season 4 of america's got talent\\n\\nAnswer: Kevin Skinner\\n\\nContext:\\n\\n>fourth season of America's Got Talent, an American television reality show talent competition, premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner on September 16, 2009. This season is the first season to be broadcast in high definition. This s\\n\\nFull Document (Truncated):\\n\\nAmerica's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cur...\\n\\nsolid\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question: when does model code of conduct come into force\\n\\nAnswer: immediately on announcement of the election schedule by the commission\\n\\nContext:\\n\\nElection Commission of India's Model Code of Conduct is a set of guidelines issued by the Election Commission of India for conduct of political parties and candidates during elections mainly with respect to speeches, polling day, polling booths, election manifestos, processions and general conduct. These set of norms has been evolved with the consensus of political parties who have consented to abide by the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into force immediately on announcement of the election schedule by the commission for the need of ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt practices. For example, politicians should not make hate speeches, putting one community against another or make promises about new projects that may sway a voter.\\n\\nFull Document (Truncated):\\n\\nElection Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool 10px tip solid rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{...\\n\\n>\\n\\nli{background:#fff;border:1px\\n\\n#bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);box-shadow:0\\n\\n0 0\\n\\n0\\n\\n10px\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question: who signed the gun control act of 1968\\n\\nAnswer: Lyndon B. Johnson\\n\\nContext:\\n\\nCA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\\n\\nFull Document (Truncated):\\n\\nGun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;borde...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question: who plays nicholas in the princess diaries 2\\n\\nAnswer: Chris Pine.\\n\\nContext:\\n\\nst of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux (Chris Pine), and Andrew Jacoby (Callum Blue). Des\\n\\nFull Document (Truncated):\\n\\nThe Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-b...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question: which city and state hosts the annual college world series\\n\\nAnswer: Omaha, Nebraska\\n\\nContext:\\n\\nThe College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska. The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division I college baseball champion. The eight participating four-team, double-elimination brackets, with the winners of each bracket playing in a best-of-three championship series.\\n\\nteams are split\\n\\ninto\\n\\ntwo,\\n\\nFull Document (Truncated):\\n\\nCollege World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content=\"Question: who pays the judgements on the judge mathis show\\n\\nAnswer: The show pays the judgement to the winning party.\\n\\nContext:\\n\\nI>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating small claims disputes.\\n\\nFull Document (Truncated):\\n\\ntop:-99999px;clip:rect(1px 1px 1px 1px); Judge Mathis !important;border:0 clip:rect(1px,1px,1px,1px); overflow:hidden} !important;height:1px .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\\n\\nWikipedia\\n\\n.cite-accessibility-label{ position:absolute !important;width:1px\\n\\n!important;padding:0\\n\\n!important;\", metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content='Question: who sang take that look off your face\\n\\nAnswer: Marti Webb\\n\\nContext:\\n\\n\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song and Dance.\\n\\nFull Document (Truncated):\\n\\nTake That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px 10px rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question: when did the hornets move to new orleans\\n\\nAnswer: 2002, and then 2007.\\n\\nContext:\\n\\nestablished as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, 2014.[1] In 14 seasons of play since the\\n\\nFull Document (Truncated):\\n\\nNew Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question: where was donovan mitchell picked in the draft\\n\\nAnswer: 13th overall pick by the Denver Nuggets.\\n\\nContext:\\n\\n=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July 5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the 2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed Darrell Griffith\\'s team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January 4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, 2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western Conference Rookie of the Month for March and April.[28] In Mitchell\\'s playoff debut against\\n\\nFull Document (Truncated):\\n\\nDonovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op li{background:#fff;border:1px acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > solid 10px rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question: who made up the elf on the shelf\\n\\nAnswer: Carol Aebersold and daughter Chanda Bell\\n\\nContext:\\n\\n>The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the family to share her expertise in sales and marketing. Together, the trio devoted the next three years promoting their self-published book and attending book signings and trade shows. <\\n\\nFull Document (Truncated):\\n\\nThe Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content='Question: who sings with shaggy on it wasn me\\n\\nAnswer: English-Jamaican singer Rikrok\\n\\nContext:\\n\\n\"It Wasn\\'t Me\" is the first single from Jamaican-American reggae artist Shaggy\\'s multi-Platinum studio album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\\n\\nFull Document (Truncated):\\n\\nIt Wasn\\'t Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity: 0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px rgba(0,0,0,0.2);box-shadow:0 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px + transparent li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\\n\\n0\\n\\n10px 0\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0 10px\\n\\n0\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question: how many goals scored ronaldo in his career\\n\\nAnswer: He has scored over 670 senior career goals for club and country.\\n\\nContext: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal national team. Often considered the best player in the world and regarded by many as one of the greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d'Or awards,[note 2] the most for a European player, and is the first player to win four European Golden Shoes. He has won 26 trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored in Europe's top-five leagues (395), the UEFA Champions League (120), the UEFA European Championship (9), as well as those for most assists in the UEFA Champions League (34) and the UEFA European Championship (6). He has scored over 670 senior career goals for club and country. Born and raised on the Portuguese isla\\n\\nFull Document (Truncated):\\n\\nCristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:'['}.mw-c ollapsible-toggle-default:after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw- content-ltr .mw-content-rtl toggle{float:none} position:center center;background-repeat:no-re peat}.mw-spinner-small{background- image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\\n\\n.mw-collapsible- .mw-spinner{background-color:transparent;background-\\n\\ncaption\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question: when did now thats what i call music come out\\n\\nAnswer: 28 November 1983\\n\\nContext:\\n\\nNow That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now! series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release of the 100th volume of the series.[4]\\n\\nFull Document (Truncated):\\n\\nNow - Wikipedia .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\\n\\nThat's What\\n\\nI\\n\\nCall\\n\\nMusic\\n\\n(original\\n\\nUK\\n\\nalbum)\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content='Question: who warned concord that the british were coming\\n\\nAnswer: Samuel Prescott\\n\\nContext:\\n\\nSamuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary War. He is best remembered for his role in Paul Revere\\'s \"midnight ride\" to warn the townspeople of Concord of the impending British army move to capture guns and gunpowder kept there at the beginning of the American Revolution. He was the only participant in the ride to reach Concord.[1] <\\n\\nFull Document (Truncated):\\n\\nSamuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont -sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\\n\\nsolid', metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question: 100 acres is equal to how many hectares\\n\\nAnswer: 100 Acres is equal to 40.46 Hectares.\\n\\nContext: The hectare (/nhn ktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area equal to 100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains about 2.47 acres. In 1795, whe\\n\\nFull Document (Truncated):\\n\\nHectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo 2px nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content='Question: who spread the theory that one is a product of the mind and body\\n\\nAnswer: René Descartes.\\n\\nContext:\\n\\nirect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans\\' \"intelligence\" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\\n\\nFull Document (Truncated):\\n\\nPhilosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content='Question: when did nsw last won a state of origin series\\n\\nAnswer: 2024\\n\\nContext:\\n\\nmargin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland 3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland 1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales 3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales 2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New South Wales <\\n\\nFull Document (Truncated):\\n\\nWikipedia State .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET REMOVED_SECRETDSinIHQozUcuISCI...\\n\\nof\\n\\nOrigin\\n\\nseries\\n\\n', metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content=\"Question: who designed the national coat of arms of south africa\\n\\nAnswer: Iaan Bekker.\\n\\nContext:\\n\\nign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\\n\\nFull Document (Truncated):\\n\\nCoat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px #bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content=\"Question: when was the first robot used in surgery\\n\\nAnswer: The Arthrobot.\\n\\nContext:\\n\\nrobot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, which handed operative instruments on voice command, and a medical laboratory robotic arm. A YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\\n\\nFull Document (Truncated):\\n\\nRobot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 335.24it/s]\n",
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning:\n",
      "\n",
      "The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "\n",
      "/tmp/ipykernel_334995/4146345483.py:41: MatplotlibDeprecationWarning:\n",
      "\n",
      "The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``REMOVED_SECRET()`` or ``pyplot.get_cmap()`` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP progress animation saved as 'umap_progress_animation.gif'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obb/codes/langers/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning:\n",
      "\n",
      "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.REMOVED_SECRET4\n",
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['REMOVED_SECRET.bias', 'REMOVED_SECRET.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:00<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content=\"Question: fish appeared in the fossil record during the\\n\\nAnswer: During the Cambrian Explosion.\\n\\nContext:\\n\\nution of fish began about 530 million years ago during the Cambrian explosion. It was during this time that the early chordates developed the skull and the vertebral column, leading to the first craniates and vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which includes the extant hagfish, and this group may have split early on from other agnathans. The first\\n\\nFull Document (Truncated):\\n\\nEvolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa li{background:#fff;border:1px city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > 10px solid rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli\", metadata={'source': 'local_database/nq_sample_28.pdf'}), Document(page_content=\"Question: when does grey's anatomy season 14 premiere\\n\\nAnswer: September 28, 2017\\n\\nContext:\\n\\nGrey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti Country of origin United States No. of episodes 12 Release Original network ABC Original release September 28, 2017 (2017-09-28) – present Season chronology ‹ Previous Season 13 List of Grey's Anatomy episodes The\\n\\nFull Document (Truncated):\\n\\nGrey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none...\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_13.pdf'}), Document(page_content=\"Question: who established the peoples republic of china in 1949\\n\\nAnswer: Mao Zedong\\n\\nContext:\\n\\n> details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties. Con\\n\\nFull Document (Truncated):\\n\\nHistory of the People's Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_7.pdf'}), Document(page_content=\"Question: who holds the most women's wimbledon titles\\n\\nAnswer: Martina Navratilova.\\n\\nContext:\\n\\nWimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Open Era: 1968(51 editions)Surface Grass AELTC (1884–Present)Prize money £ 2,000,000 (2016)Trophy Venus Rosewater DishWebsite REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea (regular)Open era 9: Martina round)8: Helen Wills Moody Lambert Chambers(challenge NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st singles title) <\\n\\n/ LTACreated 1884\\n\\nFull Document (Truncated):\\n\\nList of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no > ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_24.pdf'}), Document(page_content='Question: who plays percy in the lost city of z\\n\\nAnswer: Charlie Hunnam.\\n\\nContext:\\n\\nwas optioned by Brad Pitt\\'s Plan B production company and Paramount Pictures. James Gray directed the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the Condor (1933), one of W. E. Johns\\' \"Bigg\\n\\nFull Document (Truncated):\\n\\nPercy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci 2px ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_23.pdf'}), Document(page_content=\"Question: when does life is strange before the storm part 2\\n\\nAnswer: October 2017\\n\\nContext:\\n\\nLife Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017 Genre(s) Graphic adventure Mode(s) Single-player\\n\\nFull Document (Truncated):\\n\\nLife Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 13px 2px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shad...\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_2.pdf'}), Document(page_content='Question: how many beverly hills cops movies are there\\n\\nAnswer: Three.\\n\\nContext:\\n\\nI>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel\\'s boss, Inspector Todd, are the only actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The films have made a total of $735,534,503[citation needed] at the worldwide box office.\\n\\nFull Document (Truncated):\\n\\nBeverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_26.pdf'}), Document(page_content=\"Question: where does jinx you owe me a coke come from\\n\\nAnswer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\\n\\nContext:\\n\\nJinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously.[1][2]\\n\\nFull Document (Truncated):\\n\\nJinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_4.pdf'}), Document(page_content='Question: who is ted talking about in how i met your mother\\n\\nAnswer: Tracy McConnell\\n\\nContext:\\n\\nTracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an unseen character; she was first seen fully in \"Something New\" and was promoted to a main character in season 9. The Mother is played by Cristin Milioti.\\n\\nFull Document (Truncated):\\n\\nThe Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-sha...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_9.pdf'}), Document(page_content=\"Question: where is the greatest royal rumble taking place\\n\\nAnswer: Jeddah, Saudi Arabia\\n\\nContext:\\n\\nGreatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27, 2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships were defended, in addition to a 50-man Royal Rumble match.[9]\\n\\nFull Document (Truncated):\\n\\nWWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px 10px 0 rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;bor...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_12.pdf'}), Document(page_content=\"Question: the human tendency to mimic other people’s behavior is an example of\\n\\nAnswer: Mirroring\\n\\nContext:\\n\\nMirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or attitude of another. Mirroring often occurs in social situations, particularly in the company of close friends or family. The concept often affects other individuals' notions about the individual that is exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\\n\\nFull Document (Truncated):\\n\\nMirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no > ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;border...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_14.pdf'}), Document(page_content=\"Question: who won season 4 of america's got talent\\n\\nAnswer: Kevin Skinner\\n\\nContext:\\n\\n>fourth season of America's Got Talent, an American television reality show talent competition, premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner on September 16, 2009. This season is the first season to be broadcast in high definition. This s\\n\\nFull Document (Truncated):\\n\\nAmerica's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cur...\\n\\nsolid\", metadata={'source': 'local_database/nq_sample_10.pdf'}), Document(page_content=\"Question: when does model code of conduct come into force\\n\\nAnswer: immediately on announcement of the election schedule by the commission\\n\\nContext:\\n\\nElection Commission of India's Model Code of Conduct is a set of guidelines issued by the Election Commission of India for conduct of political parties and candidates during elections mainly with respect to speeches, polling day, polling booths, election manifestos, processions and general conduct. These set of norms has been evolved with the consensus of political parties who have consented to abide by the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into force immediately on announcement of the election schedule by the commission for the need of ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt practices. For example, politicians should not make hate speeches, putting one community against another or make promises about new projects that may sway a voter.\\n\\nFull Document (Truncated):\\n\\nElection Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool 10px tip solid rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{...\\n\\n>\\n\\nli{background:#fff;border:1px\\n\\n#bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);box-shadow:0\\n\\n0 0\\n\\n0\\n\\n10px\", metadata={'source': 'local_database/nq_sample_8.pdf'}), Document(page_content=\"Question: who signed the gun control act of 1968\\n\\nAnswer: Lyndon B. Johnson\\n\\nContext:\\n\\nCA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\\n\\nFull Document (Truncated):\\n\\nGun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;borde...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_29.pdf'}), Document(page_content=\"Question: who plays nicholas in the princess diaries 2\\n\\nAnswer: Chris Pine.\\n\\nContext:\\n\\nst of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux (Chris Pine), and Andrew Jacoby (Callum Blue). Des\\n\\nFull Document (Truncated):\\n\\nThe Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-b...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_21.pdf'}), Document(page_content=\"Question: which city and state hosts the annual college world series\\n\\nAnswer: Omaha, Nebraska\\n\\nContext:\\n\\nThe College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska. The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division I college baseball champion. The eight participating four-team, double-elimination brackets, with the winners of each bracket playing in a best-of-three championship series.\\n\\nteams are split\\n\\ninto\\n\\ntwo,\\n\\nFull Document (Truncated):\\n\\nCollege World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_5.pdf'}), Document(page_content=\"Question: who pays the judgements on the judge mathis show\\n\\nAnswer: The show pays the judgement to the winning party.\\n\\nContext:\\n\\nI>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating small claims disputes.\\n\\nFull Document (Truncated):\\n\\ntop:-99999px;clip:rect(1px 1px 1px 1px); Judge Mathis !important;border:0 clip:rect(1px,1px,1px,1px); overflow:hidden} !important;height:1px .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\\n\\nWikipedia\\n\\n.cite-accessibility-label{ position:absolute !important;width:1px\\n\\n!important;padding:0\\n\\n!important;\", metadata={'source': 'local_database/nq_sample_16.pdf'}), Document(page_content='Question: who sang take that look off your face\\n\\nAnswer: Marti Webb\\n\\nContext:\\n\\n\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song and Dance.\\n\\nFull Document (Truncated):\\n\\nTake That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px 10px rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'local_database/nq_sample_22.pdf'}), Document(page_content=\"Question: when did the hornets move to new orleans\\n\\nAnswer: 2002, and then 2007.\\n\\nContext:\\n\\nestablished as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, 2014.[1] In 14 seasons of play since the\\n\\nFull Document (Truncated):\\n\\nNew Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_27.pdf'}), Document(page_content='Question: where was donovan mitchell picked in the draft\\n\\nAnswer: 13th overall pick by the Denver Nuggets.\\n\\nContext:\\n\\n=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July 5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the 2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed Darrell Griffith\\'s team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January 4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, 2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western Conference Rookie of the Month for March and April.[28] In Mitchell\\'s playoff debut against\\n\\nFull Document (Truncated):\\n\\nDonovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op li{background:#fff;border:1px acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > solid 10px rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_25.pdf'}), Document(page_content=\"Question: who made up the elf on the shelf\\n\\nAnswer: Carol Aebersold and daughter Chanda Bell\\n\\nContext:\\n\\n>The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the family to share her expertise in sales and marketing. Together, the trio devoted the next three years promoting their self-published book and attending book signings and trade shows. <\\n\\nFull Document (Truncated):\\n\\nThe Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_11.pdf'}), Document(page_content='Question: who sings with shaggy on it wasn me\\n\\nAnswer: English-Jamaican singer Rikrok\\n\\nContext:\\n\\n\"It Wasn\\'t Me\" is the first single from Jamaican-American reggae artist Shaggy\\'s multi-Platinum studio album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\\n\\nFull Document (Truncated):\\n\\nIt Wasn\\'t Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity: 0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px rgba(0,0,0,0.2);box-shadow:0 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px + transparent li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\\n\\n0\\n\\n10px 0\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0 10px\\n\\n0\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'local_database/nq_sample_6.pdf'}), Document(page_content=\"Question: how many goals scored ronaldo in his career\\n\\nAnswer: He has scored over 670 senior career goals for club and country.\\n\\nContext: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal national team. Often considered the best player in the world and regarded by many as one of the greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d'Or awards,[note 2] the most for a European player, and is the first player to win four European Golden Shoes. He has won 26 trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored in Europe's top-five leagues (395), the UEFA Champions League (120), the UEFA European Championship (9), as well as those for most assists in the UEFA Champions League (34) and the UEFA European Championship (6). He has scored over 670 senior career goals for club and country. Born and raised on the Portuguese isla\\n\\nFull Document (Truncated):\\n\\nCristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:'['}.mw-c ollapsible-toggle-default:after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw- content-ltr .mw-content-rtl toggle{float:none} position:center center;background-repeat:no-re peat}.mw-spinner-small{background- image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\\n\\n.mw-collapsible- .mw-spinner{background-color:transparent;background-\\n\\ncaption\", metadata={'source': 'local_database/nq_sample_1.pdf'}), Document(page_content=\"Question: when did now thats what i call music come out\\n\\nAnswer: 28 November 1983\\n\\nContext:\\n\\nNow That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now! series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release of the 100th volume of the series.[4]\\n\\nFull Document (Truncated):\\n\\nNow - Wikipedia .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\\n\\nThat's What\\n\\nI\\n\\nCall\\n\\nMusic\\n\\n(original\\n\\nUK\\n\\nalbum)\", metadata={'source': 'local_database/nq_sample_18.pdf'}), Document(page_content='Question: who warned concord that the british were coming\\n\\nAnswer: Samuel Prescott\\n\\nContext:\\n\\nSamuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary War. He is best remembered for his role in Paul Revere\\'s \"midnight ride\" to warn the townspeople of Concord of the impending British army move to capture guns and gunpowder kept there at the beginning of the American Revolution. He was the only participant in the ride to reach Concord.[1] <\\n\\nFull Document (Truncated):\\n\\nSamuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont -sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\\n\\nsolid', metadata={'source': 'local_database/nq_sample_17.pdf'}), Document(page_content=\"Question: 100 acres is equal to how many hectares\\n\\nAnswer: 100 Acres is equal to 40.46 Hectares.\\n\\nContext: The hectare (/nhn ktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area equal to 100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains about 2.47 acres. In 1795, whe\\n\\nFull Document (Truncated):\\n\\nHectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo 2px nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_3.pdf'}), Document(page_content='Question: who spread the theory that one is a product of the mind and body\\n\\nAnswer: René Descartes.\\n\\nContext:\\n\\nirect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans\\' \"intelligence\" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\\n\\nFull Document (Truncated):\\n\\nPhilosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'local_database/nq_sample_19.pdf'}), Document(page_content='Question: when did nsw last won a state of origin series\\n\\nAnswer: 2024\\n\\nContext:\\n\\nmargin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland 3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland 1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales 3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales 2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New South Wales <\\n\\nFull Document (Truncated):\\n\\nWikipedia State .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET REMOVED_SECRETDSinIHQozUcuISCI...\\n\\nof\\n\\nOrigin\\n\\nseries\\n\\n', metadata={'source': 'local_database/nq_sample_15.pdf'}), Document(page_content=\"Question: who designed the national coat of arms of south africa\\n\\nAnswer: Iaan Bekker.\\n\\nContext:\\n\\nign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\\n\\nFull Document (Truncated):\\n\\nCoat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px #bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'local_database/nq_sample_20.pdf'}), Document(page_content=\"Question: when was the first robot used in surgery\\n\\nAnswer: The Arthrobot.\\n\\nContext:\\n\\nrobot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, which handed operative instruments on voice command, and a medical laboratory robotic arm. A YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\\n\\nFull Document (Truncated):\\n\\nRobot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'local_database/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 336.57it/s]\n",
      "Evaluating samples:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: fish appeared in the fossil record during the\n",
      "Ground Truth: during the cambrian explosion.\n",
      "Original Context: ution of fish began about 530 million years ago during the Cambrian explosion. It was during this time \n",
      "that the early chordates developed the skull and the vertebral column, leading to the first cran...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   3%|▎         | 1/30 [00:13<06:22, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 530 million years ago during the cambrian explosion. document 2: context\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: fish appeared in the fossil record during the\n",
      "\n",
      "Answer: During the Cambrian Explosion.\n",
      "\n",
      "Context:\n",
      "\n",
      "ution of fish began about 530 million years ago during the Cambrian explosion. It was during ...\n",
      "BLEU Score: 0.2346\n",
      "ROUGE-L F1: 0.5333\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: 0.4430\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5333\n",
      "\n",
      "\n",
      "Question: when does grey's anatomy season 14 premiere\n",
      "Ground Truth: september 28, 2017\n",
      "Original Context: Grey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra \n",
      "Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina \n",
      "Scorsone Camilla...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   7%|▋         | 2/30 [00:36<08:53, 19.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 2019 document: greys anatomy (season 14) -\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "Grey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.ref...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: -0.1926\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: who established the peoples republic of china in 1949\n",
      "Ground Truth: mao zedong\n",
      "Original Context: > details the history of mainland China since October 1, 1949, when, after a near complete victory by\n",
      "the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People's\n",
      "Rep...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  10%|█         | 3/30 [00:47<06:54, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: mao zedong\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who established the peoples republic of china in 1949\n",
      "\n",
      "Answer: Mao Zedong\n",
      "\n",
      "Context:\n",
      "\n",
      "> details the history of mainland China since October 1, 1949, when, after a near complete victory by the...\n",
      "BLEU Score: 0.2214\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 1.0000\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "\n",
      "\n",
      "Question: who holds the most women's wimbledon titles\n",
      "Ground Truth: martina navratilova.\n",
      "Original Context: Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body \n",
      "AELTC \n",
      "/ \n",
      "LTACreated \n",
      "1884 \n",
      "(established)Open \n",
      "Era: \n",
      "1968(51 \n",
      "editions)Surface \n",
      "Grass \n",
      "(1884–Present)Prize \n",
      "m...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  13%|█▎        | 4/30 [01:00<06:14, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: martina navratilova\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who holds the most women's wimbledon titles\n",
      "\n",
      "Answer: Martina Navratilova.\n",
      "\n",
      "Context:\n",
      "\n",
      "Wimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Op...\n",
      "BLEU Score: 0.0675\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.9446\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5000\n",
      "\n",
      "\n",
      "Question: who plays percy in the lost city of z\n",
      "Ground Truth: charlie hunnam.\n",
      "Original Context: was optioned by Brad Pitt's Plan B production company and Paramount Pictures. James Gray directed \n",
      "the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the \n",
      "Co...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  17%|█▋        | 5/30 [01:11<05:27, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: charlie hunnam\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who plays percy in the lost city of z\n",
      "\n",
      "Answer: Charlie Hunnam.\n",
      "\n",
      "Context:\n",
      "\n",
      "was optioned by Brad Pitt's Plan B production company and Paramount Pictures. James Gray directed the film, which st...\n",
      "BLEU Score: 0.0675\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.9365\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5000\n",
      "\n",
      "\n",
      "Question: when does life is strange before the storm part 2\n",
      "Ground Truth: october 2017\n",
      "Original Context: Life Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb\n",
      "Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham\n",
      "Prog...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  20%|██        | 6/30 [01:26<05:36, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 2017\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "Life Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding...\n",
      "BLEU Score: 0.3679\n",
      "ROUGE-L F1: 0.6667\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: -0.1520\n",
      "Exact Match: 0\n",
      "F1 Score: 0.6667\n",
      "\n",
      "\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: three.\n",
      "Original Context: I>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on\n",
      "characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel F...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  23%|██▎       | 7/30 [01:47<06:13, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 3 document: beverly hills cop (film series) - wikipedia beverly\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "Beverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.2000\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: where does jinx you owe me a coke come from\n",
      "Ground Truth: jinx is a childrens game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\n",
      "Original Context: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally\n",
      "speak the same word or phrase simultaneously.[1][2]\n",
      "Full Document (Truncated):\n",
      "Jinx (children's ga...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  27%|██▋       | 8/30 [02:10<06:42, 18.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: the origin of the phrase \"jinx, you owe me a coke\" is not specified in the provided\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: where does jinx you owe me a coke come from\n",
      "\n",
      "Answer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simul...\n",
      "BLEU Score: 0.0148\n",
      "ROUGE-L F1: 0.1500\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.0006\n",
      "Exact Match: 0\n",
      "F1 Score: 0.2000\n",
      "\n",
      "\n",
      "Question: who is ted talking about in how i met your mother\n",
      "Ground Truth: tracy mcconnell\n",
      "Original Context: Tracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom\n",
      "How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The\n",
      "M...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n",
      "Generated Answer: tracy mcconnell (the mother)\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who is ted talking about in how i met your mother\n",
      "\n",
      "Answer: Tracy McConnell\n",
      "\n",
      "Context:\n",
      "\n",
      "Tracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  30%|███       | 9/30 [02:33<06:57, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.1682\n",
      "ROUGE-L F1: 0.6667\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.7595\n",
      "Exact Match: 0\n",
      "F1 Score: 0.6667\n",
      "\n",
      "\n",
      "Question: where is the greatest royal rumble taking place\n",
      "Ground Truth: jeddah, saudi arabia\n",
      "Original Context: Greatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network\n",
      "event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27,\n",
      "2018 at the ...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  33%|███▎      | 10/30 [02:55<06:49, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 1988 wwe event in philadelphia, pennsylvania\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "WWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.re...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: -0.1440\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: the human tendency to mimic other people’s behavior is\n",
      "Ground Truth: mirroring\n",
      "Original Context: Mirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or\n",
      "attitude of another. Mirroring often occurs in social situations, particularly in the company of ...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  37%|███▋      | 11/30 [03:22<07:06, 22.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: mirroring explanation: the term mirroring directly refers to the human t\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: the human tendency to mimic other people’s behavior is an example of\n",
      "\n",
      "Answer: Mirroring\n",
      "\n",
      "Context:\n",
      "\n",
      "Mirroring is the behaviour in which one person subconsciously imitates the gesture, speech ...\n",
      "BLEU Score: 0.0216\n",
      "ROUGE-L F1: 0.1667\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.1378\n",
      "Exact Match: 0\n",
      "F1 Score: 0.1667\n",
      "\n",
      "\n",
      "Question: who won season 4 of america's got talent\n",
      "Ground Truth: kevin skinner\n",
      "Original Context: >fourth season of America's Got Talent, an American television reality show talent competition,\n",
      "premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner\n",
      "on Sept...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  40%|████      | 12/30 [03:39<06:17, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 2011\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "America's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-f...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: -0.1606\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: when does model code of conduct come into force\n",
      "Ground Truth: immediately on announcement of the election schedule by the commission\n",
      "Original Context: Election Commission of India's Model Code of Conduct is a set of guidelines issued by the Election\n",
      "Commission of India for conduct of political parties and candidates during elections mainly with resp...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  43%|████▎     | 13/30 [03:57<05:40, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: immediately on announcement of the election schedule by the commission\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: when does model code of conduct come into force\n",
      "\n",
      "Answer: immediately on announcement of the election schedule by the commission\n",
      "\n",
      "Context:\n",
      "\n",
      "Election Commission of India's Model Code of Conduc...\n",
      "BLEU Score: 1.0000\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: 1.0000\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "\n",
      "\n",
      "Question: who signed the gun control act of 1968\n",
      "Ground Truth: lyndon b. johnson\n",
      "Original Context: CA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. \n",
      "federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are ...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  47%|████▋     | 14/30 [04:15<05:07, 19.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: president lyndon b. johnson\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "Gun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.refe...\n",
      "BLEU Score: 0.4315\n",
      "ROUGE-L F1: 0.8571\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.7854\n",
      "Exact Match: 0\n",
      "F1 Score: 0.8571\n",
      "\n",
      "\n",
      "Question: who plays nicholas in the princess diaries 2\n",
      "Ground Truth: chris pine.\n",
      "Original Context: st of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, \n",
      "Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to ...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  50%|█████     | 15/30 [04:34<04:49, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: chris pine\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who plays nicholas in the princess diaries 2\n",
      "\n",
      "Answer: Chris Pine.\n",
      "\n",
      "Context:\n",
      "\n",
      "st of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Mat...\n",
      "BLEU Score: 0.0675\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: 0.8388\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5000\n",
      "\n",
      "\n",
      "Question: which city and state hosts the annual college world series\n",
      "Ground Truth: omaha, nebraska\n",
      "Original Context: The College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska.\n",
      "The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball\n",
      "C...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  53%|█████▎    | 16/30 [04:46<03:58, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: omaha, nebraska\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: which city and state hosts the annual college world series\n",
      "\n",
      "Answer: Omaha, Nebraska\n",
      "\n",
      "Context:\n",
      "\n",
      "The College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska...\n",
      "BLEU Score: 0.2214\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 1.0000\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "\n",
      "\n",
      "Question: who pays the judgements on the judge mathis show\n",
      "Ground Truth: the show pays the judgement to the winning party.\n",
      "Original Context: I>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge\n",
      "of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudica...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  57%|█████▋    | 17/30 [04:58<03:19, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: the winning party.\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who pays the judgements on the judge mathis show\n",
      "\n",
      "Answer: The show pays the judgement to the winning party.\n",
      "\n",
      "Context:\n",
      "\n",
      "I>Judge Mathis is a syndicated arbitration-based reality court show pre...\n",
      "BLEU Score: 0.0779\n",
      "ROUGE-L F1: 0.5000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.4898\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5000\n",
      "\n",
      "\n",
      "Question: who sang take that look off your face\n",
      "Ground Truth: marti webb\n",
      "Original Context: \"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd\n",
      "Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a\n",
      "Su...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  60%|██████    | 18/30 [05:13<03:06, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: queen queen\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "Take That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.0778\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: when did the hornets move to new orleans\n",
      "Ground Truth: 2002, and then 2007.\n",
      "Original Context: established as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte \n",
      "Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by \n",
      "Hurricane Kat...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  63%|██████▎   | 19/30 [05:29<02:50, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 2002, then 2007\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: when did the hornets move to new orleans\n",
      "\n",
      "Answer: 2002, and then 2007.\n",
      "\n",
      "Context:\n",
      "\n",
      "established as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, Georg...\n",
      "BLEU Score: 0.0618\n",
      "ROUGE-L F1: 0.8571\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: 0.7524\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5714\n",
      "\n",
      "\n",
      "Question: where was donovan mitchell picked in the draft\n",
      "Ground Truth: 13th overall pick by the denver nuggets.\n",
      "Original Context: =\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 \n",
      "NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] O...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  67%|██████▋   | 20/30 [05:44<02:33, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 13th overall pick by the denver nuggets.\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: where was donovan mitchell picked in the draft\n",
      "\n",
      "Answer: 13th overall pick by the Denver Nuggets.\n",
      "\n",
      "Context:...\n",
      "BLEU Score: 1.0000\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 1.0000\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "\n",
      "\n",
      "Question: who made up the elf on the shelf\n",
      "Ground Truth: carol aebersold and daughter chanda bell\n",
      "Original Context: >The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of\n",
      "tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to\n",
      "w...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  70%|███████   | 21/30 [06:08<02:41, 17.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: the creator of the elf on the shelf is not specified in the provided context. document\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "The Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.refer...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: -0.2875\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: who sings with shaggy on it wasn me\n",
      "Ground Truth: english-jamaican singer rikrok\n",
      "Original Context: \"It Wasn't Me\" is the first single from Jamaican-American reggae artist Shaggy's multi-Platinum studio\n",
      "album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\n",
      "Full Documen...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  73%|███████▎  | 22/30 [06:24<02:18, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: rikrok\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who sings with shaggy on it wasn me\n",
      "\n",
      "Answer: English-Jamaican singer Rikrok\n",
      "\n",
      "Context:\n",
      "\n",
      "\"It Wasn't Me\" is the first single from Jamaican-American reggae artist Shaggy's multi-Platinum studio ...\n",
      "BLEU Score: 0.1353\n",
      "ROUGE-L F1: 0.4000\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: -0.0093\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5000\n",
      "\n",
      "\n",
      "Question: how many goals scored ronaldo in his career\n",
      "Ground Truth: he has scored over 670 senior career goals for club and country.\n",
      "Original Context: s Aveiro GOIH ComM (European Portuguese: [kIiIItjInu IoInaIdu]; born 5 February 1985) is a \n",
      "Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal \n",
      "nation...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  77%|███████▋  | 23/30 [06:36<01:50, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 670 goals\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: how many goals scored ronaldo in his career\n",
      "\n",
      "Answer: He has scored over 670 senior career goals for club and country.\n",
      "\n",
      "Context: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]...\n",
      "BLEU Score: 0.0005\n",
      "ROUGE-L F1: 0.2857\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: 0.0931\n",
      "Exact Match: 0\n",
      "F1 Score: 0.2857\n",
      "\n",
      "\n",
      "Question: when did now thats what i call music come out\n",
      "Ground Truth: 28 november 1983\n",
      "Original Context: Now That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now!\n",
      "series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were\n",
      "re...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  80%|████████  | 24/30 [06:55<01:39, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 1993 document 2: title: now thats what i call music\n",
      "Retrieved Documents:\n",
      "Doc 1: That's What\n",
      "\n",
      "I\n",
      "\n",
      "Call\n",
      "\n",
      "Music\n",
      "\n",
      "(original\n",
      "\n",
      "UK\n",
      "\n",
      "album)...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: -0.3108\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: who warned concord that the british were coming\n",
      "Ground Truth: samuel prescott\n",
      "Original Context: Samuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American\n",
      "Revolutionary War. He is best remembered for his role in Paul Revere's \"midnight ride\" to warn the\n",
      "townspeop...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  83%|████████▎ | 25/30 [07:07<01:16, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: samuel prescott\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who warned concord that the british were coming\n",
      "\n",
      "Answer: Samuel Prescott\n",
      "\n",
      "Context:\n",
      "\n",
      "Samuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary ...\n",
      "BLEU Score: 0.2214\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 1.0000\n",
      "Exact Match: 1\n",
      "F1 Score: 1.0000\n",
      "\n",
      "\n",
      "Question: 100 acres is equal to how many hectares\n",
      "Ground Truth: 100 acres is equal to 40.46 hectares.\n",
      "Original Context: The hectare (/IhIktIIr, -tIIr/; SI symbol: ha) is an SI accepted metric system unit of area equal to \n",
      "100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  87%|████████▋ | 26/30 [07:27<01:06, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 40.46 hectares explanation: the context provides the conversion rate between acres and\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: 100 acres is equal to how many hectares\n",
      "\n",
      "Answer: 100 Acres is equal to 40.46 Hectares.\n",
      "\n",
      "Context: The hectare (/nhn ktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area ...\n",
      "BLEU Score: 0.0238\n",
      "ROUGE-L F1: 0.2857\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: 0.2490\n",
      "Exact Match: 0\n",
      "F1 Score: 0.2105\n",
      "\n",
      "\n",
      "Question: who spread the theory that one is a product of the mind\n",
      "Ground Truth: ren descartes.\n",
      "Original Context: irect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in \n",
      "the writings of Plato who maintained that humans' \"intelligence\" (a faculty of the mind or soul)...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  90%|█████████ | 27/30 [07:37<00:43, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: ren descartes\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: who spread the theory that one is a product of the mind and body\n",
      "\n",
      "Answer: René Descartes.\n",
      "\n",
      "Context:\n",
      "\n",
      "irect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist...\n",
      "BLEU Score: 0.0675\n",
      "ROUGE-L F1: 1.0000\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: 0.8536\n",
      "Exact Match: 0\n",
      "F1 Score: 0.5000\n",
      "\n",
      "\n",
      "Question: when did nsw last won a state of origin series\n",
      "Ground Truth: 2024\n",
      "Original Context: margin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 \n",
      "Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 \n",
      "Queensland 1985 New Sout...\n",
      "Warning: Invalid ground truth for question: when did nsw last won a state of origin series\n",
      "\n",
      "\n",
      "Question: who designed the national coat of arms of south africa\n",
      "Ground Truth: iaan bekker.\n",
      "Original Context: ign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology \n",
      "requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  97%|█████████▋| 29/30 [07:59<00:13, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 1994 design by peter schffer\n",
      "Retrieved Documents:\n",
      "Doc 1: Full Document (Truncated):\n",
      "\n",
      "Coat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}...\n",
      "BLEU Score: 0.0000\n",
      "ROUGE-L F1: 0.0000\n",
      "Retrieval Accuracy: 0.0000\n",
      "BERT Score: -0.1478\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0000\n",
      "\n",
      "\n",
      "Question: when was the first robot used in surgery\n",
      "Ground Truth: the arthrobot.\n",
      "Original Context: robot to assist in surgery was the Arthrobot, which was developed and used for the first time in \n",
      "Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof \n",
      "Auchinlec...\n",
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 100%|██████████| 30/30 [08:20<00:00, 16.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: 1984 explanation: the context mentions that the arthrobot was used for the first\n",
      "Retrieved Documents:\n",
      "Doc 1: Question: when was the first robot used in surgery\n",
      "\n",
      "Answer: The Arthrobot.\n",
      "\n",
      "Context:\n",
      "\n",
      "robot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983...\n",
      "BLEU Score: 0.0187\n",
      "ROUGE-L F1: 0.2667\n",
      "Retrieval Accuracy: 1.0000\n",
      "BERT Score: 0.4391\n",
      "Exact Match: 0\n",
      "F1 Score: 0.1333\n",
      "Created visualization for question 0: fish appeared in the fossil record during the...\n",
      "Created visualization for question 1: when does grey's anatomy season 14 premiere...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created visualization for question 2: who established the peoples republic of china in 1...\n",
      "Created visualization for question 3: who holds the most women's wimbledon titles...\n",
      "Created visualization for question 4: who plays percy in the lost city of z...\n",
      "Created visualization for question 5: when does life is strange before the storm part 2...\n",
      "Created visualization for question 6: how many beverly hills cops movies are there...\n",
      "Created visualization for question 7: where does jinx you owe me a coke come from...\n",
      "Created visualization for question 8: who is ted talking about in how i met your mother...\n",
      "Created visualization for question 9: where is the greatest royal rumble taking place...\n",
      "Created visualization for question 10: the human tendency to mimic other people’s behavio...\n",
      "Created visualization for question 11: who won season 4 of america's got talent...\n",
      "Created visualization for question 12: when does model code of conduct come into force...\n",
      "Created visualization for question 13: who signed the gun control act of 1968...\n",
      "Created visualization for question 14: who plays nicholas in the princess diaries 2...\n",
      "Created visualization for question 15: which city and state hosts the annual college worl...\n",
      "Created visualization for question 16: who pays the judgements on the judge mathis show...\n",
      "Created visualization for question 17: who sang take that look off your face...\n",
      "Created visualization for question 18: when did the hornets move to new orleans...\n",
      "Created visualization for question 19: where was donovan mitchell picked in the draft...\n",
      "Created visualization for question 20: who made up the elf on the shelf...\n",
      "Created visualization for question 21: who sings with shaggy on it wasn me...\n",
      "Created visualization for question 22: how many goals scored ronaldo in his career...\n",
      "Created visualization for question 23: when did now thats what i call music come out...\n",
      "Created visualization for question 24: who warned concord that the british were coming...\n",
      "Created visualization for question 25: 100 acres is equal to how many hectares...\n",
      "Created visualization for question 26: who spread the theory that one is a product of the...\n",
      "Created visualization for question 27: who designed the national coat of arms of south af...\n",
      "Created visualization for question 28: when was the first robot used in surgery...\n",
      "UMAP visualization created with 73 document chunks.\n",
      "Number of unique labels: 30\n",
      "Label distribution:\n",
      "  Label 0: 2 chunks\n",
      "  Label 1: 2 chunks\n",
      "  Label 2: 2 chunks\n",
      "  Label 3: 2 chunks\n",
      "  Label 4: 2 chunks\n",
      "  Label 5: 2 chunks\n",
      "  Label 6: 2 chunks\n",
      "  Label 7: 3 chunks\n",
      "  Label 8: 2 chunks\n",
      "  Label 9: 2 chunks\n",
      "  Label 10: 2 chunks\n",
      "  Label 11: 2 chunks\n",
      "  Label 12: 2 chunks\n",
      "  Label 13: 2 chunks\n",
      "  Label 14: 2 chunks\n",
      "  Label 15: 2 chunks\n",
      "  Label 16: 4 chunks\n",
      "  Label 17: 2 chunks\n",
      "  Label 18: 2 chunks\n",
      "  Label 19: 7 chunks\n",
      "  Label 20: 2 chunks\n",
      "  Label 21: 2 chunks\n",
      "  Label 22: 3 chunks\n",
      "  Label 23: 4 chunks\n",
      "  Label 24: 2 chunks\n",
      "  Label 25: 2 chunks\n",
      "  Label 26: 2 chunks\n",
      "  Label 27: 4 chunks\n",
      "  Label 28: 2 chunks\n",
      "  Label 29: 2 chunks\n",
      "       bleu_score     rouge1     rouge2     rougeL  retrieval_accuracy  \\\n",
      "count   29.000000  29.000000  29.000000  29.000000           29.000000   \n",
      "mean     0.154866   0.511412   0.411238   0.504680            0.413793   \n",
      "std      0.260797   0.416453   0.446679   0.420503            0.501230   \n",
      "min      0.000000   0.000000   0.000000   0.000000            0.000000   \n",
      "25%      0.000000   0.000000   0.000000   0.000000            0.000000   \n",
      "50%      0.067544   0.500000   0.210526   0.500000            0.000000   \n",
      "75%      0.221389   1.000000   1.000000   1.000000            1.000000   \n",
      "max      1.000000   1.000000   1.000000   1.000000            1.000000   \n",
      "\n",
      "       bert_score    perplexity  exact_match   f1_score  \n",
      "count   29.000000  2.900000e+01    29.000000  29.000000  \n",
      "mean     0.399877  1.866137e+06     0.172414   0.423844  \n",
      "std      0.477979  1.826937e+06     0.384426   0.365298  \n",
      "min     -0.310758  4.215373e+04     0.000000   0.000000  \n",
      "25%     -0.009262  7.807902e+05     0.000000   0.000000  \n",
      "50%      0.439114  1.394093e+06     0.000000   0.500000  \n",
      "75%      0.853624  1.883738e+06     0.000000   0.666667  \n",
      "max      1.000000  7.156238e+06     1.000000   1.000000  \n",
      "\n",
      "Average Scores:\n",
      "bleu_score            1.548656e-01\n",
      "rouge1                5.114122e-01\n",
      "rouge2                4.112383e-01\n",
      "rougeL                5.046798e-01\n",
      "retrieval_accuracy    4.137931e-01\n",
      "bert_score            3.998766e-01\n",
      "perplexity            1.866137e+06\n",
      "exact_match           1.724138e-01\n",
      "f1_score              4.238441e-01\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETSUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECREThkLnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETFv8fOZDS7A5YhqQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRET",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_REMOVED_SECRETCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETwraOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETozzaAvMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETgg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "REMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETREMOVED_SECRETAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Worst Predictions:\n",
      "Question: who sang take that look off your face\n",
      "Ground Truth: marti webb\n",
      "Generated Answer: queen queen\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who designed the national coat of arms of south africa\n",
      "Ground Truth: iaan bekker.\n",
      "Generated Answer: 1994 design by peter schffer\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when did now thats what i call music come out\n",
      "Ground Truth: 28 november 1983\n",
      "Generated Answer: 1993 document 2: title: now thats what i call music\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: three.\n",
      "Generated Answer: 3 document: beverly hills cop (film series) - wikipedia beverly\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: where is the greatest royal rumble taking place\n",
      "Ground Truth: jeddah, saudi arabia\n",
      "Generated Answer: 1988 wwe event in philadelphia, pennsylvania\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who won season 4 of america's got talent\n",
      "Ground Truth: kevin skinner\n",
      "Generated Answer: 2011\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who made up the elf on the shelf\n",
      "Ground Truth: carol aebersold and daughter chanda bell\n",
      "Generated Answer: the creator of the elf on the shelf is not specified in the provided context. document\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when does grey's anatomy season 14 premiere\n",
      "Ground Truth: september 28, 2017\n",
      "Generated Answer: 2019 document: greys anatomy (season 14) -\n",
      "BLEU Score: 0.0\n",
      "F1 Score: 0.0\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: how many goals scored ronaldo in his career\n",
      "Ground Truth: he has scored over 670 senior career goals for club and country.\n",
      "Generated Answer: 670 goals\n",
      "BLEU Score: 0.0005412204393808198\n",
      "F1 Score: 0.2857142857142857\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: where does jinx you owe me a coke come from\n",
      "Ground Truth: jinx is a childrens game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\n",
      "Generated Answer: the origin of the phrase \"jinx, you owe me a coke\" is not specified in the provided\n",
      "BLEU Score: 0.01484138751900486\n",
      "F1 Score: 0.19999999999999998\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "\n",
      "Error Patterns:\n",
      "short_answer: 16\n",
      "long_answer: 0\n",
      "low_bleu: 19\n",
      "low_f1: 13\n",
      "no_exact_match: 24\n",
      "\n",
      "Generated Answers:\n",
      "Question: fish appeared in the fossil record during the\n",
      "Ground Truth: during the cambrian explosion.\n",
      "Generated Answer: 530 million years ago during the cambrian explosion. document 2: context\n",
      "BLEU Score: 0.2346\n",
      "F1 Score: 0.5333\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when does grey's anatomy season 14 premiere\n",
      "Ground Truth: september 28, 2017\n",
      "Generated Answer: 2019 document: greys anatomy (season 14) -\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who established the peoples republic of china in 1949\n",
      "Ground Truth: mao zedong\n",
      "Generated Answer: mao zedong\n",
      "BLEU Score: 0.2214\n",
      "F1 Score: 1.0000\n",
      "Exact Match: 1\n",
      "--------------------\n",
      "Question: who holds the most women's wimbledon titles\n",
      "Ground Truth: martina navratilova.\n",
      "Generated Answer: martina navratilova\n",
      "BLEU Score: 0.0675\n",
      "F1 Score: 0.5000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who plays percy in the lost city of z\n",
      "Ground Truth: charlie hunnam.\n",
      "Generated Answer: charlie hunnam\n",
      "BLEU Score: 0.0675\n",
      "F1 Score: 0.5000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when does life is strange before the storm part 2\n",
      "Ground Truth: october 2017\n",
      "Generated Answer: 2017\n",
      "BLEU Score: 0.3679\n",
      "F1 Score: 0.6667\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: three.\n",
      "Generated Answer: 3 document: beverly hills cop (film series) - wikipedia beverly\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: where does jinx you owe me a coke come from\n",
      "Ground Truth: jinx is a childrens game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\n",
      "Generated Answer: the origin of the phrase \"jinx, you owe me a coke\" is not specified in the provided\n",
      "BLEU Score: 0.0148\n",
      "F1 Score: 0.2000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who is ted talking about in how i met your mother\n",
      "Ground Truth: tracy mcconnell\n",
      "Generated Answer: tracy mcconnell (the mother)\n",
      "BLEU Score: 0.1682\n",
      "F1 Score: 0.6667\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: where is the greatest royal rumble taking place\n",
      "Ground Truth: jeddah, saudi arabia\n",
      "Generated Answer: 1988 wwe event in philadelphia, pennsylvania\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: the human tendency to mimic other people’s behavior is\n",
      "Ground Truth: mirroring\n",
      "Generated Answer: mirroring explanation: the term mirroring directly refers to the human t\n",
      "BLEU Score: 0.0216\n",
      "F1 Score: 0.1667\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who won season 4 of america's got talent\n",
      "Ground Truth: kevin skinner\n",
      "Generated Answer: 2011\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when does model code of conduct come into force\n",
      "Ground Truth: immediately on announcement of the election schedule by the commission\n",
      "Generated Answer: immediately on announcement of the election schedule by the commission\n",
      "BLEU Score: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Exact Match: 1\n",
      "--------------------\n",
      "Question: who signed the gun control act of 1968\n",
      "Ground Truth: lyndon b. johnson\n",
      "Generated Answer: president lyndon b. johnson\n",
      "BLEU Score: 0.4315\n",
      "F1 Score: 0.8571\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who plays nicholas in the princess diaries 2\n",
      "Ground Truth: chris pine.\n",
      "Generated Answer: chris pine\n",
      "BLEU Score: 0.0675\n",
      "F1 Score: 0.5000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: which city and state hosts the annual college world series\n",
      "Ground Truth: omaha, nebraska\n",
      "Generated Answer: omaha, nebraska\n",
      "BLEU Score: 0.2214\n",
      "F1 Score: 1.0000\n",
      "Exact Match: 1\n",
      "--------------------\n",
      "Question: who pays the judgements on the judge mathis show\n",
      "Ground Truth: the show pays the judgement to the winning party.\n",
      "Generated Answer: the winning party.\n",
      "BLEU Score: 0.0779\n",
      "F1 Score: 0.5000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who sang take that look off your face\n",
      "Ground Truth: marti webb\n",
      "Generated Answer: queen queen\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when did the hornets move to new orleans\n",
      "Ground Truth: 2002, and then 2007.\n",
      "Generated Answer: 2002, then 2007\n",
      "BLEU Score: 0.0618\n",
      "F1 Score: 0.5714\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: where was donovan mitchell picked in the draft\n",
      "Ground Truth: 13th overall pick by the denver nuggets.\n",
      "Generated Answer: 13th overall pick by the denver nuggets.\n",
      "BLEU Score: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Exact Match: 1\n",
      "--------------------\n",
      "Question: who made up the elf on the shelf\n",
      "Ground Truth: carol aebersold and daughter chanda bell\n",
      "Generated Answer: the creator of the elf on the shelf is not specified in the provided context. document\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who sings with shaggy on it wasn me\n",
      "Ground Truth: english-jamaican singer rikrok\n",
      "Generated Answer: rikrok\n",
      "BLEU Score: 0.1353\n",
      "F1 Score: 0.5000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: how many goals scored ronaldo in his career\n",
      "Ground Truth: he has scored over 670 senior career goals for club and country.\n",
      "Generated Answer: 670 goals\n",
      "BLEU Score: 0.0005\n",
      "F1 Score: 0.2857\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when did now thats what i call music come out\n",
      "Ground Truth: 28 november 1983\n",
      "Generated Answer: 1993 document 2: title: now thats what i call music\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who warned concord that the british were coming\n",
      "Ground Truth: samuel prescott\n",
      "Generated Answer: samuel prescott\n",
      "BLEU Score: 0.2214\n",
      "F1 Score: 1.0000\n",
      "Exact Match: 1\n",
      "--------------------\n",
      "Question: 100 acres is equal to how many hectares\n",
      "Ground Truth: 100 acres is equal to 40.46 hectares.\n",
      "Generated Answer: 40.46 hectares explanation: the context provides the conversion rate between acres and\n",
      "BLEU Score: 0.0238\n",
      "F1 Score: 0.2105\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who spread the theory that one is a product of the mind\n",
      "Ground Truth: ren descartes.\n",
      "Generated Answer: ren descartes\n",
      "BLEU Score: 0.0675\n",
      "F1 Score: 0.5000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: who designed the national coat of arms of south africa\n",
      "Ground Truth: iaan bekker.\n",
      "Generated Answer: 1994 design by peter schffer\n",
      "BLEU Score: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Exact Match: 0\n",
      "--------------------\n",
      "Question: when was the first robot used in surgery\n",
      "Ground Truth: the arthrobot.\n",
      "Generated Answer: 1984 explanation: the context mentions that the arthrobot was used for the first\n",
      "BLEU Score: 0.0187\n",
      "F1 Score: 0.1333\n",
      "Exact Match: 0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Improved RAG System Evaluation Script\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from rouge_score import rouge_scorer\n",
    "from REMOVED_SECRET import sentence_bleu, SmoothingFunction\n",
    "from bert_score import BERTScorer\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from collections import Counter\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "from REMOVED_SECRET import cosine_similarity\n",
    "# Import your RAG system\n",
    "from RAG_UTILS import RAGSystem, EMBEDDING_MODEL_NAME, MODEL_ID, RERANKER_MODEL\n",
    "\n",
    "MODEL_ID = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "RERANKER_MODEL = None\n",
    "NUM_RETRIEVED_DOCS = 5\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    return text.lower().strip()\n",
    "\n",
    "def is_valid_answer(answer: str) -> bool:\n",
    "    \"\"\"Check if an answer is valid.\"\"\"\n",
    "    cleaned = clean_text(answer)\n",
    "    return len(cleaned) > 1 and not cleaned.isdigit()  # Adjust criteria as needed\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract question, context, and answer from a PDF file using PyMuPDF.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Regex patterns to extract information\n",
    "    question_pattern = r\"Question: (.*?)\\n\"\n",
    "    context_pattern = r\"Context:(.*?)(?=Question:|Answer:|$)\"\n",
    "    answer_pattern = r\"Answer: (.*?)(?=Context:|$)\"\n",
    "\n",
    "    questions = re.findall(question_pattern, text)\n",
    "    contexts = re.findall(context_pattern, text, re.DOTALL)\n",
    "    answers = re.findall(answer_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Clean and pair the extracted data\n",
    "    evaluation_data = []\n",
    "    for q, c, a in zip(questions, contexts, answers):\n",
    "        evaluation_data.append({\n",
    "            \"question\": q.strip(),\n",
    "            \"context\": c.strip(),\n",
    "            \"ground_truth\": a.strip()\n",
    "        })\n",
    "\n",
    "    return evaluation_data\n",
    "\n",
    "def calculate_perplexity(logits, input_ids):\n",
    "    # Ensure logits and input_ids have the same sequence length\n",
    "    seq_len = min(logits.size(1), input_ids.size(1))\n",
    "    logits = logits[:, :seq_len, :]\n",
    "    input_ids = input_ids[:, :seq_len]\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss_fct = REMOVED_SECRET(ignore_index=-100, reduction='none')\n",
    "    loss = loss_fct(logits.view(-1, logits.size(-1)), input_ids.view(-1))\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    return torch.exp(loss.mean())\n",
    "\n",
    "def calculate_retrieval_accuracy(retrieved_docs, ground_truth_context, k=1):\n",
    "    def preprocess_text(text):\n",
    "        return ' '.join(text.lower().split())\n",
    "\n",
    "    ground_truth_context = preprocess_text(ground_truth_context)\n",
    "    \n",
    "    relevant_docs = 0\n",
    "    for doc in retrieved_docs[:k]:\n",
    "        # Check if doc is a string or an object with page_content attribute\n",
    "        if isinstance(doc, str):\n",
    "            doc_text = preprocess_text(doc)\n",
    "        else:\n",
    "            doc_text = preprocess_text(doc.page_content)\n",
    "        \n",
    "        # Check for significant overlap\n",
    "        similarity = SequenceMatcher(None, ground_truth_context, doc_text).ratio()\n",
    "        if similarity > 0.5:  # You can adjust this threshold\n",
    "            relevant_docs += 1\n",
    "            break  # Stop after finding the first relevant document\n",
    "\n",
    "    return relevant_docs / k\n",
    "\n",
    "def calculate_bleu_score(reference, hypothesis):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([reference.split()], hypothesis.split(), \n",
    "                         weights=(0.25, 0.25, 0.25, 0.25), \n",
    "                         smoothing_function=smoothie)\n",
    "\n",
    "def normalize_answer(text):\n",
    "    \"\"\"\n",
    "    Normalize answer text while preserving important punctuation and structure.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace multiple whitespace characters with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Preserve common punctuation that might be important for context\n",
    "    text = re.sub(r'[^a-z0-9\\s.,;:()\"-]', '', text)\n",
    "    \n",
    "    # Normalize some common variations\n",
    "    text = text.replace(' , ', ', ').replace(' . ', '. ')\n",
    "    text = text.replace('( ', '(').replace(' )', ')')\n",
    "    \n",
    "    # Remove spaces before punctuation\n",
    "    text = re.sub(r'\\s([.,;:])', r'\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return f1\n",
    "\n",
    "def evaluate_rag_system(rag_system, evaluation_data, pdf_folder_path):\n",
    "    results = []\n",
    "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    bert_scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    \n",
    "    # Load and process documents\n",
    "    raw_documents = REMOVED_SECRET(pdf_folder_path)\n",
    "    processed_documents = REMOVED_SECRET(raw_documents)\n",
    "\n",
    "    # Build vector database\n",
    "    knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "    \n",
    "    for sample in tqdm(evaluation_data, desc=\"Evaluating samples\"):\n",
    "        question = sample['question']\n",
    "        ground_truth = normalize_answer(sample['ground_truth'])\n",
    "        context = sample['context']\n",
    "        \n",
    "        print(f\"\\n\\nQuestion: {question}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Original Context: {context[:200]}...\")  # Print first 200 characters of context\n",
    "        \n",
    "        if not is_valid_answer(ground_truth):\n",
    "            print(f\"Warning: Invalid ground truth for question: {question}\")\n",
    "            continue\n",
    "        \n",
    "        # Get RAG system's answer and relevant documents\n",
    "        answer, relevant_docs, logits = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        answer = normalize_answer(answer)\n",
    "\n",
    "        # Calculate similarity scores\n",
    "        question_embedding = REMOVED_SECRET(question)\n",
    "        doc_embeddings = REMOVED_SECRET([doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in relevant_docs])\n",
    "        similarity_scores = cosine_similarity([question_embedding], doc_embeddings)[0]\n",
    "        \n",
    "        print(f\"Generated Answer: {answer}\")\n",
    "        print(\"Retrieved Documents:\")\n",
    "        for i, doc in enumerate(relevant_docs[:3], 1):  # Print top 3 retrieved documents\n",
    "            print(f\"Doc {i}: {doc[:200]}...\")  # Print first 200 characters of each document\n",
    "        \n",
    "        # Calculate metrics\n",
    "        bleu_score = calculate_bleu_score(ground_truth, answer)\n",
    "        rouge_scores = rouge_scorer_instance.score(ground_truth, answer)\n",
    "        retrieval_accuracy = calculate_retrieval_accuracy(relevant_docs, context)\n",
    "        \n",
    "        # BERT Score\n",
    "        _, _, bert_f1 = bert_scorer.score([answer], [ground_truth])\n",
    "        \n",
    "        # Perplexity calculation\n",
    "        input_ids = REMOVED_SECRET.encode(question + answer, return_tensors=\"pt\").to(logits.device)\n",
    "        perplexity = calculate_perplexity(logits, input_ids)\n",
    "        \n",
    "        # Additional metrics\n",
    "        exact_match = exact_match_score(answer, ground_truth)\n",
    "        f1 = f1_score(answer, ground_truth)\n",
    "        \n",
    "        print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "        print(f\"ROUGE-L F1: {rouge_scores['rougeL'].fmeasure:.4f}\")\n",
    "        print(f\"Retrieval Accuracy: {retrieval_accuracy:.4f}\")\n",
    "        print(f\"BERT Score: {bert_f1.item():.4f}\")\n",
    "        print(f\"Exact Match: {exact_match}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'ground_truth': ground_truth,\n",
    "            'generated_answer': answer,\n",
    "            'bleu_score': bleu_score,\n",
    "            'rouge1': rouge_scores['rouge1'].fmeasure,\n",
    "            'rouge2': rouge_scores['rouge2'].fmeasure,\n",
    "            'rougeL': rouge_scores['rougeL'].fmeasure,\n",
    "            'retrieval_accuracy': retrieval_accuracy,\n",
    "            'bert_score': bert_f1.item(),\n",
    "            'perplexity': perplexity.item(),\n",
    "            'exact_match': exact_match,\n",
    "            'f1_score': f1,\n",
    "            'relevant_docs': relevant_docs,\n",
    "            'similarity_scores': similarity_scores.tolist()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "# Function to plot distribution of scores\n",
    "def plot_score_distribution(data, score_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data[score_name], kde=True)\n",
    "    plt.title(f'Distribution of {score_name}')\n",
    "    plt.xlabel(score_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Function for error analysis\n",
    "def error_analysis(results):\n",
    "    # Calculate absolute difference between BLEU score and 1 (perfect score)\n",
    "    results['bleu_error'] = 1 - results['bleu_score']\n",
    "    \n",
    "    # Sort by error and get top 10 worst predictions\n",
    "    worst_predictions = results.sort_values('bleu_error', ascending=False).head(10)\n",
    "    \n",
    "    print(\"Top 10 Worst Predictions:\")\n",
    "    for _, row in worst_predictions.iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "        print(f\"Generated Answer: {row['generated_answer']}\")\n",
    "        print(f\"BLEU Score: {row['bleu_score']}\")\n",
    "        print(f\"F1 Score: {row['f1_score']}\")\n",
    "        print(f\"Exact Match: {row['exact_match']}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Analyze error patterns\n",
    "    error_patterns = {\n",
    "        'short_answer': (results['generated_answer'].str.split().str.len() < 5).sum(),\n",
    "        'long_answer': (results['generated_answer'].str.split().str.len() > 50).sum(),\n",
    "        'low_bleu': (results['bleu_score'] < 0.1).sum(),\n",
    "        'low_f1': (results['f1_score'] < 0.5).sum(),\n",
    "        'no_exact_match': (results['exact_match'] == 0).sum()\n",
    "    }\n",
    "    \n",
    "    print(\"\\nError Patterns:\")\n",
    "    for pattern, count in error_patterns.items():\n",
    "        print(f\"{pattern}: {count}\")\n",
    "\n",
    "\n",
    "def prepare_umap_data(rag_system, pdf_directory):\n",
    "    # Load and process documents\n",
    "    raw_documents = REMOVED_SECRET(pdf_directory)\n",
    "    processed_documents = REMOVED_SECRET(raw_documents)\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = REMOVED_SECRET([doc.page_content for doc in processed_documents])\n",
    "\n",
    "    # Convert embeddings to numpy array\n",
    "    embeddings_array = np.array(embeddings)\n",
    "\n",
    "    # Create labels based on document sources\n",
    "    source_to_label = defaultdict(lambda: len(source_to_label))\n",
    "    labels = np.array([source_to_label[REMOVED_SECRET('source', 'unknown')] for doc in processed_documents])\n",
    "\n",
    "    # Alternatively, use K-means clustering to create labels\n",
    "    # n_clusters = min(10, len(processed_documents))  # Adjust the number of clusters as needed\n",
    "    # kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    # labels = kmeans.fit_predict(embeddings_array)\n",
    "\n",
    "    return embeddings_array, labels, processed_documents\n",
    "\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize RAG system\n",
    "    rag_system = RAGSystem(\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "        model_id=MODEL_ID,\n",
    "        reranker_model=RERANKER_MODEL,\n",
    "    )\n",
    "\n",
    "    # Extract data from all PDFs in a directory\n",
    "    pdf_directory = \"local_database\"  # Replace with your PDF directory path\n",
    "\n",
    "    # Load and process documents\n",
    "    raw_documents = REMOVED_SECRET(pdf_directory)\n",
    "    processed_documents = REMOVED_SECRET(raw_documents)\n",
    "    # For text splitting visualization\n",
    "    create_text_splitting_sankey(raw_documents, processed_documents)\n",
    "\n",
    "    # Prepare data for UMAP visualization\n",
    "    embeddings, labels, processed_documents = prepare_umap_data(rag_system, pdf_directory)\n",
    "    \n",
    "\n",
    "    # Create UMAP visualization\n",
    "    create_animated_umap(embeddings, labels)\n",
    " \n",
    "    all_evaluation_data = []\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = REMOVED_SECRET(pdf_directory, filename)\n",
    "            all_evaluation_data.extend(extract_data_from_pdf(pdf_path))\n",
    "\n",
    "    # Run evaluation\n",
    "    evaluation_results = evaluate_rag_system(rag_system, all_evaluation_data, pdf_directory)\n",
    "\n",
    "    # After evaluation, create visualizations for each result\n",
    "    for i, result in enumerate(evaluation_results.itertuples()):\n",
    "        question = result.question\n",
    "        answer = result.generated_answer\n",
    "        relevant_docs = result.relevant_docs  # Assuming you've stored this in your results\n",
    "        similarity_scores = result.similarity_scores  # Assuming you've stored this in your results\n",
    "\n",
    "        # Create visualization\n",
    "        visualize_retrieval(question, relevant_docs, similarity_scores, f\"retrieval_graph_{i}.png\")\n",
    "\n",
    "        print(f\"Created visualization for question {i}: {question[:50]}...\")\n",
    "\n",
    "    # Display some information about the UMAP visualization\n",
    "    print(f\"UMAP visualization created with {len(embeddings)} document chunks.\")\n",
    "    print(f\"Number of unique labels: {len(np.unique(labels))}\")\n",
    "    print(\"Label distribution:\")\n",
    "    for label, count in zip(*np.unique(labels, return_counts=True)):\n",
    "        print(f\"  Label {label}: {count} chunks\")\n",
    "        \n",
    "    # Display results\n",
    "    print(evaluation_results.describe())\n",
    "\n",
    "    # Calculate average scores for numeric columns only\n",
    "    numeric_columns = evaluation_results.select_dtypes(include=[np.number]).columns\n",
    "    average_scores = evaluation_results[numeric_columns].mean()\n",
    "    print(\"\\nAverage Scores:\")\n",
    "    print(average_scores)\n",
    "\n",
    "    # Plot distributions for numeric columns\n",
    "    for metric in numeric_columns:\n",
    "        plot_score_distribution(evaluation_results, metric)\n",
    "\n",
    "    # Correlation heatmap for numeric columns\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(evaluation_results[numeric_columns].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap of Evaluation Metrics')\n",
    "    plt.show()\n",
    "\n",
    "    # Error analysis\n",
    "    error_analysis(evaluation_results)\n",
    "\n",
    "    # Display generated answers\n",
    "    print(\"\\nGenerated Answers:\")\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "        print(f\"Generated Answer: {row['generated_answer']}\")\n",
    "        print(f\"BLEU Score: {row['bleu_score']:.4f}\")\n",
    "        print(f\"F1 Score: {row['f1_score']:.4f}\")\n",
    "        print(f\"Exact Match: {row['exact_match']}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Clear memory\n",
    "    rag_system.clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goooood good ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe good ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bad v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/REMOVED_SECRET+json": {
       "model_id": "69f8e3f2264149ff9161efac0d4f1ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Loading PDFs: 100%|██████████| 30/30 [00:01<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: [Document(page_content='Question: fish appeared in the fossil record during the\\n\\nAnswer: wiki/Cambrian_explosion\" title=\"Cambrian explosion\">Cambrian explosion. It was d\\n\\nContext:\\n\\nution of fish began about 530 million years ago during the Cambrian explosion. It was during this time that the early chordates developed the skull and the vertebral column, leading to the first craniates and vertebrates. The first fish lineages belong to the Agnatha, or jawless fish. Early examples include Haikouichthys. During the late Cambrian, eel-like jawless fish called the conodonts, and small mostly armoured fish known as ostracoderms, first appeared. Most jawless fish are now extinct; but the extant lampreys may approximate ancient pre-jawed fish. Lampreys belong to the Cyclostomata, which includes the extant hagfish, and this group may have split early on from other agnathans. The first\\n\\nFull Document (Truncated):\\n\\nEvolution of fish - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opa li{background:#fff;border:1px city:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > 10px solid rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\n0\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_28.pdf'}), Document(page_content=\"Question: when does grey's anatomy season 14 premiere\\n\\nAnswer: eptember 28, 2017<\\n\\nContext:\\n\\nGrey's Anatomy (season 14) Promotional poster Starring Ellen Pompeo Justin Chambers Chandra Wilson James Pickens, Jr. Kevin McKidd Jessica Capshaw Sarah Drew Jesse Williams Caterina Scorsone Camilla Luddington Kelly McCreary Jason George Martin Henderson Giacomo Gianniotti Country of origin United States No. of episodes 12 Release Original network ABC Original release September 28, 2017 (2017-09-28) – present Season chronology ‹ Previous Season 13 List of Grey's Anatomy episodes The\\n\\nFull Document (Truncated):\\n\\nGrey's Anatomy (season 14) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima ge:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 2px 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none...\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_13.pdf'}), Document(page_content='Question: who established the peoples republic of china in 1949\\n\\nAnswer: men\" title\\n\\nContext:\\n\\n> details the history of mainland China since October 1, 1949, when, after a near complete victory by the Chinese Communist Party (CCP) in the Chinese Civil War, Mao Zedong proclaimed the People\\'s Republic of China (PRC) from atop Tiananmen. The PRC has for several decades been synonymous with China, but it is only the most recent political entity to govern mainland China, preceded by the Republic of China (ROC) and thousands of years of imperial dynasties. Con\\n\\nFull Document (Truncated):\\n\\nHistory of the People\\'s Republic of China - Wikipedia .referencetooltip{position:absolute;list-style:none;l ist-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_7.pdf'}), Document(page_content=\"Question: who holds the most women's wimbledon titles\\n\\nAnswer: na Navratilova<\\n\\nContext:\\n\\nWimbledon Ladies’ Singles ChampionsLocation LondonUnited KingdomVenue AELTCGoverning body (established)Open Era: 1968(51 editions)Surface Grass AELTC (1884–Present)Prize money £ 2,000,000 (2016)Trophy Venus Rosewater DishWebsite REMOVED_SECRET/en_GB/about/history/rolls/ladiesroll.htmlMost titlesAmateur era 7: Dorothea (regular)Open era 9: Martina round)8: Helen Wills Moody Lambert Chambers(challenge NavratilovaMost consecutive titlesAmateur era 3: Lottie DodSuzanne Lenglen(challenge round)4: Helen Wills Moody(regular)Open era 6: Martina NavratilovaCurrent champion Angelique Kerber(1st singles title) <\\n\\n/ LTACreated 1884\\n\\nFull Document (Truncated):\\n\\nList of Wimbledon ladies' singles champions - Wikipedia .referencetooltip{position:absolute;list-style:no > ne;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_24.pdf'}), Document(page_content='Question: who plays percy in the lost city of z\\n\\nAnswer: Johns\\'\\n\\nContext:\\n\\nwas optioned by Brad Pitt\\'s Plan B production company and Paramount Pictures. James Gray directed the film, which stars Charlie Hunnam as Fawcett and was released in April 2017. The Cruise of the Condor (1933), one of W. E. Johns\\' \"Bigg\\n\\nFull Document (Truncated):\\n\\nPercy Fawcett - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opaci 2px ty:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-sha...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_23.pdf'}), Document(page_content=\"Question: when does life is strange before the storm part 2\\n\\nAnswer: October 2017\\n\\nContext:\\n\\nLife Is Strange: Before the Storm Developer(s) Deck Nine[a] Publisher(s) Square Enix Director(s) Webb Pickersgill Chris Floyd Producer(s) David Lawrence Hein Zoe Brown Designer(s) William Beacham Programmer(s) Mark Lyons Danielle Cheah Artist(s) Andrew Weatherl Writer(s) Zak Garriss Composer(s) Daughter Engine Unity Platform(s) Microsoft Windows PlayStation 4 Xbox One Release Episode 1 WW: 31 August 2017 Episode 2 WW: 19 October 2017 Episode 3 WW: 20 December 2017 Genre(s) Graphic adventure Mode(s) Single-player\\n\\nFull Document (Truncated):\\n\\nLife Is Strange: Before the Storm - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style -image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip li{border:#080086 13px 2px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shad...\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_2.pdf'}), Document(page_content='Question: how many beverly hills cops movies are there\\n\\nAnswer: e fil\\n\\nContext:\\n\\nI>Beverly Hills Cop is a series of American action comedy films and an unaired television pilot based on characters created by Daniel Petrie, Jr. and Danilo Bach. The films star Eddie Murphy as Axel Foley, a street-smart Detroit cop who travels to Beverly Hills, California to investigate crimes, even though it is out of his jurisdiction. There, he meets Detective Billy Rosewood (Judge Reinhold), Sergeant John Taggart (John Ashton), and Lieutenant Andrew Bogomil (Ronny Cox). Ashton and Cox do not appear in Beverly Hills Cop III. Murphy, Reinhold, and Gil Hill, who plays Axel\\'s boss, Inspector Todd, are the only actors who appear in all three films. Harold Faltermeyer produced the now famous \"Axel F\" theme song heard throughout the series. The series as a whole have been distributed by Paramount Pictures. The films have made a total of $735,534,503[citation needed] at the worldwide box office.\\n\\nFull Document (Truncated):\\n\\nBeverly Hills Cop (film series) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'nq_samples_good/nq_sample_26.pdf'}), Document(page_content=\"Question: where does jinx you owe me a coke come from\\n\\nAnswer: Jinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously\\n\\nContext:\\n\\nJinx is a children's game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously.[1][2]\\n\\nFull Document (Truncated):\\n\\nJinx (children's game) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px 8px solid;max-width:260px;padding:10px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px body solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_4.pdf'}), Document(page_content='Question: who is ted talking about in how i met your mother\\n\\nAnswer: Tracy McConnell\\n\\nContext:\\n\\nTracy McConnell, better known as \"The Mother\", is the title character from the CBS television sitcom How I Met Your Mother. The show, narrated by Future Ted, tells the story of how Ted Mosby met The Mother. Tracy McConnell appears in 8 episodes from \"Lucky Penny\" to \"The Time Travelers\" as an unseen character; she was first seen fully in \"Something New\" and was promoted to a main character in season 9. The Mother is played by Cristin Milioti.\\n\\nFull Document (Truncated):\\n\\nThe Mother (How I Met Your Mother) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-s tyle-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-sha...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_9.pdf'}), Document(page_content=\"Question: where is the greatest royal rumble taking place\\n\\nAnswer: Jeddah, Saudi Arabia\\n\\nContext:\\n\\nGreatest Royal Rumble[3] was a professional wrestling pay-per-view event[4] and WWE Network event[5][6] promoted by WWE for their Raw and SmackDown brands. The event was held on April 27, 2018 at the King Abdullah Sports City's King Abdullah International Stadium in Jeddah, Saudi Arabia.[3][7] The event was scheduled for 7:00 p.m. local time. It aired live in the United States at noon EDT, with a pre-show starting at 11 a.m. EDT.[8] At the event, all men's main roster championships were defended, in addition to a 50-man Royal Rumble match.[9]\\n\\nFull Document (Truncated):\\n\\nWWE Greatest Royal Rumble - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-im > age:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px 10px 0 rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;bor...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_12.pdf'}), Document(page_content=\"Question: the human tendency to mimic other people’s behavior is an example of\\n\\nAnswer: Mirroring\\n\\nContext:\\n\\nMirroring is the behaviour in which one person subconsciously imitates the gesture, speech pattern, or attitude of another. Mirroring often occurs in social situations, particularly in the company of close friends or family. The concept often affects other individuals' notions about the individual that is exhibiting mirroring behaviors, which can lead to the individual building rapport with others.\\n\\nFull Document (Truncated):\\n\\nMirroring (psychology) - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no > ne;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;border...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_14.pdf'}), Document(page_content=\"Question: who won season 4 of america's got talent\\n\\nAnswer: nner was\\n\\nContext:\\n\\n>fourth season of America's Got Talent, an American television reality show talent competition, premiered on the NBC network on June 23, 2009. Country singer Kevin Skinner was named the winner on September 16, 2009. This season is the first season to be broadcast in high definition. This s\\n\\nFull Document (Truncated):\\n\\nAmerica's Got Talent (season 4) - Wikipedia .mw-editfont-monospace{font-family:monospace,monospa ce}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cur...\\n\\nsolid\", metadata={'source': 'nq_samples_good/nq_sample_10.pdf'}), Document(page_content=\"Question: when does model code of conduct come into force\\n\\nAnswer: immediately on announcement of the election schedule by the commission\\n\\nContext:\\n\\nElection Commission of India's Model Code of Conduct is a set of guidelines issued by the Election Commission of India for conduct of political parties and candidates during elections mainly with respect to speeches, polling day, polling booths, election manifestos, processions and general conduct. These set of norms has been evolved with the consensus of political parties who have consented to abide by the principles embodied in the said code in its letter and spirit.The Model Code of Conduct comes into force immediately on announcement of the election schedule by the commission for the need of ensuring free and fair elections.[1] Much of it is designed to avert communal clashes and corrupt practices. For example, politicians should not make hate speeches, putting one community against another or make promises about new projects that may sway a voter.\\n\\nFull Document (Truncated):\\n\\nElection Commission of India's Model Code of Conduct - Wikipedia .referencetooltip{position:absolute;li st-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetool 10px tip solid rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{...\\n\\n>\\n\\nli{background:#fff;border:1px\\n\\n#bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);box-shadow:0\\n\\n0 0\\n\\n0\\n\\n10px\", metadata={'source': 'nq_samples_good/nq_sample_8.pdf'}), Document(page_content=\"Question: who signed the gun control act of 1968\\n\\nAnswer: t Lyndon B. Johnson on\\n\\nContext:\\n\\nCA was signed into law by President Lyndon B. Johnson on October 22, 1968, and is Title I of the U.S. federal firearms laws. The National Firearms Act of 1934 (NFA) is Title II. Both GCA and NFA are enforced by the Bureau of Alcohol, Tobacco, Firearms and Explosives (ATF).\\n\\nFull Document (Truncated):\\n\\nGun Control Act of 1968 - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:n > one;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px rgba(0,0,0,0.2);-moz-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;borde...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_29.pdf'}), Document(page_content=\"Question: who plays nicholas in the princess diaries 2\\n\\nAnswer: ine),\\n\\nContext:\\n\\nst of the cast returned from the first film, including Julie Andrews, Anne Hathaway, Héctor Elizondo, Heather Matarazzo, and Larry Miller. Garry Marshall returned to direct and Debra Martin Chase to produce. New characters include Viscount Mabrey (John Rhys-Davies), Lord Nicholas Devereaux (Chris Pine), and Andrew Jacoby (Callum Blue). Des\\n\\nFull Document (Truncated):\\n\\nThe Princess Diaries 2: Royal Engagement - Wikipedia .referencetooltip{position:absolute;list-style:non e;list-style-image:none;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px li{border:#080086 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-b...\\n\\n2px\\n\\nsolid;max-width:260px;padding:10px\\n\\n8px\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_21.pdf'}), Document(page_content=\"Question: which city and state hosts the annual college world series\\n\\nAnswer: Omaha, Nebraska\\n\\nContext:\\n\\nThe College World Series, or CWS, is an annual June baseball tournament held in Omaha, Nebraska. The CWS is the culmination of the National Collegiate Athletic Association (NCAA) Division I Baseball Championship tournament—featuring 64 teams in the first round—which determines the NCAA Division I college baseball champion. The eight participating four-team, double-elimination brackets, with the winners of each bracket playing in a best-of-three championship series.\\n\\nteams are split\\n\\ninto\\n\\ntwo,\\n\\nFull Document (Truncated):\\n\\nCollege World Series - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:non 2px e;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no transparent ne;border-top:12px #080086 solid;border-right:7px solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_5.pdf'}), Document(page_content=\"Question: who pays the judgements on the judge mathis show\\n\\nAnswer: Mathis\\n\\nContext:\\n\\nI>Judge Mathis is a syndicated arbitration-based reality court show presided over by the retired Judge of Michigan's 36th District Court, Greg Mathis.[1] The syndicated series features Mathis adjudicating small claims disputes.\\n\\nFull Document (Truncated):\\n\\ntop:-99999px;clip:rect(1px 1px 1px 1px); Judge Mathis !important;border:0 clip:rect(1px,1px,1px,1px); overflow:hidden} !important;height:1px .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuK...\\n\\nWikipedia\\n\\n.cite-accessibility-label{ position:absolute !important;width:1px\\n\\n!important;padding:0\\n\\n!important;\", metadata={'source': 'nq_samples_good/nq_sample_16.pdf'}), Document(page_content='Question: who sang take that look off your face\\n\\nAnswer: Marti Webb\\n\\nContext:\\n\\n\"Take That Look Off Your Face\" is the title of a hit song by musical theatre composer Andrew Lloyd Webber. Collaborating with lyricist Don Black, it was written for the song cycle show Tell Me on a Sunday in 1978. It was sung and released by Marti Webb in 1980, and became a No.3 hit in the UK charts. The song was also popular in Ireland, and spent six weeks at number one. Later, Tell Me on a Sunday was combined with another Lloyd Webber work, Variations, to form an entire new show, Song and Dance.\\n\\nFull Document (Truncated):\\n\\nTake That Look Off Your Face - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-i > mage:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px li{background:#fff;border:1px 10px rgba(0,0,0,0.2);-moz-box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\nsolid 0\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0', metadata={'source': 'nq_samples_good/nq_sample_22.pdf'}), Document(page_content=\"Question: when did the hornets move to new orleans\\n\\nAnswer: n then-owner of t\\n\\nContext:\\n\\nestablished as the New Orleans Hornets in the 2002–03 season when then-owner of the Charlotte Hornets, George Shinn, relocated the franchise to New Orleans. Due to the damage caused by Hurricane Katrina in 2005, the franchise temporarily relocated to Oklahoma City, where they spent two seasons officially known as the New Orleans/Oklahoma City Hornets. The team returned to New Orleans full-time for the 2007–08 season. On January 24, 2013, the franchise announced it would rename itself the Pelicans,[7] effective after the conclusion of the 2012–13 season. The Charlotte Hornets name, history and records from 1988 to 2002 were returned to its original city to be used by the then–Charlotte Bobcats franchise, which subsequently became the Charlotte Hornets, starting May 20, 2014.[1] In 14 seasons of play since the\\n\\nFull Document (Truncated):\\n\\nNew Orleans Pelicans - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_27.pdf'}), Document(page_content='Question: where was donovan mitchell picked in the draft\\n\\nAnswer: i/20\\n\\nContext:\\n\\n=\"/wiki/Denver_Nuggets\" title=\"Denver Nuggets\">Denver Nuggets with the 13th overall pick in the 2017 NBA draft only to be traded to the Utah Jazz for the 24th pick (Tyler Lydon) and Trey Lyles.[15] On July 5, 2017, Mitchell signed a four-year rookie scale contract with the Jazz.[16] On July 11, 2017, Mitchell signed a multi-year shoe deal with Adidas. Later that day, Mitchell scored 37 points against the Memphis Grizzlies in the 2017 NBA Summer League in Las Vegas, the most by any player during the 2017 NBA Summer League.[17] In his NBA debut on October 18, 2017, Mitchell registered 10 points and 4 assists against the Denver Nuggets.[18] On December 1, 2017, he scored a career-high 41 points in a 114–108 win over the New Orleans Pelicans. He set the Jazz scoring record for a rookie and became the first NBA rookie to score 40 points in a game since Blake Griffin in 2011.[19] He surpassed Darrell Griffith\\'s team-record 38 in 1981.[20] Mitchell also became the seventh rookie in franchise history to have a 30-plus point game, as well as the first to have a 40-plus point game.[21] On January 4, 2018, Mitchell was named the Western Conference Rookie of the Month for December 2017 after averaging 23.1 points, 3.4 assists, 3.2 rebounds and 1.8 steals in 34.3 minutes per game during the month of December.[22] On January 15, 2018, Mitchell surpassed Karl Malone for most 20+ points games during a rookie season when he had his 19th 20+ point game.[23] On February 2, 2018 Donovan recorded his second 40 point game of his rookie season against the Phoenix Suns, becoming the first rookie guard to notch two 40-point games since Allen Iverson in 1996-97. [24] On February 5, 2018, Donovan was officially named by the NBA as an injury replacement for Orlando Magic forward Aaron Gordon (strained left hip flexor) for the 2018 NBA Slam Dunk Contest.[25] He won the contest scoring a 48 and 50 in the first round, then a 50 and 48 in the final round being the first rookie to win the contest since Zach LaVine. On March 1, 2018, Mitchell was named as the Western Conference rookie of the month for the 3rd time this season for games played in February.[26] On April 10, he set a rookie record for most three-pointers in a season with 186 three-pointers during a 119–79 win over the Golden State Warriors.[27] On April 12, at the end of the regular season, Mitchell was named Western Conference Rookie of the Month for March and April.[28] In Mitchell\\'s playoff debut against\\n\\nFull Document (Truncated):\\n\\nDonovan Mitchell - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;op li{background:#fff;border:1px acity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > solid 10px rgba(0,0,0,0.2);box-shadow:0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px transparent + li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0...\\n\\n#bbb;-webkit-box-shadow:0\\n\\n0 0\\n\\n10px\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0\\n\\n10px\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\n0\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_25.pdf'}), Document(page_content=\"Question: who made up the elf on the shelf\\n\\nAnswer: a Bell over\\n\\nContext:\\n\\n>The Elf on the Shelf was written in 2004 by Carol Aebersold and daughter Chanda Bell over a cup of tea. Bell suggested they write a book about an old tradition of an elf sent from Santa who came to watch over them at Christmas time. Aebersold's other daughter, Christa Pitts, was recruited by the family to share her expertise in sales and marketing. Together, the trio devoted the next three years promoting their self-published book and attending book signings and trade shows. <\\n\\nFull Document (Truncated):\\n\\nThe Elf on the Shelf - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:'';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px\", metadata={'source': 'nq_samples_good/nq_sample_11.pdf'}), Document(page_content='Question: who sings with shaggy on it wasn me\\n\\nAnswer: English-Jamaican singer Rikrok\\n\\nContext:\\n\\n\"It Wasn\\'t Me\" is the first single from Jamaican-American reggae artist Shaggy\\'s multi-Platinum studio album Hot Shot (2000). The song features vocals from English-Jamaican singer Rikrok.\\n\\nFull Document (Truncated):\\n\\nIt Wasn\\'t Me - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity: 0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 10px rgba(0,0,0,0.2);margin:0;padding:8px rgba(0,0,0,0.2);box-shadow:0 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px; margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shad solid;border-right:7px ow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px + transparent li::after{z-index:111;content:\\'\\';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;hei ght:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referenceto oltip.RTflipped > li + li{position:absolute;top:0;border-top:0;bor...\\n\\n0\\n\\n10px 0\\n\\nrgba(0,0,0,0.2);-moz-box-shadow:0 10px\\n\\n0\\n\\n#bbb\\n\\nsolid;border-left:7px\\n\\ntransparent\\n\\nsolid}.referencetooltip\\n\\n>\\n\\nli', metadata={'source': 'nq_samples_good/nq_sample_6.pdf'}), Document(page_content='Question: how many goals scored ronaldo in his career\\n\\nAnswer: allers_with_500_or_more_goals\" title=\"List of men\\'s footballers with 500 or more goals\">670 senior career goals for club and cou\\n\\nContext: s Aveiro GOIH ComM (European Portuguese: [kninntjnnu nonnandu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for Italian club Juventus and the Portugal national team. Often considered the best player in the world and regarded by many as one of the greatest players of all time,[4][5] Ronaldo has a record-tying five Ballon d\\'Or awards,[note 2] the most for a European player, and is the first player to win four European Golden Shoes. He has won 26 trophies in his career, including five league titles, five UEFA Champions League titles and one UEFA European Championship. A prolific goalscorer, Ronaldo holds the records for most official goals scored in Europe\\'s top-five leagues (395), the UEFA Champions League (120), the UEFA European Championship (9), as well as those for most assists in the UEFA Champions League (34) and the UEFA European Championship (6). He has scored over 670 senior career goals for club and country. Born and raised on the Portuguese isla\\n\\nFull Document (Truncated):\\n\\nCristiano Ronaldo - Wikipedia .mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-sel ect:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default:before{content:\\'[\\'}.mw-c ollapsible-toggle-default:after{content:\\']\\'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-content-ltr .mw-collapsible-toggle{float:none} .mw-content-rtl .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_SECRETMJxGBNWLuGo8ngWBY+Hgx...\\n\\ncaption', metadata={'source': 'nq_samples_good/nq_sample_1.pdf'}), Document(page_content=\"Question: when did now thats what i call music come out\\n\\nAnswer: 28 November 1983\\n\\nContext:\\n\\nNow That's What I Call Music (also simply titled Now or Now 1) is the first album from the popular Now! series that was released in the United Kingdom on 28 November 1983.[1] Initial pressings were released on vinyl and audio cassette. To celebrate the 25th anniversary of the album and series, the album was re-released on CD for the first time in 2009. However, alternative longer mixes of Only For Love, Double Dutch and Candy Girl were included in place of the original shorter single mixes from 1983.[2] A double vinyl re-release followed for Record Store Day on 18 April 2015.[3] In July 2018, the album was newly remastered and re-released on CD, vinyl and cassette to commemorate the release of the 100th volume of the series.[4]\\n\\nFull Document (Truncated):\\n\\nNow - Wikipedia .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET BQAFAAABXVgII7jwpAo+TxjkoiGkY5...\\n\\nThat's What\\n\\nI\\n\\nCall\\n\\nMusic\\n\\n(original\\n\\nUK\\n\\nalbum)\", metadata={'source': 'nq_samples_good/nq_sample_18.pdf'}), Document(page_content='Question: who warned concord that the british were coming\\n\\nAnswer: Samuel Prescott\\n\\nContext:\\n\\nSamuel Prescott (August 19, 1751 – c. 1777) was a Massachusetts Patriot during the American Revolutionary War. He is best remembered for his role in Paul Revere\\'s \"midnight ride\" to warn the townspeople of Concord of the impending British army move to capture guns and gunpowder kept there at the beginning of the American Revolution. He was the only participant in the ride to reach Concord.[1] <\\n\\nFull Document (Truncated):\\n\\nSamuel Prescott - Wikipedia .mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont -sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monos pace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textIn putWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px} .mw-ui-button{fo nt-family:inherit;font-size:1em;display:inline-block;min-width:4em;max-width:28.75em;padding:0.54687 5em 1em;line-height:1.286;margin:0;border-radius:2px;-webkit-box-sizing:border-box;-moz-box-sizing: border-box;box-sizing:border-box;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;background-color:#f8f9fa;color:#222222;border:1px #a2a9b1;text-align:center;font-weight:bold;cursor:pointer}.mw-...\\n\\nsolid', metadata={'source': 'nq_samples_good/nq_sample_17.pdf'}), Document(page_content='Question: 100 acres is equal to how many hectares\\n\\nAnswer: =\"/wiki/Hectometre\" title=\"Hectometre\">hectometre (hm2) and primarily u\\n\\nContext: The hectare (/nhnktnnr, -tnnr/; SI symbol: ha) is an SI accepted metric system unit of area equal to 100 ares (10,000 m2) or 1 square hectometre (hm2) and primarily used in the measurement of land as a metric replacement for the imperial acre.[1] An acre is about 0.405 hectare and one hectare contains about 2.47 acres. In 1795, whe\\n\\nFull Document (Truncated):\\n\\nHectare - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;fo 2px nt-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-box-shadow:no...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_3.pdf'}), Document(page_content='Question: who spread the theory that one is a product of the mind and body\\n\\nAnswer: non-extended,\\n\\nContext:\\n\\nirect\" title=\"Western Philosophy\">Western Philosophy, the earliest discussions of dualist ideas are in the writings of Plato who maintained that humans\\' \"intelligence\" (a faculty of the mind or soul) could not be identified with, or explained in terms of, their physical body.[6][30] However, the best-known version of dualism is due to René Descartes (1641), and holds that the mind is a non-extended, non-physical substance, a \"res cogitans\".[7] Descartes was the first to clearly identify the mind with consciousness and self-awareness, and to distinguish this from the brain, which was the seat of intelligence. He was therefore the first to formulate the mind–body problem in the form in which it still exists today.[7]\\n\\nFull Document (Truncated):\\n\\nPhilosophy of mind - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:none; 2px opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px rgba(0,0,0,0.3);-moz-box-shadow:2px 2px 2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-moz-bo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_19.pdf'}), Document(page_content='Question: when did nsw last won a state of origin series\\n\\nAnswer: D> <\\n\\nContext:\\n\\nmargin: 1em auto\"> State of Origin series Year Winner Wins Losses Drawn Shield Holder 1982 Queensland 2 1 0 Queensland 1983 Queensland 2 1 0 Queensland 1984 Queensland 2 1 0 Queensland 1985 New South Wales 2 1 0 New South Wales 1986 New South Wales 3 0 0 New South Wales 1987 Queensland 2 1[23] 0 Queensland 1988 Queensland 3 0 0 Queensland 1989 Queensland 3 0 0 Queensland 1990 New South Wales 2 1 0 New South Wales 1991 Queensland 2 1 0 Queensland 1992 New South Wales 2 1 0 New South Wales 1993 New South Wales 2 1 0 New South Wales 1994 New South Wales 2 1 0 New South Wales 1995 Queensland 3 0 0 Queensland 1996 New South Wales 3 0 0 New South Wales 1997 New South Wales 2 1 0 New South Wales 1998 Queensland 2 1 0 Queensland 1999 Draw 1 1 1 Queensland 2000 New South Wales 3 0 0 New South Wales 2001 Queensland 2 1 0 Queensland 2002 Draw 1 1 1 Queensland 2003 New South Wales 2 1 0 New South Wales 2004 New South Wales 2 1 0 New South Wales 2005 New South Wales 2 1 0 New South Wales 2006 Queensland 2 1 0 Queensland 2007 Queensland 2 1 0 Queensland 2008 Queensland 2 1 0 Queensland 2009 Queensland 2 1 0 Queensland 2010 Queensland 3 0 0 Queensland 2011 Queensland 2 1 0 Queensland 2012 Queensland 2 1 0 Queensland 2013 Queensland 2 1 0 Queensland 2014 New South Wales 2 1 0 New South Wales 2015 Queensland 2 1 0 Queensland 2016 Queensland 2 1 0 Queensland 2017 Queensland 2 1 0 Queensland 2018 New South Wales 2 1 0 New South Wales <\\n\\nFull Document (Truncated):\\n\\nWikipedia State .mw-spinner{background-color:transparent;background-position:center center;background-repeat:no-re peat}.mw-spinner-small{background-image:url(data:image/gif;base64,R0lGODlhFAAUAIQQAAYJBRkb REMOVED_SECRETREMOVED_SECRET/////////////////// REMOVED_SECRETREMOVED_SECRETQkCi REMOVED_REMOVED_SECRET REMOVED_REMOVED_SECRETECQo REMOVED_SECRETREMOVED_SECRET REMOVED_REMOVED_SECRETHK REMOVED_SECRETUABQAAAV6YCCO44GQKOkw40CIxZuKi9KI REMOVED_REMOVED_SECRETC43 REMOVED_SECRETREMOVED_SECRET REMOVED_SECRETDSinIHQozUcuISCI...\\n\\nof\\n\\nOrigin\\n\\nseries\\n\\n', metadata={'source': 'nq_samples_good/nq_sample_15.pdf'}), Document(page_content=\"Question: who designed the national coat of arms of south africa\\n\\nAnswer: r's\\n\\nContext:\\n\\nign process was initiated when, in 1999, the Department of Arts, Culture, Science and Technology requested ideas for the new coat-of-arms from the public. A brief was then prepared based on the ideas received, along with input from the Cabinet. The Government Communication and Information System then approached Design South Africa to brief ten of the top designers. Three designers were chosen to present their concepts to the Cabinet. Iaan Bekker's design was chosen. The new\\n\\nFull Document (Truncated):\\n\\nCoat of arms of South Africa - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-ima > ge:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip 10px solid li{background:#fff;border:1px #bbb;-webkit-box-shadow:0 rgba(0,0,0,0.2);-moz-box-shadow:0 10px 0 rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{ box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;backgrou nd-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:1 2px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;h eight:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencet ooltip.RTflipped > li + li{position:absolute;top:0;...\\n\\n0\\n\\n10px\\n\\nrgba(0,0,0,0.2);box-shadow:0\\n\\n0\", metadata={'source': 'nq_samples_good/nq_sample_20.pdf'}), Document(page_content='Question: when was the first robot used in surgery\\n\\nAnswer: =\"ci\\n\\nContext:\\n\\nrobot to assist in surgery was the Arthrobot, which was developed and used for the first time in Vancouver in 1983.[44] Intimately involved were biomedical engineer, Dr. James McEwen, Geof Auchinleck, a UBC engineering physics grad, and Dr. Brian Day as well as a team of engineering students. The robot was used in an orthopaedic surgical procedure on 12 March 1984, at the UBC Hospital in Vancouver. Over 60 arthroscopic surgical procedures were performed in the first 12 months, and a 1985 National Geographic video on industrial robots, The Robotics Revolution, featured the device. Other related robotic devices developed at the same time included a surgical scrub nurse robot, which handed operative instruments on voice command, and a medical laboratory robotic arm. A YouTube video entitled Arthrobot illustrates some of these in operation. In 1985\\n\\nFull Document (Truncated):\\n\\nRobot-assisted surgery - Wikipedia .referencetooltip{position:absolute;list-style:none;list-style-image:no 2px ne;opacity:0;font-size:10px;margin:0;z-index:5;padding:0}.referencetooltip 13px solid;max-width:260px;padding:10px 8px 2px 8px;margin:0px;background-color:#F7F7F7;-webkit-box-shadow:2px 2px 2px rgba(0,0,0,0.3);-moz-box-shadow:2px rgba(0,0,0,0.3)}.referencetooltip li+li{margin-left:7px;margin-top:-2px;border:0;padding:0;height:3px;wid th:0px;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:no ne;border-top:12px #080086 solid;border-right:7px transparent solid}.referencetooltip>li+li::after{content:\\'\\';border-top:8px #F7F7F7 solid;border-right:5px transparent transparent solid;border-left:5px solid;margin-top:-12px;margin-left:-5px;z-index:1;height:0px;width:0px;display:block}.client-js body .referencetooltip li li{border:none;-webkit-box-shadow:none;-mo...\\n\\nli{border:#080086\\n\\n4px\\n\\n4px\\n\\nrgba(0,0,0,0.3);box-shadow:2px\\n\\n4px\\n\\ntransparent solid;border-left:7px', metadata={'source': 'nq_samples_good/nq_sample_30.pdf'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Documents: 100%|██████████| 30/30 [00:00<00:00, 305.97it/s]\n",
      "Evaluating samples:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/REMOVED_SECRET/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   3%|▎         | 1/30 [01:02<30:21, 62.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:   7%|▋         | 2/30 [02:06<29:29, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  10%|█         | 3/30 [03:15<29:43, 66.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  13%|█▎        | 4/30 [04:18<28:05, 64.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  17%|█▋        | 5/30 [05:22<26:55, 64.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  20%|██        | 6/30 [05:53<21:16, 53.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  23%|██▎       | 7/30 [06:59<21:59, 57.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  27%|██▋       | 8/30 [07:55<20:50, 56.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  30%|███       | 9/30 [08:52<19:53, 56.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  33%|███▎      | 10/30 [09:55<19:37, 58.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  37%|███▋      | 11/30 [10:55<18:45, 59.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  40%|████      | 12/30 [11:56<17:54, 59.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  43%|████▎     | 13/30 [12:56<16:56, 59.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  47%|████▋     | 14/30 [14:00<16:17, 61.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  50%|█████     | 15/30 [15:16<16:23, 65.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  53%|█████▎    | 16/30 [16:28<15:45, 67.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  57%|█████▋    | 17/30 [17:38<14:47, 68.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  60%|██████    | 18/30 [19:05<14:44, 73.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  63%|██████▎   | 19/30 [20:18<13:28, 73.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  67%|██████▋   | 20/30 [21:19<11:37, 69.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  70%|███████   | 21/30 [22:19<10:02, 66.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  73%|███████▎  | 22/30 [23:29<09:03, 67.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  77%|███████▋  | 23/30 [24:38<07:57, 68.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  80%|████████  | 24/30 [25:50<06:55, 69.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  83%|████████▎ | 25/30 [26:55<05:39, 67.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  87%|████████▋ | 26/30 [28:03<04:31, 67.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  90%|█████████ | 27/30 [29:18<03:30, 70.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  93%|█████████▎| 28/30 [30:16<02:12, 66.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples:  97%|█████████▋| 29/30 [31:16<01:04, 64.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Retrieving documents...\n",
      "Retrieved 30 documents.\n",
      "Using 1 documents for answering.\n",
      "=> Generating answer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 100%|██████████| 30/30 [32:28<00:00, 64.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "       bleu_score  exact_match   f1_score\n",
      "count   30.000000         30.0  30.000000\n",
      "mean     0.003033          0.0   0.161577\n",
      "std      0.009376          0.0   0.120964\n",
      "min      0.000000          0.0   0.000000\n",
      "25%      0.000004          0.0   0.080563\n",
      "50%      0.000044          0.0   0.133831\n",
      "75%      0.000281          0.0   0.196875\n",
      "max      0.043572          0.0   0.480000\n",
      "\n",
      "Average Scores:\n",
      "bleu_score     0.003033\n",
      "exact_match    0.000000\n",
      "f1_score       0.161577\n",
      "dtype: float64\n",
      "\n",
      "Sample Results:\n",
      "Question: how many goals scored ronaldo in his career\n",
      "Ground Truth: allers_with_500_or_more_goals titlelist of mens footballers with 500 or more goals670 senior career goals for club and cou context s aveiro goih comm european portuguese kiiiitjinu ioinaidu born 5 february 1985 is a portuguese professional footballer who plays as a forward for italian club juventus and the portugal national team often considered the best player in the world and regarded by many as one of the greatest players of all time45 ronaldo has a recordtying five ballon dor awardsnote 2 the most for a european player and is the first player to win four european golden shoes he has won 26 trophies in his career including five league titles five uefa champions league titles and one uefa european championship a prolific goalscorer ronaldo holds the records for most official goals scored in europes topfive leagues 395 the uefa champions league 120 the uefa european championship 9 as well as those for most assists in the uefa champions league 34 and the uefa european championship 6 he has scored over 670 senior career goals for club and country born and raised on the portuguese isla full document truncated cristiano ronaldo wikipedia REMOVED_SECRETctnonewebkitusersel REMOVED_REMOVED_SECRETntmwc REMOVED_SECRETREMOVED_SECRETr caption mwcollapsibletogglemwcontentltr caption mwcollapsibletogglemwcontentrtl caption mwcollapsibletogglemwcontentrtl mwcontentltr caption mwcollapsibletogglemwcontentltr mwcontentrtl caption mwcollapsibletogglefloatnone REMOVED_SECRETroundpositioncenter centerbackgroundrepeatnore REMOVED_REMOVED_SECRETbrkb REMOVED_SECRETnkyuq7m7umfjxtpv0v REMOVED_SECRETafaauaaafc2agjunqkci REMOVED_SECRETjxgbnwlugo8ngwbyhgx\n",
      "Generated Answer: context s aveiro goih comm european portuguese kninntjnnu nonnandu\n",
      "BLEU Score: 0.0000\n",
      "Exact Match: 0\n",
      "F1 Score: 0.1029\n",
      "--------------------\n",
      "Question: who established the peoples republic of china in 1949\n",
      "Ground Truth: men title context details the history of mainland china since october 1 1949 when after a near complete victory by the chinese communist party ccp in the chinese civil war mao zedong proclaimed the peoples republic of china prc from atop tiananmen the prc has for several decades been synonymous with china but it is only the most recent political entity to govern mainland china preceded by the republic of china roc and thousands of years of imperial dynasties con full document truncated history of the peoples republic of china wikipedia REMOVED_SECRETenonel REMOVED_REMOVED_SECRETp liborder080086 2px solidmaxwidth260pxpadding10px 8px 13px REMOVED_SECREToxshadow2px 4px 2px rgba00003mozboxshadow2px 4px 2px rgba00003boxshadow2px 4px 2px rgba00003referencetooltip REMOVED_SECRETing0height3pxwid REMOVED_REMOVED_SECRETwno nebordertop12px 080086 solidborderright7px transparent solidborderleft7px transparent REMOVED_SECRETdertop8px f7f7f7 solidborderright5px transparent solidborderleft5px transparent REMOVED_REMOVED_SECRETs body referencetooltip li libordernonewebkit\n",
      "Generated Answer: context document 1 the peoples republic of china prc commonly known as china is a\n",
      "BLEU Score: 0.0002\n",
      "Exact Match: 0\n",
      "F1 Score: 0.2056\n",
      "--------------------\n",
      "Question: how many beverly hills cops movies are there\n",
      "Ground Truth: e fil context ibeverly hills cop is a series of american action comedy films and an unaired television pilot based on characters created by daniel petrie jr and danilo bach the films star eddie murphy as axel foley a streetsmart detroit cop who travels to beverly hills california to investigate crimes even though it is out of his jurisdiction there he meets detective billy rosewood judge reinhold sergeant john taggart john ashton and lieutenant andrew bogomil ronny cox ashton and cox do not appear in beverly hills cop iii murphy reinhold and gil hill who plays axels boss inspector todd are the only actors who appear in all three films harold faltermeyer produced the now famous axel f theme song heard throughout the series the series as a whole have been distributed by paramount pictures the films have made a total of 735534503citation needed at the worldwide box office full document truncated beverly hills cop film series wikipedia REMOVED_SECRETenoneliststyleim REMOVED_SECRET5padding0referencetooltip libackgroundfffborder1px solid bbbwebkitboxshadow0 0 10px rgba00002mozboxshadow0 0 10px rgba00002boxshadow0 0 10px rgba00002margin0padding8px REMOVED_SECRETtooltip li li REMOVED_SECRETREMOVED_SECRETu REMOVED_REMOVED_SECRETp1 2px bbb solidborderright7px transparent solidborderleft7px transparent solidreferencetooltip li liafterzindex111contentborder6px solid transparentborderbottom0bordertop8px solid fffh REMOVED_SECRETREMOVED_SECRETcet ooltiprtflipped li lipositionabsolutetop\n",
      "Generated Answer: 3 3 in this task you are given a tuple comprising head and tail\n",
      "BLEU Score: 0.0000\n",
      "Exact Match: 0\n",
      "F1 Score: 0.0523\n",
      "--------------------\n",
      "Question: who warned concord that the british were coming\n",
      "Ground Truth: samuel prescott context samuel prescott august 19 1751 c 1777 was a massachusetts patriot during the american revolutionary war he is best remembered for his role in paul reveres midnight ride to warn the townspeople of concord of the impending british army move to capture guns and gunpowder kept there at the beginning of the american revolution he was the only participant in the ride to reach concord1 full document truncated samuel prescott wikipedia REMOVED_SECRETnospacemweditfont REMOVED_SECRETriffontfamilyserif REMOVED_SECRETeditfontseriffontsize13px mweditfontmonos REMOVED_SECRETREMOVED_SECRETtextin REMOVED_SECRETace oouiinputwidgetinputmweditfontsansserif oouiinputwidgetinputmweditfontserif oouiinputwidgetinputfontsize13px mwuibuttonfo REMOVED_SECRETREMOVED_SECRET87 5em REMOVED_REMOVED_SECRETg REMOVED_SECRETncenonedisplayinline REMOVED_SECRET8f9facolor222222border1px solid REMOVED_SECRETrpointermw\n",
      "Generated Answer: context samuel prescott august 19 1751 c 1777\n",
      "BLEU Score: 0.0000\n",
      "Exact Match: 0\n",
      "F1 Score: 0.2000\n",
      "--------------------\n",
      "Question: fish appeared in the fossil record during the\n",
      "Ground Truth: wikicambrian_explosion titlecambrian explosioncambrian explosion it was d context ution of fish began about 530 million years ago during the cambrian explosion it was during this time that the early chordates developed the skull and the vertebral column leading to the first craniates and vertebrates the first fish lineages belong to the agnatha or jawless fish early examples include haikouichthys during the late cambrian eellike jawless fish called the conodonts and small mostly armoured fish known as ostracoderms first appeared most jawless fish are now extinct but the extant lampreys may approximate ancient prejawed fish lampreys belong to the cyclostomata which includes the extant hagfish and this group may have split early on from other agnathans the first full document truncated evolution of fish wikipedia REMOVED_SECRETenoneliststyleimagenoneopa REMOVED_SECRETeferencetooltip libackgroundfffborder1px solid bbbwebkitboxshadow0 0 10px rgba00002mozboxshadow0 0 10px rgba00002boxshadow0 0 10px rgba00002margin0padding8px REMOVED_SECRETtooltip li liboxsizingborderboxmarginleft7px REMOVED_SECRETREMOVED_SECRETd REMOVED_SECRETrtop12px bbb solidborderright7px transparent solidborderleft7px transparent solidreferencetooltip li liafterzindex111contentborder6px solid transparentborderbottom0bordertop8px solid fffhei REMOVED_SECRETREMOVED_SECRETto oltiprtflipped li lipositionabsolutetop0bordertop\n",
      "Generated Answer: wikicambrian_explosion titlecambrian explosioncambrian explosion it was during this time\n",
      "BLEU Score: 0.0000\n",
      "Exact Match: 0\n",
      "F1 Score: 0.1552\n",
      "--------------------\n",
      "\n",
      "Results saved to rag_evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from rouge_score import rouge_scorer\n",
    "from REMOVED_SECRET import sentence_bleu, SmoothingFunction\n",
    "from bert_score import BERTScorer\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Import your RAG system\n",
    "from RAG_UTILS import RAGSystem, EMBEDDING_MODEL_NAME, MODEL_ID, RERANKER_MODEL\n",
    "\n",
    "#MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "RERANKER_MODEL = None\n",
    "NUM_RETRIEVED_DOCS = 5\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters and extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return ' '.join(text.split()).lower()\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    question_pattern = r\"Question: (.*?)\\n\"\n",
    "    context_pattern = r\"Context:(.*?)(?=Question:|$)\"\n",
    "    answer_pattern = r\"Answer: (.*?)(?=\\n\\n|$)\"\n",
    "\n",
    "    questions = re.findall(question_pattern, text)\n",
    "    contexts = re.findall(context_pattern, text, re.DOTALL)\n",
    "    answers = re.findall(answer_pattern, text, re.DOTALL)\n",
    "\n",
    "    evaluation_data = []\n",
    "    for q, c, a in zip(questions, contexts, answers):\n",
    "        evaluation_data.append({\n",
    "            \"question\": clean_text(q.strip()),\n",
    "            \"context\": c.strip(),\n",
    "            \"ground_truth\": clean_text(a.strip())\n",
    "        })\n",
    "\n",
    "    return evaluation_data\n",
    "\n",
    "def calculate_metrics(ground_truth, generated_answer):\n",
    "    ground_truth = clean_text(ground_truth)\n",
    "    generated_answer = clean_text(generated_answer)\n",
    "    \n",
    "    # BLEU score\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    bleu_score = sentence_bleu([ground_truth.split()], generated_answer.split(), \n",
    "                               weights=(0.25, 0.25, 0.25, 0.25), \n",
    "                               smoothing_function=smoothie)\n",
    "    \n",
    "    # Exact match\n",
    "    exact_match = int(ground_truth == generated_answer)\n",
    "    \n",
    "    # F1 score\n",
    "    ground_truth_set = set(ground_truth.split())\n",
    "    generated_set = set(generated_answer.split())\n",
    "    \n",
    "    if not ground_truth_set and not generated_set:\n",
    "        f1 = 1.0\n",
    "    elif not ground_truth_set or not generated_set:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        precision = len(ground_truth_set.intersection(generated_set)) / len(generated_set)\n",
    "        recall = len(ground_truth_set.intersection(generated_set)) / len(ground_truth_set)\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'bleu_score': bleu_score,\n",
    "        'exact_match': exact_match,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "def evaluate_rag_system(rag_system, evaluation_data, pdf_folder_path):\n",
    "    results = []\n",
    "    \n",
    "    # Load and process documents\n",
    "    raw_documents = REMOVED_SECRET(pdf_folder_path)\n",
    "    processed_documents = REMOVED_SECRET(raw_documents)\n",
    "\n",
    "    # Build vector database\n",
    "    knowledge_index = rag_system.build_vector_database(processed_documents)\n",
    "    \n",
    "    for sample in tqdm(evaluation_data, desc=\"Evaluating samples\"):\n",
    "        question = sample['question']\n",
    "        ground_truth = sample['ground_truth']\n",
    "        context = sample['context']\n",
    "        \n",
    "        # Get RAG system's answer\n",
    "        answer, relevant_docs, _ = rag_system.answer_with_rag(question, knowledge_index)\n",
    "        \n",
    "        # Clean the generated answer\n",
    "        answer = clean_text(answer)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(ground_truth, answer)\n",
    "        \n",
    "        results.append({\n",
    "            'question': question,\n",
    "            'ground_truth': ground_truth,\n",
    "            'generated_answer': answer,\n",
    "            'bleu_score': metrics['bleu_score'],\n",
    "            'exact_match': metrics['exact_match'],\n",
    "            'f1_score': metrics['f1_score'],\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    rag_system = RAGSystem(\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "        model_id=MODEL_ID,\n",
    "        reranker_model=RERANKER_MODEL,\n",
    "    )\n",
    "\n",
    "    pdf_directory = \"nq_samples_good\"  # Replace with your PDF directory path\n",
    "    all_evaluation_data = []\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = REMOVED_SECRET(pdf_directory, filename)\n",
    "            all_evaluation_data.extend(extract_data_from_pdf(pdf_path))\n",
    "\n",
    "    evaluation_results = evaluate_rag_system(rag_system, all_evaluation_data, pdf_directory)\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(evaluation_results.describe())\n",
    "\n",
    "    print(\"\\nAverage Scores:\")\n",
    "    print(evaluation_results[['bleu_score', 'exact_match', 'f1_score']].mean())\n",
    "\n",
    "    # Display some sample results\n",
    "    print(\"\\nSample Results:\")\n",
    "    for _, row in evaluation_results.sample(n=5).iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Ground Truth: {row['ground_truth']}\")\n",
    "        print(f\"Generated Answer: {row['generated_answer']}\")\n",
    "        print(f\"BLEU Score: {row['bleu_score']:.4f}\")\n",
    "        print(f\"Exact Match: {row['exact_match']}\")\n",
    "        print(f\"F1 Score: {row['f1_score']:.4f}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    evaluation_results.to_csv(\"rag_evaluation_results.csv\", index=False)\n",
    "    print(\"\\nResults saved to rag_evaluation_results.csv\")\n",
    "\n",
    "    rag_system.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "REMOVED_SECRET"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
